{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "sys.path.insert(0, os.path.dirname(os.getcwd()))\n",
    "from align_utils import align_df\n",
    "from plot_utils import arr_pcmesh, df_heatmap\n",
    "from red_likelihood import decomposeCArray, degVis, makeCArray, red_ant_sep\n",
    "from red_utils import find_deg_df, find_rel_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "\n",
    "plot_figs = False\n",
    "if plot_figs:\n",
    "    mpl.rcParams['figure.dpi'] = 300\n",
    "\n",
    "mpl.rc('font',**{'family':'serif','serif':['cm']})\n",
    "mpl.rc('text', usetex=True)\n",
    "mpl.rc('text.latex', preamble=r'\\usepackage{amssymb} \\usepackage{amsmath}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jd_time = 2458098.43869\n",
    "jd_anchor = 2458099\n",
    "pol = 'ee'\n",
    "ndist = 'gaussian'\n",
    "rel_dir_path = '../rel_dfs'\n",
    "deg_dir_path = '../deg_dfs'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing a pair of datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading 1st relatively calibrated dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(rel_dir_path, 'rel_df.{}.{}.md.pkl'.format(jd_time, pol)), \\\n",
    "          'rb') as f:\n",
    "    md = pickle.load(f)\n",
    "    \n",
    "indices = ['freq', 'time_int']\n",
    "resid_cols = ['residual', 'norm_residual']\n",
    "vis_list = list(map(str, np.arange(md['no_unq_bls']*2).tolist()))\n",
    "cvis_list = ['C' + vis_id for vis_id in list(map(str, np.arange(md['no_unq_bls']).tolist()))]\n",
    "gain_list = list(map(str, np.arange(md['no_unq_bls']*2, (md['no_unq_bls'] + md['no_ants'])*2 ).tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rel_df_path = find_rel_df(jd_time, pol, ndist, rel_dir_path)\n",
    "rel_df = pd.read_pickle(rel_df_path)\n",
    "rel_df.drop(columns=resid_cols, inplace=True)\n",
    "\n",
    "Nfreqs = rel_df.index.get_level_values('freq').unique().size\n",
    "Ntints = rel_df.index.get_level_values('time_int').unique().size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading 2nd relatively calibrated dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to an offset in LAST, two relatively calibrated dataframes must be merged, with the appropriate cuts in LAST to align the merged dataframe with the 1st one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rel_df_c = align_df('rel', jd_time, jd_anchor, rel_dir_path, ndist, pol)\n",
    "rel_df_c.drop(columns=resid_cols+gain_list, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Degenerate transformation of the 1st dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_list = ['success', 'status', 'message', 'fun', 'nit']\n",
    "rel_df_d = rel_df[min_list].copy()\n",
    "rel_df_d = rel_df_d.reindex(columns=rel_df_d.columns.values.tolist() + vis_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deg_df_path = find_deg_df(jd_time, pol, 'jd.{}'.format(jd_anchor), ndist, deg_dir_path)\n",
    "deg_df = pd.read_pickle(deg_df_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deg_df_d = deg_df[['0', '1', '2']].copy().reset_index()\n",
    "deg_df_d.rename(columns={'time_int1': 'time_int', '0': 'amp', '1': 'tilt_x', '2':'tilt_y'}, inplace=True)\n",
    "deg_df_d.set_index(indices, inplace=True)\n",
    "deg_df_d.sort_index(inplace=True)\n",
    "rel_df.drop(columns=gain_list, inplace=True)\n",
    "rel_df = rel_df.join(deg_df_d)\n",
    "rel_df.sample(5).sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ant_sep = red_ant_sep(md['redg'], md['antpos'])\n",
    "rel_df_d[vis_list] = rel_df.apply(lambda row: pd.Series(decomposeCArray(degVis(ant_sep, \\\n",
    "                     makeCArray(row[len(min_list):len(min_list) + md['no_unq_bls']*2].values.astype(float)), \\\n",
    "                     *row[-3:].values.astype(float)))), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rel_df_d.sample(5).sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combining degenerately consistent dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merging dataframes\n",
    "rel_df_d['JD'] = int(jd_time)\n",
    "rel_df_c['JD'] = int(jd_anchor)\n",
    "\n",
    "rel_df_t = pd.concat([rel_df_d, rel_df_c])\n",
    "\n",
    "rel_df_t.reset_index(inplace=True)\n",
    "rel_df_t.set_index(['freq', 'time_int', 'JD'], inplace=True)\n",
    "rel_df_t.sort_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rel_df_t.sample(5).sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistics on combined dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rel_df_t[vis_list].groupby(level=['freq', 'time_int']).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rel_df_t[vis_list].groupby(level=['freq', 'time_int']).std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single time integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_integration = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selecting time integration\n",
    "rel_df_tint = rel_df_t.xs(time_integration, level='time_int', drop_level=True)\n",
    "# turning into complex values\n",
    "rel_df_tintc = rel_df_tint.apply(lambda row: pd.Series(makeCArray(row[vis_list].values.astype(float))), \\\n",
    "                                 axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis_abs_mean = rel_df_tintc.abs().groupby('freq').mean()\n",
    "piv = pd.pivot_table(vis_abs_mean, columns='freq')\n",
    "vmax = np.nanpercentile(piv.values, 95)\n",
    "\n",
    "# mean visibility amplitudes for specified time integration\n",
    "arr_pcmesh(piv.columns, piv.index, piv.to_numpy(), vmin=0, vmax=vmax, extend='max', \n",
    "           xlabel='Frequency Channel', ylabel='Redundant Baseline Group', clabel=r'$\\overline{|V|}$', \\\n",
    "           xlim=(0, 1023))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "re_df = rel_df_tint.drop(columns=min_list).iloc[:, np.arange(2*md['no_unq_bls'], step=2)]\\\n",
    "        .groupby('freq').var()\n",
    "im_df = rel_df_tint.drop(columns=min_list).iloc[:, np.arange(1, 2*md['no_unq_bls'], step=2)]\\\n",
    "        .groupby('freq').var()\n",
    "re_df.columns = np.arange(md['no_unq_bls'])\n",
    "im_df.columns = np.arange(md['no_unq_bls'])\n",
    "var_df = re_df + im_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "piv = pd.pivot_table(var_df, columns='freq')\n",
    "vmax = np.nanpercentile(piv.values, 95)\n",
    "\n",
    "# visibility variance for specified time integration\n",
    "arr_pcmesh(piv.columns, piv.index, piv.to_numpy(), vmin=0, vmax=vmax, extend='max', \n",
    "           xlabel='Frequency Channel', ylabel='Redundant Baseline Group', clabel=r'$\\mathrm{Var}(V)$', \\\n",
    "           xlim=(0, 1023), sci_fmt=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistics over multiple JDs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Starting from the JDs from the previous section, we add further JDs that cover the same LAST range by aligning them in LAST and degenerately transforming them to be consistent with the anchor day (JD 2458099 in this case).\n",
    "\n",
    "We present an example of how this is done below. See the align_deg.py script for the full implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find dataset from specified JD that contains visibilities at the same LAST\n",
    "\n",
    "jd_ci = 2458101\n",
    "\n",
    "# load rel cal dataframe and align in LAST\n",
    "rel_dfk = align_df('rel', jd_time, jd_ci, rel_dir_path, ndist, \\\n",
    "                   pol)\n",
    "rel_dfk.drop(columns=resid_cols+gain_list, inplace=True)\n",
    "\n",
    "# degenerate transformation\n",
    "deg_dfk = align_df('deg', jd_time, jd_ci, deg_dir_path, ndist, \\\n",
    "                   pol, JD_anchor=jd_anchor)\n",
    "\n",
    "# degenerate transformation of redundant visibility solutions\n",
    "deg_dfk = deg_dfk[['0', '1', '2']].copy().reset_index()\n",
    "deg_dfk.rename(columns={'time_int1': 'time_int', '0': 'amp', \\\n",
    "                        '1': 'tilt_x', '2':'tilt_y'}, inplace=True)\n",
    "deg_dfk.set_index(indices, inplace=True)\n",
    "deg_dfk.sort_index(inplace=True)\n",
    "rel_dfk = rel_dfk.join(deg_dfk)\n",
    "\n",
    "rel_df_di = rel_df[min_list].copy()\n",
    "rel_df_di = rel_df_di.reindex(columns=rel_df_di.columns.values.tolist()\\\n",
    "                              +vis_list)\n",
    "rel_df_di[vis_list] = rel_dfk.apply(lambda row: pd.Series(decomposeCArray(\\\n",
    "    degVis(ant_sep, makeCArray(row[len(min_list):len(min_list) + \\\n",
    "    md['no_unq_bls']*2].values.astype(float)), *row[-3:].values.astype(float)))), \\\n",
    "    axis=1)\n",
    "\n",
    "# merging dataframes\n",
    "rel_df_di['JD'] = jd_ci\n",
    "rel_df_di.reset_index(inplace=True)\n",
    "rel_df_di.set_index(['freq', 'time_int', 'JD'], inplace=True)\n",
    "rel_df_di.sort_index(inplace=True)\n",
    "\n",
    "rel_df_t = pd.concat([rel_df_t, rel_df_di])\n",
    "rel_df_t.sort_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rel_df_t"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hera",
   "language": "python",
   "name": "hera"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

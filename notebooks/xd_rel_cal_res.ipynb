{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "standard-asian",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import yaml\n",
    "from collections import OrderedDict as odict\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from hera_cal.io import HERAData\n",
    "\n",
    "from simpleredcal.align_utils import idr2_jdsx\n",
    "from simpleredcal.fit_diagnostics import abs_residuals, norm_residuals\n",
    "from simpleredcal.plot_utils import clipped_heatmap, df_heatmap, flagged_hist, \\\n",
    "plot_res_grouped, plot_res_heatmap\n",
    "from simpleredcal.red_likelihood import condenseMap, group_data, makeCArray, \\\n",
    "relabelAnts, split_rel_results\n",
    "from simpleredcal.red_utils import DATAPATH, find_nearest, find_zen_file, \\\n",
    "JD2LSTPATH, RESPATH\n",
    "from simpleredcal.xd_utils import union_bad_ants, XDgroup_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intense-surgery",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adjacent-warrant",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "\n",
    "plot_figs = False\n",
    "if plot_figs:\n",
    "    mpl.rcParams['figure.dpi'] = 300\n",
    "\n",
    "mpl.rc('font',**{'family':'serif','serif':['cm']})\n",
    "mpl.rc('text', usetex=True)\n",
    "mpl.rc('text.latex', preamble=r'\\usepackage{amssymb} \\usepackage{amsmath}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fitted-basement",
   "metadata": {},
   "outputs": [],
   "source": [
    "jd_time = 2458098.43869 # used to find LST that labels dataframe\n",
    "pol = 'ee'\n",
    "ndist = 'cauchy'\n",
    "\n",
    "dir_path = os.path.join(RESPATH, 'xd_rel_dfs_nn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "similar-incident",
   "metadata": {},
   "outputs": [],
   "source": [
    "lst_df = pd.read_pickle(JD2LSTPATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "understood-bundle",
   "metadata": {},
   "outputs": [],
   "source": [
    "lst_ref = lst_df[lst_df['JD_time'] == jd_time]['LASTs'].values[0][0]\n",
    "lst_stop = lst_df[lst_df['JD_time'] == jd_time]['LASTs'].values[0][-1]\n",
    "xd_df_path = os.path.join(dir_path, 'xd_rel_df.{:.4f}.{}.{}.pkl'.format(lst_ref, pol, ndist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "respective-belief",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(dir_path, 'xd_rel_df.{:.4f}.{}.md.pkl'.format(lst_ref, pol)), 'rb') as f:\n",
    "    md = pickle.load(f)\n",
    "\n",
    "xd_df = pd.read_pickle(xd_df_path)\n",
    "\n",
    "chans = xd_df.index.get_level_values(level='freq').unique().values\n",
    "tints = xd_df.index.get_level_values(level='time_int').unique().values\n",
    "\n",
    "Nfreqs = chans.size\n",
    "Ntints = tints.size\n",
    "\n",
    "xd_df.sample(5).sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "organic-custom",
   "metadata": {},
   "source": [
    "## Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "direct-product",
   "metadata": {},
   "source": [
    "### Number of iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "solid-meditation",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_res_grouped(xd_df, 'nit', logy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "certain-upset",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_res_heatmap(xd_df, 'nit', clip=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "brown-stock",
   "metadata": {},
   "source": [
    "### Log-likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tamil-richardson",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_res_grouped(xd_df, 'fun', logy=True, figsize=(10, 7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aging-transport",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_res_heatmap(xd_df, 'fun', clip=True, clip_pctile=98, figsize=(8, 6))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "complete-horse",
   "metadata": {},
   "source": [
    "### Residuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adverse-leeds",
   "metadata": {},
   "outputs": [],
   "source": [
    "xd_df[['med_abs_norm_res_Re', 'med_abs_norm_res_Im']] = xd_df.apply(lambda row: \\\n",
    "    pd.Series(abs_residuals(row['norm_residual'])), axis=1)\n",
    "\n",
    "xd_df['med_abs_norm_res_comb'] = np.sqrt(xd_df['med_abs_norm_res_Re']**2 + \\\n",
    "                                         xd_df['med_abs_norm_res_Im']**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "designed-finish",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_res_heatmap(xd_df, 'med_abs_norm_res_comb', vmin=0.16, vmax=0.22, \\\n",
    "                 figsize=(8, 6))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "three-touch",
   "metadata": {},
   "source": [
    "## Gains at sample frequency and time slice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "senior-trigger",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check results for a given frequency & time integration\n",
    "test_freq = 600\n",
    "test_tint = 53\n",
    "\n",
    "resx = xd_df.loc[(test_freq, test_tint)][5:-5].values.astype(float)\n",
    "test_vis, test_gains = split_rel_results(resx, md['no_unq_bls'], coords='cartesian')\n",
    "test_gains = test_gains.reshape((md['JDs'].size, -1))\n",
    "\n",
    "print('Mean gain amplitude across JDs for test frequency {} and time integration {}: '\\\n",
    "      '\\n{}\\n'.format(test_freq, test_tint, np.mean(np.abs(test_gains), axis=0)))\n",
    "print('Mean gain phase across JDs for test frequency {} and time integration {}: '\\\n",
    "      '\\n{}\\n'.format(test_freq, test_tint, np.mean(np.angle(test_gains), axis=0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "anonymous-convert",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(nrows=1, ncols=2, figsize=(9, 3.5), sharey=True)\n",
    "\n",
    "sns.heatmap(np.abs(test_gains), cmap=sns.cm.rocket_r, center=1, ax=ax1)\n",
    "sns.heatmap(np.angle(test_gains), cmap='bwr', center=0, ax=ax2, vmin=-np.pi, vmax=np.pi)\n",
    "ax1.set_xlabel('Antenna number')\n",
    "ax2.set_xlabel('Antenna number')\n",
    "\n",
    "ax1.set_yticks(np.arange(md['JDs'].size)+0.5)\n",
    "ax1.set_yticklabels(md['JDs'], rotation=0)\n",
    "ax2.set_yticks(np.arange(md['JDs'].size), minor=True)\n",
    "ax1.tick_params(axis='y', which='minor', color='white')\n",
    "ax2.tick_params(axis='y', which='minor', color='white')\n",
    "\n",
    "ax1.set_xticks(np.arange(md['no_ants'])[::5]+0.5, minor=False)\n",
    "ax1.set_xticklabels(np.arange(md['no_ants'])[::5])\n",
    "ax2.set_xticks(np.arange(md['no_ants'])[::5]+0.5, minor=False)\n",
    "ax2.set_xticklabels(np.arange(md['no_ants'])[::5])\n",
    "\n",
    "ax1.grid(which='minor', axis='y', linestyle='--', lw=0.5)\n",
    "ax2.grid(which='minor', axis='y', linestyle='--', lw=0.5)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "assigned-magnitude",
   "metadata": {},
   "source": [
    "## Visibilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "humanitarian-trigger",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_unq_bls = md['no_unq_bls']\n",
    "no_min_p = 5 # number of columns in df that are attributes of the SciPy OptimizeResult \n",
    "vis_df = xd_df.iloc[:, no_min_p:no_unq_bls*2+no_min_p]\n",
    "\n",
    "visC_df = vis_df.apply(lambda row: makeCArray(row.values), axis=1)\n",
    "visC_df = pd.DataFrame(visC_df.values.tolist(), index=visC_df.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "arabic-devices",
   "metadata": {},
   "source": [
    "### Visibilities at test time integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "worst-night",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = visC_df.xs(53, level='time_int').abs().transpose()\n",
    "vmax = np.nanpercentile(df.values, 98)\n",
    "vmin = np.nanpercentile(df.values, 2)\n",
    "df_heatmap(df, xbase=25, ybase=5, \\\n",
    "           xlabel='Channel', ylabel='Redundant Baseline Group', \\\n",
    "           vmin=vmin, vmax=vmax, figsize=(8, 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intense-mailing",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = visC_df.xs(53, level='time_int').applymap(np.angle).transpose()\n",
    "df_heatmap(df, xbase=25, ybase=5, cmap='bwr', vmin=-np.pi, vmax=np.pi, center=0, \\\n",
    "           xlabel='Channel', ylabel='Redundant Baseline Group', figsize=(8, 6))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "limited-phrase",
   "metadata": {},
   "source": [
    "## Final flags from the HERA pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "durable-jones",
   "metadata": {},
   "source": [
    "Final flags are the individual final calibration flags + the manual flags applied by Nick Kern + the MAD-clipping flags from LST-binning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vulnerable-seventh",
   "metadata": {},
   "source": [
    "#### Get flags from .smooth_abs.calfits files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "catholic-making",
   "metadata": {},
   "outputs": [],
   "source": [
    "idr2_flags = np.load(f'{DATAPATH}/idr2_flags.npz')['arr_0'].astype(bool)\n",
    "idr2_flags = idr2_flags[:, chans - 50, :] # Channels 500-700, which include Band 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lesbian-patrol",
   "metadata": {},
   "source": [
    "#### Additional flags by Nick Kern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "assisted-blast",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists('/lustre/aoc/projects/hera/H1C_IDR2/'):\n",
    "    nkern_flg_dir = '/lustre/aoc/projects/hera/H1C_IDR2/IDR2_2_pspec/v2/one_group/'\n",
    "    local_work = False\n",
    "else:\n",
    "    nkern_flg_dir = '/Users/matyasmolnar/Downloads/HERA_Data/sample_data/'\n",
    "    local_work = True\n",
    "\n",
    "nkern_flg_file = os.path.join(nkern_flg_dir, 'preprocess_params.yaml')\n",
    "\n",
    "# Read YAML file\n",
    "with open(nkern_flg_file, 'r') as stream:\n",
    "    data_loaded = yaml.safe_load(stream)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hundred-silver",
   "metadata": {},
   "outputs": [],
   "source": [
    "man_flags = np.concatenate([np.arange(i[0], i[1]+1) for i in \\\n",
    "                            data_loaded['algorithm']['fg_filt']['flag_chans']]).ravel()\n",
    "rel_nflags = man_flags[np.where(np.logical_and(man_flags >= chans[0], man_flags <= chans[-1]))] - chans[0]\n",
    "idr2_flags[:, rel_nflags, :] = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bright-bibliography",
   "metadata": {},
   "source": [
    "##### Last individual dataset flags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "engaging-module",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = clipped_heatmap(idr2_flags.sum(axis=0).transpose(), 'Time Integration', 'Channel', \\\n",
    "                          vmin=0, clip_pctile=100, figsize=(8, 5), xoffset=-chans[0], \\\n",
    "                          cbar_lab='\\# Flagged Days')\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hired-copyright",
   "metadata": {},
   "source": [
    "#### MAD-clipping flags from LST-Binning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prostate-symbol",
   "metadata": {},
   "outputs": [],
   "source": [
    "mad_clip_dir = '/lustre/aoc/projects/hera/mmolnar/LST_bin/binned_files/lstb_mad_flags'\n",
    "mad_flag_files = sorted(glob.glob(os.path.join(mad_clip_dir, 'zen.grp1.of1.LST.*.bad_jds.pkl')))\n",
    "mad_flag_lsts = np.array(['.'.join(os.path.basename(fn).split('.')[4:6]) for fn in mad_flag_files])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "finite-repeat",
   "metadata": {},
   "outputs": [],
   "source": [
    "clip_f_idx1 = find_nearest(mad_flag_lsts.astype(float), lst_ref, condition='leq')[1]\n",
    "clip_f_idx2 = find_nearest(mad_flag_lsts.astype(float), lst_stop, condition='leq')[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "controversial-mountain",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(mad_flag_files[clip_f_idx1], 'rb') as f:\n",
    "    clip_flags1 = pickle.load(f)\n",
    "\n",
    "with open(mad_flag_files[clip_f_idx2], 'rb') as f:\n",
    "    clip_flags2 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "common-lying",
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_ants_idr2 = union_bad_ants(idr2_jdsx)\n",
    "\n",
    "clip_flags1 = {k: v for k, v in clip_flags1.items() if k[0] != k[1] and k[2] == 'ee'} # flt autos and pol\n",
    "clip_flags1 = {k: v for k, v in clip_flags1.items() if not any(i in bad_ants_idr2 for i in k[:2])} # flt bad ants\n",
    "\n",
    "clip_flags2 = {k: v for k, v in clip_flags2.items() if k[0] != k[1] and k[2] == 'ee'} # flt autos and pol\n",
    "clip_flags2 = {k: v for k, v in clip_flags2.items() if not any(i in bad_ants_idr2 for i in k[:2])} # flt bad ants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fancy-intellectual",
   "metadata": {},
   "outputs": [],
   "source": [
    "if local_work:\n",
    "    lst_binned_dir = '/Users/matyasmolnar/Downloads/HERA_Data/sample_data/'\n",
    "else:\n",
    "    lst_binned_dir = '/lustre/aoc/projects/hera/H1C_IDR2/IDR2_2/LSTBIN/one_group/grp1'\n",
    "\n",
    "lst_binned_file1 = os.path.join(lst_binned_dir, 'zen.grp1.of1.LST.{}.HH.OCRSL.uvh5'.\\\n",
    "                               format(mad_flag_lsts[clip_f_idx1]))\n",
    "lst_binned_file2 = os.path.join(lst_binned_dir, 'zen.grp1.of1.LST.{}.HH.OCRSL.uvh5'.\\\n",
    "                               format(mad_flag_lsts[clip_f_idx2]))\n",
    "\n",
    "hd_lstb1 = HERAData(lst_binned_file1)\n",
    "hd_lstb2 = HERAData(lst_binned_file2)\n",
    "hd = HERAData(find_zen_file(jd_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stock-tutorial",
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_lsts1 = np.sort(np.append(hd_lstb1.lsts, hd_lstb1.lsts + np.median(np.ediff1d(hd_lstb1.lsts))/2))\n",
    "bin_lsts2 = np.sort(np.append(hd_lstb2.lsts, hd_lstb2.lsts + np.median(np.ediff1d(hd_lstb2.lsts))/2))\n",
    "\n",
    "bin_idx1 = np.digitize(hd.lsts, bin_lsts1, right=False)\n",
    "bin_idx1 = bin_idx1[bin_idx1 < hd.Ntimes*2]\n",
    "\n",
    "bin_idx2 = np.digitize(hd.lsts, bin_lsts2, right=False)\n",
    "bin_idx2 = bin_idx2[np.where(bin_idx2 == 0)[0][-1]:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "foreign-advocate",
   "metadata": {},
   "outputs": [],
   "source": [
    "relab_dict1 = condenseMap(bin_idx1)\n",
    "relab_dict2 = {k: v+bin_idx1.size for k, v in condenseMap(bin_idx2).items()}\n",
    "\n",
    "mad_flags_dict = odict()\n",
    "for bl in clip_flags1.keys():\n",
    "    mad_flags_dict[bl] = odict()\n",
    "    # Iterate over 1st MAD-clipped dataset\n",
    "    for t, v in clip_flags1[bl].items():\n",
    "        if 2*t in bin_idx1:\n",
    "            mad_flags_dict[bl][relab_dict1[2*t]] = v[::2]\n",
    "        if 2*t+1 in bin_idx1:\n",
    "            mad_flags_dict[bl][relab_dict1[2*t+1]] = v[1::2]\n",
    "    # Iterate over 2nd MAD-clipped dataset\n",
    "    for t, v in clip_flags2[bl].items():\n",
    "        if 2*t in bin_idx2:\n",
    "            mad_flags_dict[bl][relab_dict2[2*t]] = v[::2]\n",
    "        if 2*t+1 in bin_idx2:\n",
    "            mad_flags_dict[bl][relab_dict2[2*t+1]] = v[1::2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "instrumental-disco",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn flags from MAD-clipping to ndarray\n",
    "RedG = md['redg']\n",
    "mad_flags = np.empty((len(idr2_jdsx), hd.Nfreqs, hd.Ntimes, RedG.shape[0]), dtype=bool)\n",
    "\n",
    "for i, bl_row in enumerate(RedG):\n",
    "    mad_flags[:, :, :, i] = np.moveaxis(np.array(list(mad_flags_dict[(*RedG[0][1:], pol)].values())), \\\n",
    "                                        [1, 2, 0], [0, 1, 2])\n",
    "mad_flags = mad_flags[:, chans, ...] # Channels 500-700, which include Band 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "floral-institution",
   "metadata": {},
   "outputs": [],
   "source": [
    "tot_flags = mad_flags + np.tile(idr2_flags[..., np.newaxis], RedG.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "serious-invalid",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('For HERA data over JDs {}, channels {}-{}, LASTs {:.3f}-{:.3f}, '\\\n",
    "      'excluding all those with bad antennas, there are {:,} visibilities, '\\\n",
    "      'of which {:,} are flagged from the calibration pipeline and manual flagging '\\\n",
    "      'and {:,} are flagged through MAD-clippnig.'\\\n",
    "      .format(idr2_jdsx, chans[0], chans[-1], lst_ref, lst_stop, tot_flags.size, \\\n",
    "              tot_flags.sum(), mad_flags.sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "computational-shipping",
   "metadata": {},
   "outputs": [],
   "source": [
    "tot_flags.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "enabling-accounting",
   "metadata": {},
   "outputs": [],
   "source": [
    "# With MAD-clipping\n",
    "tot_flags_d = np.all(tot_flags, axis=3)\n",
    "fig, ax = clipped_heatmap(tot_flags_d.sum(axis=0).transpose(), 'Time Integration', 'Channel', \\\n",
    "                          vmin=0, clip_pctile=100, figsize=(8, 5), xoffset=-chans[0], \\\n",
    "                          cbar_lab='No Flagged Days')\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "careful-israel",
   "metadata": {},
   "source": [
    "## Finding additional flags through xd_rel_cal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sporting-platform",
   "metadata": {},
   "source": [
    "### Negative log-likelihood histograms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "everyday-workplace",
   "metadata": {},
   "source": [
    "We look at the mininmum negative log-likelihood from across days redundant calibration $-\\ln(\\mathcal{L}^C_\\mathrm{xd\\_rel})$ solved using **xd_rel_cal**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "editorial-philippines",
   "metadata": {},
   "outputs": [],
   "source": [
    "nll_upper_cut = 2\n",
    "xd_rel_values = xd_df['fun'].values.astype(float)\n",
    "\n",
    "flgs_all = np.zeros_like(tot_flags_d[0, ...])\n",
    "flg_pct = 50 / 100\n",
    "flgs_all[np.where(tot_flags_d.mean(axis=0) > flg_pct)] = True # if 50% of days flagged\n",
    "flgs_all = flgs_all.ravel(order='F')\n",
    "\n",
    "flagged_hist(xd_rel_values, flgs_all, \\\n",
    "             xlabel=r'$-\\ln(\\mathcal{L}^C_\\mathrm{xd\\_rel})$', \\\n",
    "             lower_cut=0.1, upper_cut=nll_upper_cut, bin_width=0.02, hist_start=0, ylim=(0, 1500))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "crude-pasta",
   "metadata": {},
   "outputs": [],
   "source": [
    "sus_slices = np.where((xd_rel_values > 10) & ~flgs_all)[0]\n",
    "xd_df.index[sus_slices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "native-passion",
   "metadata": {},
   "outputs": [],
   "source": [
    "xd_rel_values[sus_slices]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "appreciated-refrigerator",
   "metadata": {},
   "source": [
    "This method can broadly tell us which slices (over days and baselines) have corrupted data, but forfeits the granularity of being able to flag specific day/channel/time/baseline slices, since it only explores data along the channel/time dimensions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accepting-making",
   "metadata": {},
   "source": [
    "### Calculating the NLLs had the minimization been done with Gaussian distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "induced-sociology",
   "metadata": {},
   "outputs": [],
   "source": [
    "if ndist == 'gaussian':\n",
    "    nll_dist = 'cauchy'\n",
    "if ndist == 'cauchy':\n",
    "    nll_dist = 'gaussian'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nervous-humanitarian",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_cols = [col for col in xd_df.columns.values if col.isdigit()]\n",
    "\n",
    "# Retrieve solved gains in array format\n",
    "xd_gains = xd_df[res_cols[no_unq_bls*2:]].values.reshape((Nfreqs, Ntints, md['JDs'].size, -1))\n",
    "xd_gains = np.moveaxis(xd_gains, [2, 0, 1, 3], [0, 1, 2, 3])\n",
    "y = xd_gains.reshape(xd_gains.shape[:3] + (md['no_ants'], -1, 2))\n",
    "xd_gains = np.squeeze(y[..., 0] + 1j*y[..., 1])\n",
    "\n",
    "# Retrieve solved visibilities in array format\n",
    "xd_vis = xd_df[res_cols[:no_unq_bls*2]].values.reshape((Nfreqs, Ntints, -1, 2))\n",
    "xd_vis = xd_vis[..., 0] + 1j*xd_vis[..., 1]\n",
    "xd_vis = np.tile(np.expand_dims(xd_vis, axis=0), (md['JDs'].size, 1, 1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "variable-automation",
   "metadata": {},
   "outputs": [],
   "source": [
    "if Ntints == md['Ntimes']:\n",
    "    tints = None\n",
    "if (md['JDs'] == idr2_jdsx).all():\n",
    "    jds = idr2_jdsx\n",
    "else:\n",
    "    jds = md['JDs']\n",
    "\n",
    "if os.path.exists(f'{DATAPATH}/test_idr2_cdata.npz'):\n",
    "    local_work = True\n",
    "    local_jd = 2458098.43869\n",
    "    if jd_time == local_jd:\n",
    "    # retrieve data locally\n",
    "        cdata = np.load(f'{DATAPATH}/test_idr2_cdata.npz')['arr_0']\n",
    "        cndata = np.load(f'{DATAPATH}/test_idr2_cndata.npz')['arr_0']\n",
    "    else:\n",
    "        raise Exception('Only H1C_IDR2 visibility data across JDs aligned with {} '\n",
    "                        'is available locally.'.format(local_jd))\n",
    "else:\n",
    "    _, _, cdata, cndata = XDgroup_data(jd_time, jds, pol, chans=chans, \\\n",
    "        tints=tints, bad_ants=True, use_flags='first', noise=True)\n",
    "    cdata = cdata.data\n",
    "\n",
    "cRedG = relabelAnts(RedG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "earned-georgia",
   "metadata": {},
   "outputs": [],
   "source": [
    "NLLFN = {'cauchy': lambda delta: np.log(1 + np.square(np.abs(delta))).sum(axis=(0, -1)),\n",
    "         'gaussian': lambda delta: np.square(np.abs(delta)).sum(axis=(0, -1))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "broke-gnome",
   "metadata": {},
   "outputs": [],
   "source": [
    "gvis = xd_vis[..., cRedG[:, 0]]*xd_gains[..., cRedG[:, 1]]*np.conj(xd_gains[..., cRedG[:, 2]])\n",
    "delta = cdata - gvis\n",
    "nlog_likelihood = NLLFN[nll_dist](delta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "formal-david",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = clipped_heatmap(nlog_likelihood.transpose(), ylabel='Time integration', \n",
    "                          clip_pctile=98, figsize=(8, 6), clip_rnd=100, xoffset=-chans[0])\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "referenced-vampire",
   "metadata": {},
   "source": [
    "### Residuals between solved visibilities and gain transformed observed visibilities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "female-translator",
   "metadata": {},
   "source": [
    "With across days redundant calibration, we obtain a single set of visibilities. We wish to compare these solved visibilities to the observed visibilities on different days, to find potential outliers. The amplitudes of these visibilities could be compared; their phases, however, cannot, since there are degenerate offsets between them.\n",
    "\n",
    "We do not wish to calculate these degenerate offsets, as this is computationally expensive - this would require doing pairs of comparison between the solved xd_rel_cal solutions and each day. What we can do, however, is take the observed visibilities and divide them by the solved gains to get a quantity that is comparable as it is degenerately consistent. The residual between this quantity and the true visibilities is what we use for outlier detection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "serious-stations",
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_vis = cdata / xd_gains[..., cRedG[:, 1]] / np.conj(xd_gains[..., cRedG[:, 2]])\n",
    "tr_res = xd_vis[..., cRedG[:, 0]] - tr_vis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "amino-engagement",
   "metadata": {},
   "source": [
    "#### Modified Z-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vital-carter",
   "metadata": {},
   "outputs": [],
   "source": [
    "correction = 1.4826\n",
    "mad = np.median(np.abs(tr_res), axis=0) # Median Absolute Deviation\n",
    "modz = np.abs(tr_res)/(correction*np.tile(np.expand_dims(mad, axis=0), \\\n",
    "                                          (md['JDs'].size, 1, 1, 1))) # Modified Z-score\n",
    "# Note that these quantities are about the solved visibility values, and not\n",
    "# about their medians"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bridal-vanilla",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_modz = np.mean(modz, axis=(0, -1)) # mean over days and baselines\n",
    "fig, ax = clipped_heatmap(mean_modz.transpose(), 'Time Integration', 'Channel', \\\n",
    "                          clip_pctile=99, figsize=(8, 5), xoffset=-chans[0])\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tough-parliament",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean modified Z-score, if looking at the mean mod-Z across baselines\n",
    "bad_slicesz = np.where(np.logical_and(modz.mean(axis=-1) > 0.8, ~tot_flags_d))\n",
    "print('{} potentially bad day/chan/time slices found that are not flagged through the '\\\n",
    "      'hera_cal pipeline, through modified Z-score considerations'.format(bad_slicesz[0].size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "oriental-quilt",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at individual baselines\n",
    "bad_slicesz_bl = np.where(np.logical_and(modz > 5, ~tot_flags))\n",
    "print('{} potentially bad day/chan/time/baseline slices found that are not flagged through the '\\\n",
    "      'hera_cal pipeline, through modified Z-score considerations'.format(bad_slicesz_bl[0].size))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nervous-stopping",
   "metadata": {},
   "source": [
    "$\\mathcal{R}_{\\mathrm{man}}$ already calculated above, but run on last baseline dimension too - should be similar results to modified Z-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "configured-hungary",
   "metadata": {},
   "outputs": [],
   "source": [
    "nrm_resid = norm_residuals(xd_vis[..., cRedG[:, 0]], tr_vis)\n",
    "abs_resid = np.median(np.abs(nrm_resid), axis=-1) # median over the baseline axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "responsible-underground",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_abs_resid = np.mean(abs_resid, axis=0) # mean over days\n",
    "vmin = np.nanpercentile(mean_abs_resid, 1)\n",
    "fig, ax = clipped_heatmap(mean_abs_resid.transpose(), 'Time Integration', 'Channel', \\\n",
    "                          clip_pctile=98, vmin=vmin, figsize=(8, 5), xoffset=-chans[0])\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "capital-aggregate",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "# Histograms of NLL/Noise, R_man to find outliers"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hera",
   "language": "python",
   "name": "hera"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

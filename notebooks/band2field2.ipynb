{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import sys\n",
    "import yaml\n",
    "from collections import OrderedDict as odict\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import ticker\n",
    "\n",
    "from hera_cal.io import HERAData\n",
    "from hera_cal.utils import LST2JD\n",
    "\n",
    "sys.path.insert(0, os.path.dirname(os.getcwd()))\n",
    "from align_utils import idr2_jdsx\n",
    "from plot_utils import clipped_heatmap\n",
    "from red_likelihood import relabelAnts\n",
    "from red_utils import calfits_to_flags, find_nearest, find_zen_file, match_lst\n",
    "from xd_utils import union_bad_ants, XDgroup_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xd_dir_path = '../xd_rel_dfs_nn'\n",
    "jd_time = 2458098.43869 # reference JD\n",
    "pol = 'ee'\n",
    "ndist = 'cauchy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hd = HERAData(find_zen_file(jd_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting channels, LASTs and datasets for Band 2 Field 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Band 2 Frequencies\n",
    "b2_freq_start = 150.3*1e6 # MHz\n",
    "b2_freq_stop = 167.8*1e6 # MHz\n",
    "band2_chans = np.where(np.logical_and(hd.freqs >= b2_freq_start, hd.freqs <= b2_freq_stop))[0]\n",
    "\n",
    "# Field 2 LASTs\n",
    "b2_lst_start = 4.5 # hours\n",
    "b2_lst_stop = 6.5 # hours\n",
    "\n",
    "# Convert to radians\n",
    "lst_start_rad = b2_lst_start * np.pi / 12\n",
    "lst_end_rad = b2_lst_stop * np.pi / 12\n",
    "\n",
    "# Match with dataset labels\n",
    "last_df = pd.read_pickle('../jd_lst_map_idr2.pkl')\n",
    "jd_start_match = find_nearest(last_df['JD_time'].values, LST2JD(lst_start_rad, int(jd_time)), \\\n",
    "                              condition='leq')[0]\n",
    "jd_end_match = find_nearest(last_df['JD_time'].values, LST2JD(lst_end_rad, int(jd_time)), \\\n",
    "                            condition='geq')[0]\n",
    "\n",
    "# Field 2 Datasets\n",
    "tocal = np.where(np.logical_and(last_df['JD_time'].loc[int(jd_time)].values >= jd_start_match, \\\n",
    "                                last_df['JD_time'].loc[int(jd_time)].values <= jd_end_match))\n",
    "field2_refs = last_df['JD_time'].loc[int(jd_time)].values[tocal]\n",
    "\n",
    "print('Band 2 channels are from {}-{} and Field 2 spans from LASTs {}-{}'\\\n",
    "      .format(band2_chans[0], band2_chans[-1], b2_lst_start, b2_lst_stop))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst_ref = last_df[last_df['JD_time'] == jd_time]['LASTs'].values[0][0]\n",
    "\n",
    "with open(os.path.join(xd_dir_path, 'xd_rel_df.{:.4f}.{}.md.pkl'.format(lst_ref, pol)), 'rb') as f:\n",
    "    md = pickle.load(f)\n",
    "    \n",
    "RedG = md['redg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jd_label_dict_fn = '../b2f2_jd_dict.npz'\n",
    "\n",
    "# Getting datasets for H1C_IDR2 JDs that are in Field 2\n",
    "jd_label_dict = {}\n",
    "for jd_ref in field2_refs:\n",
    "    jds = []\n",
    "    for jd in idr2_jdsx[1:]:\n",
    "        jda = str(match_lst(jd_ref, jd, tint=0))\n",
    "        jdb = str(match_lst(jd_ref, jd, tint=-1))\n",
    "        if len(jda) < 13:\n",
    "            jda = jda + '0'\n",
    "        if len(jdb) < 13:\n",
    "            jdb = jdb + '0'\n",
    "        jds.append([jda, jdb])\n",
    "    jd_label_dict[jd_ref] = jds\n",
    "    \n",
    "if not os.path.exists(jd_label_dict_fn):\n",
    "    np.savez(jd_label_dict_fn, jd_dict=jd_label_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building final flags array\n",
    "\n",
    "Final flags are the individual final calibration flags + the manual flags applied by Nick Kern + the MAD-clipping flags from LST-binning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calibration flags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cal_flags_fn = '../b2f2_cal_flags.npz'\n",
    "\n",
    "if os.path.exists(cal_flags_fn):\n",
    "    cal_flags = np.load(cal_flags_fn)['flags']\n",
    "\n",
    "else:\n",
    "    cal_file = 'smooth_abs'\n",
    "    for count, jd_ref in enumerate(field2_refs):\n",
    "\n",
    "        cal_flags_jd = np.zeros((len(idr2_jdsx), hd.Nfreqs, hd.Ntimes, RedG.shape[0]), dtype=bool)\n",
    "        cal_flags_jd[0, ...] = calfits_to_flags(jd_ref, cal_file, pol=pol, add_bad_ants=None)\n",
    "\n",
    "        jds = jd_label_dict[jd_ref]\n",
    "        lst_ref = last_df[last_df['JD_time'] == jd_ref]['LASTs'].values[0][0]\n",
    "        \n",
    "        for i, (JDa, JDb) in enumerate(jds):\n",
    "            flagsa = calfits_to_flags(JDa, cal_file, pol=pol, add_bad_ants=None)\n",
    "            flagsb = calfits_to_flags(JDb, cal_file, pol=pol, add_bad_ants=None)\n",
    "\n",
    "            last2 = last_df[last_df['JD_time'] == float(JDa)]['LASTs'].values[0]\n",
    "            _, offset = find_nearest(last2, lst_ref)\n",
    "\n",
    "            flagsc = np.concatenate((flagsa[:, offset:], flagsb[:, :offset]), axis=1)\n",
    "            cal_flags_jd[i+1, ...] = flagsc\n",
    "\n",
    "        if count == 0:\n",
    "            cal_flags = cal_flags_jd\n",
    "        else:\n",
    "            cal_flags = np.concatenate((cal_flags, cal_flags_jd), axis=2)\n",
    "            \n",
    "    np.savez_compressed(cal_flags_fn, flags=cal_flags, jds_refs=field2_refs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Nick Kern's manual flags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists('/lustre/aoc/projects/hera/H1C_IDR2/'):\n",
    "    nkern_flg_dir = '/lustre/aoc/projects/hera/H1C_IDR2/IDR2_2_pspec/v2/one_group/'\n",
    "    local_work = False\n",
    "else:\n",
    "    nkern_flg_dir = '/Users/matyasmolnar/Downloads/HERA_Data/robust_cal'\n",
    "    local_work = True\n",
    "\n",
    "nkern_flg_file = os.path.join(nkern_flg_dir, 'preprocess_params.yaml')\n",
    "\n",
    "# Read YAML file\n",
    "with open(nkern_flg_file, 'r') as stream:\n",
    "    data_loaded = yaml.safe_load(stream)\n",
    "    \n",
    "man_flags = np.concatenate([np.arange(i[0], i[1]+1) for i in \\\n",
    "                            data_loaded['algorithm']['fg_filt']['flag_chans']]).ravel()\n",
    "cal_flags[:, man_flags, :, :] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = clipped_heatmap(np.all(cal_flags, axis=3).sum(axis=0).transpose(), 'Time Integration', 'Channel', \\\n",
    "                          vmin=0, clip_pctile=100, figsize=(8, 5), xoffset=None, ybase=60,\\\n",
    "                          cbar_lab='# Flagged Days')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Restricting to Band 2\n",
    "cal_flags = cal_flags[:, band2_chans, :, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Getting MAD-clipping flags from LST-Binning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_span = []\n",
    "for jd_ref in field2_refs:\n",
    "    lst_ref = last_df[last_df['JD_time'] == jd_ref]['LASTs'].values[0][0]\n",
    "    last_span.append(lst_ref)\n",
    "last_span.append(last_df[last_df['JD_time'] == jd_ref]['LASTs'].values[0][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mad_flags_fn = '../b2f2_mad_flags.npz'\n",
    "\n",
    "if os.path.exists(mad_flags_fn):\n",
    "    mad_flags = np.load(mad_flags_fn)['flags']\n",
    "else:\n",
    "    mad_clip_dir = '/lustre/aoc/projects/hera/mmolnar/LST_bin/binned_files'\n",
    "    mad_flag_files = sorted(glob.glob(os.path.join(mad_clip_dir, 'zen.grp1.of1.LST.*.bad_jds.pkl')))\n",
    "    mad_flag_lsts = np.array(['.'.join(os.path.basename(fn).split('.')[4:6]) for fn in mad_flag_files])\n",
    "\n",
    "    to_open = []\n",
    "    for last in last_span:\n",
    "        clip_f_idx = find_nearest(mad_flag_lsts.astype(float), last, condition='leq')[1]\n",
    "        to_open.append(mad_flag_files[clip_f_idx])\n",
    "    to_open = sorted(list(set(to_open)))\n",
    "\n",
    "    bad_ants_idr2 = union_bad_ants(idr2_jdsx)\n",
    "    lst_binned_dir = '/lustre/aoc/projects/hera/H1C_IDR2/IDR2_2/LSTBIN/one_group/grp1'\n",
    "\n",
    "    for count, mad_clip_fn in enumerate(to_open):\n",
    "\n",
    "        with open(mad_clip_fn, 'rb') as f:\n",
    "            mad_flags_i = pickle.load(f)\n",
    "\n",
    "        mad_flags_i = {k: v for k, v in mad_flags_i.items() if \\\n",
    "                       k[0] != k[1] and k[2] == 'ee'} # flt autos and pol\n",
    "        mad_flags_i = {k: v for k, v in mad_flags_i.items() if \\\n",
    "                       not any(i in bad_ants_idr2 for i in k[:2])} # flt bad ants\n",
    "\n",
    "        mad_flags_dict_i = odict()\n",
    "        for bl in mad_flags_i.keys():\n",
    "            mad_flags_dict_i[bl] = odict()\n",
    "            for t, v in mad_flags_i[bl].items():\n",
    "                mad_flags_dict_i[bl][2*t] = v[::2]\n",
    "                mad_flags_dict_i[bl][2*t+1] = v[1::2]\n",
    "\n",
    "        # Turn flags from MAD-clipping to ndarray\n",
    "        mad_flags_arr_i = np.empty((len(idr2_jdsx), hd.Nfreqs, hd.Ntimes*2, RedG.shape[0]), dtype=bool)\n",
    "\n",
    "        for i, bl_row in enumerate(RedG):\n",
    "            mad_flags_arr_i[:, :, :, i] = np.moveaxis(np.array(list(mad_flags_dict_i[(*RedG[0][1:], pol)]\\\n",
    "                                              .values())), [1, 2, 0], [0, 1, 2])\n",
    "        mad_flags_arr_i = mad_flags_arr_i[:, band2_chans, ...]\n",
    "\n",
    "\n",
    "        if count == 0 or count == len(to_open) - 1:\n",
    "            \n",
    "            mad_flag_lst = '.'.join(os.path.basename(mad_clip_fn).split('.')[4:6])\n",
    "            lst_binned_file = os.path.join(lst_binned_dir, 'zen.grp1.of1.LST.{}.HH.OCRSL.uvh5'.\\\n",
    "                                   format(mad_flag_lst))\n",
    "            hd_lstb_i = HERAData(lst_binned_file)\n",
    "\n",
    "            if count == 0:\n",
    "                # Selecting first LAST\n",
    "                lst_ref_i = HERAData(find_zen_file(field2_refs[0])).lsts[0]\n",
    "            else:\n",
    "                # Selecting last LAST\n",
    "                lst_ref_i = HERAData(find_zen_file(field2_refs[-1])).lsts[-1]\n",
    "\n",
    "            bin_lsts = np.sort(np.append(hd_lstb_i.lsts, hd_lstb_i.lsts + \\\n",
    "                                         np.median(np.ediff1d(hd_lstb_i.lsts))/2))\n",
    "            adj_idx = find_nearest(bin_lsts, lst_ref_i, condition=None)[1]\n",
    "\n",
    "            if count == 0:\n",
    "                # Slicing s.t. times are aligned with those from field2_refs[0]\n",
    "                mad_flags = mad_flags_arr_i[:, :, adj_idx:, :]\n",
    "            else:\n",
    "                # Slicing s.t. times do not go beyond those in field2_refs[-1]\n",
    "                mad_flags_arr_i = mad_flags_arr_i[:, :, :adj_idx+1, :]\n",
    "\n",
    "        if count != 0:\n",
    "            mad_flags = np.concatenate((mad_flags, mad_flags_arr_i), axis=2)\n",
    "            \n",
    "    np.savez_compressed(mad_flags_fn, flags=mad_flags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tot_flags = cal_flags + mad_flags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting raw visibility data and xd_rel_cal solutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasts_b2 = []\n",
    "for jd_ref in field2_refs:\n",
    "    lasts_b2.append(last_df[last_df['JD_time'] == jd_ref]['LASTs'].values[0])\n",
    "lasts_b2 = np.array(lasts_b2).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis_data_fn = '../b2f2_vis_data.npz'\n",
    "\n",
    "if os.path.exists(vis_data_fn):\n",
    "    cdata = np.load(vis_data_fn)['data']\n",
    "else:\n",
    "    # this will take a while... run on cluster\n",
    "    for count, jd_ref in enumerate(field2_refs):\n",
    "        _, _, cdata_i, _ = XDgroup_data(jd_ref, idr2_jdsx, pol, chans=band2_chans, \\\n",
    "            tints=None, bad_ants=True, use_flags='first', noise=True)\n",
    "        cdata_i = cdata_i.data\n",
    "        \n",
    "        if count == 0:\n",
    "            cdata = cdata_i\n",
    "        else:\n",
    "            cdata = np.concatenate((cdata, cdata_i), axis=2)\n",
    "            \n",
    "    np.savez_compressed(vis_data_fn, data=cdata, jds_refs=field2_refs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for count, jd_ref in enumerate(field2_refs):\n",
    "\n",
    "    lst_ref = last_df[last_df['JD_time'] == jd_ref]['LASTs'].values[0][0]\n",
    "    xd_df_path = os.path.join(xd_dir_path, 'xd_rel_df.{:.4f}.{}.{}.pkl'.format(lst_ref, pol, ndist))\n",
    "\n",
    "    xd_df_i = pd.read_pickle(xd_df_path)\n",
    "    \n",
    "    if count == 0:\n",
    "        xd_df = xd_df_i\n",
    "    else:\n",
    "        xd_df_i.reset_index(level='time_int', inplace=True)\n",
    "        xd_df_i['time_int'] += 60*count\n",
    "        xd_df_i.set_index('time_int', append=True, inplace=True)\n",
    "        \n",
    "        xd_df = pd.concat([xd_df, xd_df_i])\n",
    "        \n",
    "xd_df.sort_index(inplace=True)\n",
    "xd_df = xd_df[xd_df.index.get_level_values(level='freq').isin(band2_chans)]\n",
    "\n",
    "chans = xd_df.index.get_level_values(level='freq').unique().values\n",
    "tints = xd_df.index.get_level_values(level='time_int').unique().values\n",
    "\n",
    "Nfreqs = chans.size\n",
    "Ntints = tints.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_cols = [col for col in xd_df.columns.values if col.isdigit()]\n",
    "\n",
    "# Retrieve solved gains in array format\n",
    "xd_gains = xd_df[res_cols[md['no_unq_bls']*2:]].values.reshape((Nfreqs, Ntints, md['JDs'].size, -1))\n",
    "xd_gains = np.moveaxis(xd_gains, [2, 0, 1, 3], [0, 1, 2, 3])\n",
    "y = xd_gains.reshape(xd_gains.shape[:3] + (md['no_ants'], -1, 2))\n",
    "xd_gains = np.squeeze(y[..., 0] + 1j*y[..., 1])\n",
    "\n",
    "# Retrieve solved visibilities in array format\n",
    "xd_vis = xd_df[res_cols[:md['no_unq_bls']*2]].values.reshape((Nfreqs, Ntints, -1, 2))\n",
    "xd_vis = xd_vis[..., 0] + 1j*xd_vis[..., 1]\n",
    "xd_vis = np.tile(np.expand_dims(xd_vis, axis=0), (md['JDs'].size, 1, 1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking data consistency:\n",
    "print(tot_flags.shape)\n",
    "print(cdata.shape)\n",
    "print((md['JDs'].size, Nfreqs, Ntints))\n",
    "print(xd_gains.shape)\n",
    "print(xd_vis.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transforming visibilities to comparable quantities, s.t. statistics can be done on them\n",
    "cRedG = relabelAnts(RedG)\n",
    "tr_vis = cdata / xd_gains[..., cRedG[:, 1]] / np.conj(xd_gains[..., cRedG[:, 2]])\n",
    "tr_res = xd_vis[..., cRedG[:, 0]] - tr_vis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modifiez Z-score clipping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correction = 1.4826\n",
    "mad = np.median(np.abs(tr_res), axis=0) # Median Absolute Deviation\n",
    "modz = np.abs(tr_res)/(correction*np.tile(np.expand_dims(mad, axis=0), \\\n",
    "                                          (md['JDs'].size, 1, 1, 1))) # Modified Z-score\n",
    "# Note that these quantities are about the solved visibility values, and not\n",
    "# about their medians"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at individual baselines\n",
    "bad_slicesz_bl = np.where(np.logical_and(modz > 5, ~tot_flags))\n",
    "print('{} potentially bad day/chan/time/baseline slices found that are not flagged through the '\\\n",
    "      'hera_cal pipeline, through modified Z-score considerations'.format(bad_slicesz_bl[0].size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modz_fn = '../b2f2_mz_flags.npz'\n",
    "if not os.path.exists(modz_fn):\n",
    "    np.savez_compressed(modz_fn, modz=modz, simga4=modz > 4, simga5=modz > 5, simga6=modz > 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tot_flags = tot_flags + (modz > 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final flags to be carried through to LST-binning\n",
    "tot_flags_fn = '../b2f2_tot_flags.npz'\n",
    "if not os.path.exists(tot_flags_fn):\n",
    "    np.savez_compressed(tot_flags_fn, flags=tot_flags)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

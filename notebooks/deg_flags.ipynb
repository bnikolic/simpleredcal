{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "import sys\n",
    "from operator import itemgetter\n",
    "\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from astropy.stats import sigma_clip\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import ticker\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "from scipy.signal import savgol_filter\n",
    "from statsmodels.nonparametric.kernel_regression import KernelReg\n",
    "\n",
    "from hera_cal.io import HERAData\n",
    "\n",
    "sys.path.insert(0, os.path.dirname(os.getcwd()))\n",
    "from fit_diagnostics import abs_residuals\n",
    "from plot_utils import arr_pcmesh, clipped_heatmap, flagged_hist, plot_res_heatmap\n",
    "from red_likelihood import fltBad, get_reds, group_data, makeCArray\n",
    "from red_utils import calfits_to_flags, find_deg_df, find_flag_file, find_nearest, \\\n",
    "find_rel_df, find_zen_file, get_bad_ants, JD2LSTPATH, match_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "\n",
    "plot_figs = False\n",
    "if plot_figs:\n",
    "    mpl.rcParams['figure.dpi'] = 300\n",
    "\n",
    "mpl.rc('font',**{'family':'serif','serif':['cm']})\n",
    "mpl.rc('text', usetex=True)\n",
    "mpl.rc('text.latex', preamble=r'\\usepackage{amssymb} \\usepackage{amsmath}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "JD1 = 2458098.43869\n",
    "JD_comp = 2458099\n",
    "\n",
    "pol = 'ee'\n",
    "n_dist = 'gaussian'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting final flags from smooth_abs calfits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "JD2 = match_lst(JD1, JD_comp, tint=0)\n",
    "JD3 = match_lst(JD1, JD_comp, tint=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "band_edge = 50 # frequency channels to cut\n",
    "add_ba = 14 # additional bad antennas\n",
    "cal_file = 'smooth_abs'\n",
    "\n",
    "flags1 = np.mean(calfits_to_flags(JD1, cal_file, pol=pol, add_bad_ants=add_ba), \\\n",
    "                 axis=2).astype(int)[band_edge:-band_edge, :]\n",
    "flags2 = np.mean(calfits_to_flags(JD2, cal_file, pol=pol, add_bad_ants=add_ba), \\\n",
    "                 axis=2).astype(int)[band_edge:-band_edge, :]\n",
    "flags3 = np.mean(calfits_to_flags(JD3, cal_file, pol=pol, add_bad_ants=add_ba), \\\n",
    "                 axis=2).astype(int)[band_edge:-band_edge, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aligning flags on JD_comp wit those on JD1 in LAST\n",
    "\n",
    "last_df = pd.read_pickle(JD2LSTPATH)\n",
    "last1 = last_df[last_df['JD_time'] == JD1]['LASTs'].values[0]\n",
    "last2 = last_df[last_df['JD_time'] == JD2]['LASTs'].values[0]\n",
    "_, offset = find_nearest(last2, last1[0])\n",
    "\n",
    "flagsc = np.concatenate((flags2[:, offset:], flags3[:, :offset]), axis=1) * 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flagsf = flags1 + flagsc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define colors\n",
    "colors = ((1.0, 1.0, 1.0), 'C2', 'C10', (1., 0., 0.))\n",
    "cmap = LinearSegmentedColormap.from_list('Custom', colors, len(colors))\n",
    "\n",
    "fig, ax = arr_pcmesh(np.arange(1024)[band_edge:-band_edge], np.arange(60), flagsf.T, cmap=cmap, \\\n",
    "    xlabel='Frequency Channel', ylabel='Time Integration', clabel='Flags', \\\n",
    "    xlim=(0, 1023), rtn_fig_ax=True)\n",
    "\n",
    "cbar = ax.collections[0].colorbar\n",
    "cbar.set_ticks(np.array([0., 0.75, 1.5, 2.25]) + 0.375)\n",
    "cbar.set_ticklabels(['False', '98', '99', 'Both'])\n",
    "\n",
    "fig.tight_layout()\n",
    "# save_fig_dir = '/Users/matyasmolnar/Desktop/Thesis/CHAP-4/FIGS'\n",
    "# plt.savefig(os.path.join(save_fig_dir, '2458098_99_OCRSD_ee_flags.pdf'), bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Negative log-likelihood histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deg_df_path = '../deg_dfs'\n",
    "rel_df_path = '../rel_dfs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deg_df_j = find_deg_df(JD1, pol, 'jd', n_dist, dir=deg_df_path)\n",
    "df_j = pd.read_pickle(deg_df_j)\n",
    "Nfreqs = df_j.index.get_level_values('freq').unique().size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flagsr = flagsf.ravel(order='F').astype(int).astype(bool)\n",
    "deg_values = df_j['fun'].values.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nll_upper_cut = 0.009\n",
    "flagged_hist(deg_values, flagsr, xlabel=r'$-\\ln(\\mathcal{L}^G_\\mathrm{deg})$', lower_cut=None, \\\n",
    "             upper_cut=nll_upper_cut, bin_width=0.0002, hist_start=0, ylim=(0, 7000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nll_suspect_slices = []\n",
    "for i, n in enumerate(deg_values):\n",
    "    if ~flagsr[i]:\n",
    "        if n > nll_upper_cut:\n",
    "            nll_suspect_slices.append(df_j.index.values[i] + (i, n))\n",
    "print(*nll_suspect_slices, sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Median absolute normalized residual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_j[['med_abs_norm_res_Re', 'med_abs_norm_res_Im']] = df_j.apply(lambda row: \\\n",
    "pd.Series(abs_residuals(row['norm_residual'])), axis=1)\n",
    "\n",
    "df_j['med_abs_norm_res_comb'] = np.sqrt((df_j['med_abs_norm_res_Re']**2 + \\\n",
    "                                        df_j['med_abs_norm_res_Im']**2).values)\n",
    "\n",
    "rman_values = df_j['med_abs_norm_res_comb'].values.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rman_upper_cut = 0.2\n",
    "flagged_hist(rman_values, flagsr, xlabel=r'$\\mathcal{R}_{\\mathrm{man}}$', lower_cut=None, \\\n",
    "             upper_cut=rman_upper_cut, bin_width=0.0025, hist_start=0, ylim=(0, 3000), figsize=(6,6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rman_suspect_slices = []\n",
    "for i, n in enumerate(rman_values):\n",
    "    if ~flagsr[i]:\n",
    "        if n > rman_upper_cut:\n",
    "            rman_suspect_slices.append(df_j.index.values[i] + (i, n))\n",
    "print(*rman_suspect_slices, sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_res_heatmap(df_j, 'fun', index='time_int1', columns='freq', clip=True, clip_pctile=95, vmin=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize negative log-likelihoods by visibility amplitude mean/median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_res_heatmap(df_j, 'fun', index='time_int1', columns='freq', clip=True, clip_pctile=95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rel_df_j = pd.read_pickle(find_rel_df(JD1, pol, n_dist, dir=rel_df_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join('../rel_dfs', 'rel_df.{}.{}.md.pkl'.format(JD1, pol)), 'rb') as f:\n",
    "    md = pickle.load(f)\n",
    "\n",
    "no_unq_bls = md['no_unq_bls']\n",
    "no_min_p = 5 # number of columns in df that are attributes of the SciPy OptimizeResult \n",
    "vis_df = rel_df_j.iloc[:, no_min_p:no_unq_bls*2+no_min_p]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis_df['vamp_mean'] = vis_df.apply(lambda row: \\\n",
    "                      np.mean(np.abs(makeCArray(row[:no_unq_bls*2].values.astype(float)))), \\\n",
    "                      axis=1)\n",
    "\n",
    "vis_df['vamp_median'] = vis_df.apply(lambda row: \\\n",
    "                        np.median(np.abs(makeCArray(row[:no_unq_bls*2].values.astype(float)))), \\\n",
    "                        axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rel_df_j2a = pd.read_pickle(find_rel_df(JD2, pol, n_dist, dir=rel_df_path))\n",
    "rel_df_j2b = pd.read_pickle(find_rel_df(JD3, pol, n_dist, dir=rel_df_path))\n",
    "\n",
    "Nfreqs = rel_df_j.index.get_level_values('freq').unique().size\n",
    "Ntints = rel_df_j.index.get_level_values('time_int').unique().size\n",
    "\n",
    "indices = ['freq', 'time_int']\n",
    "rel_df_j2a = rel_df_j2a[rel_df_j2a.index.get_level_values('time_int') >= offset]\n",
    "rel_df_j2a.reset_index(inplace=True)\n",
    "rel_df_j2a['time_int'] = np.tile(np.arange(Ntints - offset), Nfreqs)\n",
    "rel_df_j2a.set_index(indices, inplace=True)\n",
    "\n",
    "rel_df_j2b = rel_df_j2b[rel_df_j2b.index.get_level_values('time_int') < offset]\n",
    "rel_df_j2b.reset_index(inplace=True)\n",
    "rel_df_j2b['time_int'] = np.tile(np.arange(Ntints - offset, Ntints), Nfreqs)\n",
    "rel_df_j2b.set_index(indices, inplace=True)\n",
    "\n",
    "rel_df_j2 = pd.concat([rel_df_j2a, rel_df_j2b])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis_df2 = rel_df_j2.iloc[:, no_min_p:no_unq_bls*2+no_min_p]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis_df2['vamp_mean'] = vis_df2.apply(lambda row: \\\n",
    "                       np.mean(np.abs(makeCArray(row[:no_unq_bls*2].values.astype(float)))), \\\n",
    "                       axis=1)\n",
    "\n",
    "vis_df2['vamp_median'] = vis_df2.apply(lambda row: \\\n",
    "                         np.median(np.abs(makeCArray(row[:no_unq_bls*2].values.astype(float)))), \\\n",
    "                         axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis_df['vamp_mean_xdmean'] = (vis_df['vamp_mean'] + vis_df2['vamp_mean']) / 2\n",
    "vis_df['vamp_median_xdmean'] = (vis_df['vamp_median'] + vis_df2['vamp_median']) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_res_heatmap(vis_df, 'vamp_mean_xdmean', clip=True, clip_pctile=97)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_res_heatmap(vis_df, 'vamp_median_xdmean', clip=True, clip_pctile=97)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis_df.reset_index(inplace=True)\n",
    "vis_df.rename(columns={'time_int': 'time_int1'}, inplace=True)\n",
    "vis_df.set_index(['time_int1', 'freq'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_j['mean_nrm_nll'] = df_j['fun'] / vis_df['vamp_mean']**2\n",
    "df_j['median_nrm_nll'] = df_j['fun'] / vis_df['vamp_median']**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_res_heatmap(df_j, 'mean_nrm_nll', index='time_int1', columns='freq', clip=True, clip_pctile=97)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_res_heatmap(df_j, 'median_nrm_nll', index='time_int1', columns='freq', clip=True, clip_pctile=97)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_nrm_nll = df_j['mean_nrm_nll'].values.astype(float)\n",
    "median_nrm_nll = df_j['median_nrm_nll'].values.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vamp_mean_nrm_nll_upper_cut = 25\n",
    "flagged_hist(mean_nrm_nll, flagsr, xlabel=r'$-\\ln(\\mathcal{L}^G_\\mathrm{deg}) \\; / \\; \\overline{\\left| V_\\mathrm{obs} \\right|}$', \\\n",
    "             lower_cut=None, upper_cut=vamp_mean_nrm_nll_upper_cut, bin_width=0.5, hist_start=0, ylim=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vamp_med_nrm_nll_upper_cut = 8\n",
    "flagged_hist(median_nrm_nll, flagsr, xlabel=r'$-\\ln(\\mathcal{L}^G_\\mathrm{deg}) \\; / \\; \\mathrm{med} \\left( \\left| V_\\mathrm{obs} \\right| \\right)$', lower_cut=None, \\\n",
    "             upper_cut=vamp_med_nrm_nll_upper_cut, bin_width=0.1, hist_start=0, ylim=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vamp_med_suspect_slices = []\n",
    "for i, n in enumerate(median_nrm_nll):\n",
    "    if ~flagsr[i]:\n",
    "        if n > vamp_med_nrm_nll_upper_cut:\n",
    "            vamp_med_suspect_slices.append(df_j.index.values[i] + (n,))\n",
    "print(*vamp_med_suspect_slices, sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalizing by smoothed noise from autocorrelations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load inferred noise on data\n",
    "local_dir = '/Users/matyasmolnar/Downloads/HERA_Data/sample_data'\n",
    "if os.path.exists(local_dir):\n",
    "    noise_dir = local_dir\n",
    "else:\n",
    "    noise_dir = '/lustre/aoc/projects/hera/H1C_IDR2/IDR2_2/{}'.format(int(JD1))\n",
    "noise_file = os.path.join(noise_dir, 'zen.{}.HH.noise_std.uvh5'.format(JD1))\n",
    "hd_noise = HERAData(noise_file)\n",
    "noise, noise_flags, _ = hd_noise.read(polarizations=[pol])\n",
    "RedG = md['redg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bl_var = np.empty((RedG.shape[0], md['Ntimes'], md['Nfreqs']), dtype=complex)\n",
    "for i in range(bl_var.shape[0]):\n",
    "    bl_var[i, ...] = noise[(int(RedG[i, 1]), int(RedG[i, 1]), pol)] * \\\n",
    "                     noise[(int(RedG[i, 2]), int(RedG[i, 2]), pol)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def arr_heatmap(arr, clip_pctile=97, clip_rnd=100, sci_format=False, retn_vmax=False):\n",
    "    fig, ax, vmin, vmax = clipped_heatmap(arr, 'time_int', xlabel='freq', figsize=(11,7), \\\n",
    "                              clip_pctile=clip_pctile, vmin=0, clip_rnd=clip_rnd, \\\n",
    "                              sci_format=sci_format, retn_vlims=True)\n",
    "    ax.xaxis.set_major_formatter(ticker.ScalarFormatter(useOffset=-band_edge))\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    if retn_vmax:\n",
    "        return vmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.absolute(bl_var.mean(axis=0))[:, band_edge:-band_edge]\n",
    "arr_heatmap(arr, clip_pctile=92)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_nrm_nll = df_j['fun'].values.astype(float) / arr.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = noise_nrm_nll.reshape((md['Ntimes'], Nfreqs))\n",
    "vmax = arr_heatmap(arr, clip_pctile=95, clip_rnd=1e4, sci_format=True, retn_vmax=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flagged_hist(noise_nrm_nll, flagsr, xlabel=r'$-\\ln(\\mathcal{L}^G_\\mathrm{deg}) \\; / \\; \\sigma_{98}^2$', \\\n",
    "             lower_cut=None, upper_cut=vmax, bin_width=None, hist_start=0, ylim=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_nrm_98_suspect_slices = []\n",
    "for i, n in enumerate(noise_nrm_nll):\n",
    "    if ~flagsr[i]:\n",
    "        if n > vmax:\n",
    "            noise_nrm_98_suspect_slices.append(df_j.index.values[i] + (n,))\n",
    "print(*noise_nrm_98_suspect_slices, sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load inferred noise on data from 2nd dataset\n",
    "if not os.path.exists(local_dir):\n",
    "    noise_dir = '/lustre/aoc/projects/hera/H1C_IDR2/IDR2_2/{}'.format(int(JD2))\n",
    "\n",
    "noise_file = os.path.join(noise_dir, 'zen.{}.HH.noise_std.uvh5'.format(JD2))\n",
    "hd_noise = HERAData(noise_file)\n",
    "noise, _, _ = hd_noise.read(polarizations=[pol])\n",
    "\n",
    "bl_var2a = np.empty((RedG.shape[0], md['Ntimes'], md['Nfreqs']), dtype=complex)\n",
    "for i in range(bl_var2a.shape[0]):\n",
    "    bl_var2a[i, ...] = noise[(int(RedG[i, 1]), int(RedG[i, 1]), pol)] * \\\n",
    "                       noise[(int(RedG[i, 2]), int(RedG[i, 2]), pol)]\n",
    "    \n",
    "noise_file = os.path.join(noise_dir, 'zen.{}.HH.noise_std.uvh5'.format(JD3))\n",
    "hd_noise = HERAData(noise_file)\n",
    "noise, _, _ = hd_noise.read(polarizations=[pol])\n",
    "\n",
    "bl_var2b = np.empty((RedG.shape[0], md['Ntimes'], md['Nfreqs']), dtype=complex)\n",
    "for i in range(bl_var2b.shape[0]):\n",
    "    bl_var2b[i, ...] = noise[(int(RedG[i, 1]), int(RedG[i, 1]), pol)] * \\\n",
    "                       noise[(int(RedG[i, 2]), int(RedG[i, 2]), pol)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bl_var2 = np.concatenate((bl_var2a[:, offset:, :], bl_var2a[:, :offset, :]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bl_varca = (bl_var + bl_var2) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hd = HERAData(find_zen_file(JD1))\n",
    "reds = fltBad(get_reds(hd.antpos, pols=[pol]), get_bad_ants(find_zen_file(JD_time=JD1)))\n",
    "bl_types = RedG[:, 0]\n",
    "slct_bl_type_id = 2 # 14 m EW baselines\n",
    "slct_bl_type = reds[slct_bl_type_id][0]\n",
    "print(slct_bl_type) # 14 m EW baselines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ew_14_bls = np.where(RedG[:, 0] == slct_bl_type_id)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bl_varcr = bl_varca[ew_14_bls, ...] # selecting only 14m EW baselines\n",
    "bl_varcr = np.mean(np.abs(bl_varcr), axis=0) # average over 14m EW baselines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nan_helper(y):\n",
    "    return np.isnan(y), lambda z: z.nonzero()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bl_varc = np.empty_like(bl_varcr)\n",
    "for i in range(bl_varcr.shape[1]):\n",
    "    bl_varc[:, i] = sigma_clip(bl_varcr[:, i], sigma=4, cenfunc='median').filled(fill_value=np.nan)\n",
    "    nans, x = nan_helper(bl_varc[:, i])\n",
    "    bl_varc[:, i][nans]= np.interp(x(nans), x(~nans), bl_varc[:, i][~nans])\n",
    "    \n",
    "# Savitzky-Golay filter\n",
    "for i in range(bl_varc.shape[1]):\n",
    "    bl_varc[:, i] = savgol_filter(bl_varc[:, i], window_length=17, polyorder=3, mode='interp')\n",
    "    \n",
    "bl_varc[bl_varc < 0] = 1e-8 # zero pad bottom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_freq = 381\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.plot(bl_varcr[:, test_freq])\n",
    "ax.plot(bl_varc[:, test_freq])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_tint = 30\n",
    "clf = KernelReg(bl_varc[test_tint, :], np.arange(hd.Nfreqs), var_type='c', reg_type='ll', bw = 'cv_ls')\n",
    "y_pred = clf.fit()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fff = np.append(np.zeros(band_edge), np.append(flagsf[:, test_tint], np.zeros(band_edge))).astype(bool)\n",
    "mf = np.ma.masked_array(bl_varcr[test_tint, :], fff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.plot(bl_varcr[test_tint, :])\n",
    "ax.plot(mf)\n",
    "ax.plot(y_pred)\n",
    "\n",
    "ax.set_ylim((0, 300))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.absolute(bl_varca.mean(axis=0))[:, band_edge:-band_edge]\n",
    "arr_heatmap(arr, clip_pctile=93)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snoise_arr = np.absolute(bl_varc)[:, band_edge:-band_edge]\n",
    "arr_heatmap(snoise_arr, clip_pctile=93)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_nrm_nll = df_j['fun'].values.astype(float) / snoise_arr.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = noise_nrm_nll.reshape((md['Ntimes'], Nfreqs))\n",
    "arr_heatmap(arr, clip_pctile=95, clip_rnd=1e4, sci_format=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_nrm_upper_cut = 9.8e-5\n",
    "flagged_hist(noise_nrm_nll, flagsr, xlabel=r'$-\\ln(\\mathcal{L}^G_\\mathrm{deg}) \\; / \\; \\sigma_{14m}^2 $', \\\n",
    "             lower_cut=None, upper_cut=noise_nrm_upper_cut, bin_width=vmax/50, hist_start=0, logy=False, \\\n",
    "             ylim=None, figsize=(6, 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_nrm_suspect_slices = []\n",
    "for i, n in enumerate(noise_nrm_nll):\n",
    "    if ~flagsr[i]:\n",
    "        if n > noise_nrm_upper_cut:\n",
    "            tint, freq = df_j.index.values[i]\n",
    "            noise_nrm_suspect_slices.append(df_j.index.values[i] + \\\n",
    "                (i, n, rman_values[i], deg_values[i], snoise_arr.ravel()[i],))\n",
    "            \n",
    "rman_adj_slices = []\n",
    "for i in rman_suspect_slices:\n",
    "    i = i[:3] + (noise_nrm_nll[i[2]], i[3], deg_values[i[2]], snoise_arr.ravel()[i[2]],)\n",
    "    rman_adj_slices.append(i)            \n",
    "            \n",
    "noise_nrm_suspect_slices += rman_adj_slices\n",
    "outliers = sorted(noise_nrm_suspect_slices, key=itemgetter(1))\n",
    "print(*outliers, sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outlier detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis_list = list(map(str, np.arange(md['no_unq_bls']*2).tolist()))\n",
    "\n",
    "visC_df = vis_df[vis_list].apply(lambda row: makeCArray(row.values), axis=1)\n",
    "visC_df = pd.DataFrame(visC_df.values.tolist(), index=visC_df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def outlier_heatmap(arr, vmin=0, vmax=None, clip_pctile=98, cmap=sns.cm.rocket_r, center=None):\n",
    "    fig, ax = plt.subplots(figsize=(11, 7))\n",
    "    if vmax is None:\n",
    "        vmax = np.ceil(np.nanpercentile(arr, clip_pctile)*10000)/10000\n",
    "    ax = sns.heatmap(arr, vmax=vmax, vmin=vmin, cmap=cmap, center=center)\n",
    "    ax.xaxis.set_major_locator(ticker.MultipleLocator(50))\n",
    "    ax.xaxis.set_major_formatter(ticker.ScalarFormatter(useOffset=-band_edge))\n",
    "    ax.yaxis.set_major_locator(ticker.MultipleLocator(5))\n",
    "    ax.yaxis.set_major_formatter(ticker.ScalarFormatter())\n",
    "    ax.set_xlabel('freq')\n",
    "    ax.set_ylabel('time_int')\n",
    "\n",
    "    # scale ellipse to appear as a circle\n",
    "    circ_height = 2\n",
    "    width = circ_height * Nfreqs/md['Ntimes'] * 8 / 11\n",
    "\n",
    "    for suspect in outliers:\n",
    "        circle = matplotlib.patches.Ellipse((suspect[1]+0.5, suspect[0]+0.5), width, circ_height, \\\n",
    "                                             color='cyan', fill=False, lw=1.3)\n",
    "        ax.add_patch(circle)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def outlier_pcmesh(arr, vmin=0, vmax=None, clip_pctile=98, cmap=sns.cm.rocket_r, \\\n",
    "                   clabel=None, c_extend=None, sc_color='cyan', savefig=None, dpi=125):\n",
    "\n",
    "    if vmax is None:\n",
    "        vmax = np.ceil(np.nanpercentile(arr, clip_pctile)*10000)/10000\n",
    "        \n",
    "    fig, ax = arr_pcmesh(np.arange(hd.Nfreqs)[band_edge:-band_edge],np.arange(hd.Ntimes), arr, cmap=cmap, \\\n",
    "        xlabel='Frequency Channel', ylabel='Time Integration', clabel=clabel, vmax=vmax, \\\n",
    "        xlim=(0, 1023), rtn_fig_ax=True)\n",
    "\n",
    "    for suspect in outliers:\n",
    "        ax.scatter(suspect[1]+band_edge, suspect[0], s=100, fc='None', edgecolors=sc_color, lw=1, ls='-')\n",
    "\n",
    "    fig.tight_layout()\n",
    "    if savefig is not None:\n",
    "        plt.savefig(savefig, bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visC_14ewabs = visC_df[2].abs().values.reshape((Nfreqs, md['Ntimes'])).transpose()\n",
    "\n",
    "outlier_pcmesh(visC_14ewabs, vmin=0, vmax=0.06, clabel=r'$|V|$', c_extend='max', savefig=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visC_14ewangle = np.angle(visC_df[2].values).reshape((Nfreqs, md['Ntimes'])).transpose()\n",
    "\n",
    "outlier_pcmesh(visC_14ewangle, vmin=n-np.pi, vmax=np.pi, clabel=r'$\\varphi$', cmap='PiYG', \\\n",
    "               sc_color='darkorange')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rel_df_j2a = pd.read_pickle(find_rel_df(JD2, pol, n_dist, dir=rel_df_path))\n",
    "rel_df_j2b = pd.read_pickle(find_rel_df(JD3, pol, n_dist, dir=rel_df_path))\n",
    "\n",
    "Nfreqs = rel_df_j.index.get_level_values('freq').unique().size\n",
    "Ntints = rel_df_j.index.get_level_values('time_int').unique().size\n",
    "\n",
    "indices = ['freq', 'time_int']\n",
    "rel_df_j2a = rel_df_j2a[rel_df_j2a.index.get_level_values('time_int') >= offset]\n",
    "rel_df_j2a.sort_index()\n",
    "rel_df_j2a.reset_index(inplace=True)\n",
    "rel_df_j2a['time_int'] = np.tile(np.arange(Ntints - offset), Nfreqs)\n",
    "rel_df_j2a.set_index(indices, inplace=True)\n",
    "\n",
    "rel_df_j2b = rel_df_j2b[rel_df_j2b.index.get_level_values('time_int') < offset]\n",
    "rel_df_j2b.sort_index()\n",
    "rel_df_j2b.reset_index(inplace=True)\n",
    "rel_df_j2b['time_int'] = np.tile(np.arange(Ntints - offset, Ntints), Nfreqs)\n",
    "rel_df_j2b.set_index(indices, inplace=True)\n",
    "\n",
    "# rel_df_j2 = pd.concat([rel_df_j2a, rel_df_j2b])\n",
    "rel_df_j2 = rel_df_j2a.append(rel_df_j2b)\n",
    "rel_df_j2.sort_index()\n",
    "\n",
    "vis_df2 = rel_df_j2a.iloc[:, no_min_p:no_unq_bls*2+no_min_p]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visC_df2a = vis_df2[vis_list].apply(lambda row: makeCArray(row.values), axis=1)\n",
    "visC_df2a = pd.DataFrame(visC_df2a.values.tolist(), index=visC_df2a.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis_df2b = rel_df_j2b.iloc[:, no_min_p:no_unq_bls*2+no_min_p]\n",
    "visC_df2b = vis_df2b[vis_list].apply(lambda row: makeCArray(row.values), axis=1)\n",
    "visC_df2b = pd.DataFrame(visC_df2b.values.tolist(), index=visC_df2b.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visC_14ewabs2a = visC_df2a[2].abs().values.reshape((Nfreqs, md['Ntimes'] - offset)).transpose()\n",
    "visC_14ewabs2b = visC_df2b[2].abs().values.reshape((Nfreqs, offset)).transpose()\n",
    "visC_14ewabs2 = np.append(visC_14ewabs2a, visC_14ewabs2b, axis=0)\n",
    "\n",
    "outlier_pcmesh(visC_14ewabs2, vmin=0, vmax=0.06, clabel=r'$|V|$', c_extend='max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visC_14ewabs2a = np.angle(visC_df2a[2].values).reshape((Nfreqs, md['Ntimes'] - offset)).transpose()\n",
    "visC_14ewabs2b = np.angle(visC_df2b[2].values).reshape((Nfreqs, offset)).transpose()\n",
    "visC_14ewangle2 = np.append(visC_14ewabs2a, visC_14ewabs2b, axis=0)\n",
    "\n",
    "outlier_pcmesh(visC_14ewangle2, vmin=n-np.pi, vmax=np.pi, clabel=r'$\\varphi$', cmap='PiYG', \\\n",
    "               sc_color='darkorange')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zen_fn = find_zen_file(JD1)\n",
    "bad_ants = get_bad_ants(zen_fn)\n",
    "flags_fn = find_flag_file(JD1, 'first')\n",
    "\n",
    "hdraw, RedG, cMData = group_data(zen_fn, pol, chans=None, tints=None, \\\n",
    "                                 bad_ants=bad_ants, flag_path=flags_fn)\n",
    "cData_1 = cMData.filled()\n",
    "cData_1 = cData_1[band_edge:-band_edge, :, ew_14_bls[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_abs_12_13 = np.abs(cData_1).transpose()\n",
    "\n",
    "outlier_pcmesh(raw_abs_12_13, vmin=0, vmax=0.08, clabel=r'$|V|$', c_extend='max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_phase_12_13 = np.angle(cData_1).transpose()\n",
    "\n",
    "outlier_pcmesh(raw_phase_12_13, vmin=n-np.pi, vmax=np.pi, clabel=r'$\\varphi$', cmap='PiYG', \\\n",
    "               sc_color='darkorange')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zen_fn2 = find_zen_file(JD2)\n",
    "bad_ants2 = get_bad_ants(zen_fn2)\n",
    "flags_fn2 = find_flag_file(JD2, 'first')\n",
    "\n",
    "hdraw, RedG, cMData = group_data(zen_fn2, pol, chans=None, tints=None, \\\n",
    "                                 bad_ants=bad_ants2, flag_path=flags_fn2)\n",
    "cData_2 = cMData.filled()\n",
    "cData_2 = cData_2[band_edge:-band_edge, :, ew_14_bls[0]]\n",
    "\n",
    "zen_fn3 = find_zen_file(JD3)\n",
    "bad_ants3 = get_bad_ants(zen_fn3)\n",
    "flags_fn3 = find_flag_file(JD3, 'first')\n",
    "\n",
    "hdraw, RedG, cMData = group_data(zen_fn3, pol, chans=None, tints=None, \\\n",
    "                                 bad_ants=bad_ants3, flag_path=flags_fn3)\n",
    "cData_3 = cMData.filled()\n",
    "cData_3 = cData_3[band_edge:-band_edge, :, ew_14_bls[0]]\n",
    "\n",
    "cData_4 = np.concatenate((cData_2[:, offset:], cData_3[:, :offset]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_abs_99_12_13 = np.abs(cData_4).transpose()\n",
    "\n",
    "outlier_pcmesh(raw_abs_99_12_13, vmin=0, vmax=0.08, clabel=r'$|V|$', c_extend='max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_phase_99_12_13 = np.angle(cData_4).transpose()\n",
    "\n",
    "outlier_pcmesh(raw_phase_99_12_13, vmin=n-np.pi, vmax=np.pi, clabel=r'$\\varphi$', cmap='PiYG', \\\n",
    "               sc_color='darkorange')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "193px",
    "width": "395px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from plot_utils import df_heatmap\n",
    "from red_likelihood import decomposeCArray, degVis, makeCArray, red_ant_sep\n",
    "from red_utils import find_nearest, find_deg_df, find_rel_df, \\\n",
    "match_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jd_time = 2458098.43869\n",
    "jd_anchor = 2458099\n",
    "pol = 'ee'\n",
    "dist = 'gaussian'\n",
    "rel_dir_path = 'rel_dfs'\n",
    "deg_dir_path = 'deg_dfs'\n",
    "coords = 'cartesian'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_figs = False\n",
    "if plot_figs:\n",
    "    import matplotlib as mpl\n",
    "    mpl.rcParams['figure.dpi'] = 300"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing a pair of datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading 1st relatively calibrated dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(rel_dir_path, 'rel_df.{}.{}.md.pkl'.format(jd_time, pol)), 'rb') as f:\n",
    "    md = pickle.load(f)\n",
    "    \n",
    "indices = ['freq', 'time_int']\n",
    "resid_cols = ['residual', 'norm_residual']\n",
    "vis_list = list(map(str, np.arange(md['no_unq_bls']*2).tolist()))\n",
    "cvis_list = ['C' + vis_id for vis_id in list(map(str, np.arange(md['no_unq_bls']).tolist()))]\n",
    "gain_list = list(map(str, np.arange(md['no_unq_bls']*2, (md['no_unq_bls'] + md['no_ants'])*2 ).tolist()))\n",
    "\n",
    "rel_df_path = find_rel_df(jd_time, pol, dist, rel_dir_path)\n",
    "rel_df = pd.read_pickle(rel_df_path)\n",
    "rel_df.drop(columns=resid_cols, inplace=True)\n",
    "\n",
    "Nfreqs = rel_df.index.get_level_values('freq').unique().size\n",
    "Ntints = rel_df.index.get_level_values('time_int').unique().size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading 2nd relatively calibrated dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to an offset in LAST, two relatively calibrated dataframes must be merged, with the appropriate cuts in LAST to align the merged dataframe with the 1st one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find dataset from specified JD that contains visibilities at the same LAST\n",
    "jd_time2 = match_lst(jd_time, jd_anchor)\n",
    "rel_df_path2 = find_rel_df(jd_time2, pol, dist, rel_dir_path)\n",
    "\n",
    "# aligning datasets in LAST\n",
    "last_df = pd.read_pickle('jd_lst_map_idr2.pkl')\n",
    "last1 = last_df[last_df['JD_time'] == jd_time]['LASTs'].values[0]\n",
    "last2 = last_df[last_df['JD_time'] == jd_time2]['LASTs'].values[0]\n",
    "_, offset = find_nearest(last2, last1[0])\n",
    "\n",
    "rel_df2 = pd.read_pickle(rel_df_path2)\n",
    "rel_df2 = rel_df2[rel_df2.index.get_level_values('time_int') >= offset]\n",
    "# shifting tints to align with those from jd_time\n",
    "rel_df2.reset_index(inplace=True)\n",
    "rel_df2['time_int'] = np.tile(np.arange(Ntints - offset), Nfreqs)\n",
    "rel_df2.set_index(indices, inplace=True)\n",
    "\n",
    "next_row = np.where(last_df['JD_time'] == jd_time2)[0][0] + 1\n",
    "rel_df_path3 = find_rel_df(last_df.iloc[next_row]['JD_time'], pol, \\\n",
    "                           dist, rel_dir_path)\n",
    "rel_df3 = pd.read_pickle(rel_df_path3)\n",
    "rel_df3 = rel_df3[rel_df3.index.get_level_values('time_int') < offset]\n",
    "# shifting tints to align with those from jd_time\n",
    "rel_df3.reset_index(inplace=True)\n",
    "rel_df3['time_int'] = np.tile(np.arange(Ntints - offset, Ntints), Nfreqs)\n",
    "rel_df3.set_index(indices, inplace=True)\n",
    "\n",
    "# combined results dataframes that is now alinged in LAST by row number\n",
    "# with rel_df:\n",
    "rel_df_c = pd.concat([rel_df2, rel_df3])\n",
    "rel_df_c.sort_index(inplace=True)\n",
    "rel_df_c.drop(columns=resid_cols + gain_list, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Degenerate transformation of the 1st dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_list = ['success', 'status', 'message', 'fun', 'nit']\n",
    "rel_df_d = rel_df[min_list].copy()\n",
    "rel_df_d = rel_df_d.reindex(columns=rel_df_d.columns.values.tolist() + vis_list)\n",
    "rel_df_d.sample(5).sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deg_df_path = find_deg_df(jd_time, pol, 'jd.{}'.format(jd_anchor), dist, deg_dir_path)\n",
    "deg_df = pd.read_pickle(deg_df_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deg_df_d = deg_df[['0', '1', '2']].copy().reset_index()\n",
    "deg_df_d.rename(columns={'time_int1': 'time_int', '0': 'amp', '1': 'tilt_x', '2':'tilt_y'}, inplace=True)\n",
    "deg_df_d.set_index(indices, inplace=True)\n",
    "deg_df_d.sort_index(inplace=True)\n",
    "rel_df.drop(columns=gain_list, inplace=True)\n",
    "rel_df = rel_df.join(deg_df_d)\n",
    "rel_df.sample(5).sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ant_sep = red_ant_sep(md['redg'], md['antpos'])\n",
    "rel_df_d[vis_list] = rel_df.apply(lambda row: pd.Series(decomposeCArray(degVis(ant_sep, \\\n",
    "                     makeCArray(row[len(min_list):len(min_list) + md['no_unq_bls']*2].values.astype(float)), \n",
    "                     *row[-3:].values.astype(float)))), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rel_df_d.sample(5).sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combining degenerately consistent dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merging dataframes\n",
    "rel_df_d['JD'] = int(jd_time)\n",
    "rel_df_c['JD'] = int(jd_anchor)\n",
    "\n",
    "rel_df_t = pd.concat([rel_df_d, rel_df_c])\n",
    "\n",
    "rel_df_t.reset_index(inplace=True)\n",
    "rel_df_t.set_index(['freq', 'time_int', 'JD'], inplace=True)\n",
    "rel_df_t.sort_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rel_df_t.sample(5).sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistics on combined dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rel_df_t[vis_list].groupby(level=['freq', 'time_int']).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rel_df_t[vis_list].groupby(level=['freq', 'time_int']).std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single time integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_integration = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selecting time integration\n",
    "rel_df_tint = rel_df_t.xs(time_integration, level='time_int', drop_level=True)\n",
    "# turning into complex values\n",
    "rel_df_tintc = rel_df_tint.apply(lambda row: pd.Series(makeCArray(row[vis_list].values.astype(float))), \\\n",
    "                                 axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rel_df_tintc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis_abs_mean = rel_df_tintc.abs().groupby('freq').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "piv = pd.pivot_table(vis_abs_mean, columns='freq')\n",
    "vmax = np.nanpercentile(piv.values, 95)\n",
    "vmin = 0\n",
    "df_heatmap(piv, xbase=50, ybase=5, vmax=vmax, vmin=vmin, \\\n",
    "           title='Mean visibility amplitudes for time_integration {}'.format(time_integration), \\\n",
    "           xlabel='Frequency', \\\n",
    "           ylabel='Redundant Baseline Group')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "re_df = rel_df_tint.drop(columns=min_list).iloc[:, np.arange(2*md['no_unq_bls'], step=2)]\\\n",
    "        .groupby('freq').var()\n",
    "im_df = rel_df_tint.drop(columns=min_list).iloc[:, np.arange(1, 2*md['no_unq_bls'], step=2)]\\\n",
    "        .groupby('freq').var()\n",
    "re_df.columns = np.arange(md['no_unq_bls'])\n",
    "im_df.columns = np.arange(md['no_unq_bls'])\n",
    "var_df = re_df + im_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "piv = pd.pivot_table(var_df, columns='freq')\n",
    "vmax = np.nanpercentile(piv.values, 95)\n",
    "vmin = 0\n",
    "df_heatmap(piv, xbase=50, ybase=5, vmax=vmax, vmin=vmin, \\\n",
    "           title='Visibility variance for time_integration {}'.format(time_integration), \\\n",
    "           xlabel='Frequency', \\\n",
    "           ylabel='Redundant Baseline Group')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistics over multiple JDs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Starting from the JDs from the previous section, we add further JDs that cover the same LAST range by aligning them in LAST and degenerately transforming them to be consistent with the anchor day (JD 2458099 in this case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idr2_jds = [2458098, 2458099, 2458101, 2458102, 2458103, 2458104, 2458105, \\\n",
    "            2458106, 2458107, 2458108, 2458109, 2458110, 2458111, 2458112, \\\n",
    "            2458113, 2458114, 2458115, 2458116, 2458140]\n",
    "# 2458109 to be removed from idr2_jds as it has different antennas (antenna 14 flagged there)\n",
    "jd_comp = [2458101]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find dataset from specified JD that contains visibilities at the same LAST\n",
    "\n",
    "jd_ci = jd_comp[0]\n",
    "\n",
    "#### load rel cal dataframe and align in LAST ####\n",
    "\n",
    "jd_timei = match_lst(jd_time, jd_ci)\n",
    "rel_df_path2 = find_rel_df(jd_timei, pol, dist, rel_dir_path)\n",
    "\n",
    "# aligning datasets in LAST\n",
    "lasti = last_df[last_df['JD_time'] == jd_timei]['LASTs'].values[0]\n",
    "_, offset = find_nearest(lasti, last1[0])\n",
    "\n",
    "rel_dfi = pd.read_pickle(rel_df_path2)\n",
    "rel_dfi = rel_dfi[rel_dfi.index.get_level_values('time_int') >= offset]\n",
    "# shifting tints to align with those from jd_time\n",
    "rel_dfi.reset_index(inplace=True)\n",
    "rel_dfi['time_int'] = np.tile(np.arange(Ntints - offset), Nfreqs)\n",
    "rel_dfi.set_index(indices, inplace=True)\n",
    "\n",
    "next_row = np.where(last_df['JD_time'] == jd_timei)[0][0] + 1\n",
    "jd_timei2 = last_df.iloc[next_row]['JD_time']\n",
    "rel_df_pathj = find_rel_df(jd_timei2, pol, dist, rel_dir_path)\n",
    "rel_dfj = pd.read_pickle(rel_df_pathj)\n",
    "rel_dfj = rel_dfj[rel_dfj.index.get_level_values('time_int') < offset]\n",
    "# shifting tints to align with those from jd_time\n",
    "rel_dfj.reset_index(inplace=True)\n",
    "rel_dfj['time_int'] = np.tile(np.arange(Ntints - offset, Ntints), Nfreqs)\n",
    "rel_dfj.set_index(indices, inplace=True)\n",
    "\n",
    "# combined results dataframes that is now alinged in LAST by row number\n",
    "# with rel_df:\n",
    "rel_dfk = pd.concat([rel_dfi, rel_dfj])\n",
    "rel_dfk.sort_index(inplace=True)\n",
    "rel_dfk.drop(columns=resid_cols + gain_list, inplace=True)\n",
    "\n",
    "\n",
    "#### degenerate transformation ####\n",
    "\n",
    "# load rel cal dataframe and align in LAST \n",
    "\n",
    "deg_df_pathi = find_deg_df(jd_timei, pol, 'jd.{}'.format(jd_anchor), dist, deg_dir_path)\n",
    "deg_dfi = pd.read_pickle(deg_df_pathi)\n",
    "deg_dfi = deg_dfi[deg_dfi.index.get_level_values('time_int1') >= offset]\n",
    "deg_dfi.sort_index(level=['freq', 'time_int1'], inplace=True)\n",
    "deg_dfi.reset_index(inplace=True)\n",
    "deg_dfi['time_int1'] = np.tile(np.arange(Ntints - offset), Nfreqs)\n",
    "deg_indices = ['freq', 'time_int1']\n",
    "deg_dfi.set_index(deg_indices, inplace=True)\n",
    "\n",
    "deg_df_pathj = find_deg_df(jd_timei2, pol, 'jd.{}'.format(jd_anchor), dist, deg_dir_path)\n",
    "deg_dfj = pd.read_pickle(deg_df_pathj)\n",
    "deg_dfj = deg_dfj[deg_dfj.index.get_level_values('time_int1') < offset]\n",
    "deg_dfj.sort_index(level=['freq', 'time_int1'], inplace=True)\n",
    "deg_dfj.reset_index(inplace=True)\n",
    "deg_dfj['time_int1'] = np.tile(np.arange(Ntints - offset, Ntints), Nfreqs)\n",
    "deg_dfj.set_index(deg_indices, inplace=True)\n",
    "\n",
    "deg_dfk = pd.concat([deg_dfi, deg_dfj])\n",
    "deg_dfk.sort_index(inplace=True)\n",
    "\n",
    "\n",
    "# degenerate transformation of redundant visibility solutions\n",
    "\n",
    "deg_dfk = deg_dfk[['0', '1', '2']].copy().reset_index()\n",
    "deg_dfk.rename(columns={'time_int1': 'time_int', '0': 'amp', '1': 'tilt_x', '2':'tilt_y'}, inplace=True)\n",
    "deg_dfk.set_index(indices, inplace=True)\n",
    "deg_dfk.sort_index(inplace=True)\n",
    "rel_dfk = rel_dfk.join(deg_dfk)\n",
    "\n",
    "rel_df_di = rel_df[min_list].copy()\n",
    "rel_df_di = rel_df_di.reindex(columns=rel_df_di.columns.values.tolist() + vis_list)\n",
    "\n",
    "rel_df_di[vis_list] = rel_dfk.apply(lambda row: pd.Series(decomposeCArray(degVis(ant_sep, \\\n",
    "                      makeCArray(row[len(min_list):len(min_list) + md['no_unq_bls']*2].values.astype(float)), \n",
    "                      *row[-3:].values.astype(float)))), axis=1)\n",
    "\n",
    "\n",
    "# merging dataframes\n",
    "\n",
    "rel_df_di['JD'] = int(jd_timei)\n",
    "rel_df_di.reset_index(inplace=True)\n",
    "rel_df_di.set_index(['freq', 'time_int', 'JD'], inplace=True)\n",
    "rel_df_di.sort_index(inplace=True)\n",
    "\n",
    "rel_df_t = pd.concat([rel_df_t, rel_df_di])\n",
    "rel_df_t.sort_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rel_df_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from plot_utils import df_heatmap\n",
    "from red_likelihood import decomposeCArray, degVis, makeCArray, red_ant_sep\n",
    "from red_utils import find_nearest, find_deg_df, find_rel_df, \\\n",
    "match_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jd_time = 2458098.43869\n",
    "jd_comp = 2458099\n",
    "pol = 'ee'\n",
    "dist = 'gaussian'\n",
    "dir_path = '/Users/matyasmolnar/Downloads/HERA_Data/robust_cal/simpleredcal'\n",
    "coords = 'cartesian'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_figs = False\n",
    "if plot_figs:\n",
    "    import matplotlib as mpl\n",
    "    mpl.rcParams['figure.dpi'] = 300"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading 1st relatively calibrated dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('rel_df.{}.{}.md.pkl'.format(jd_time, pol), 'rb') as f:\n",
    "    md = pickle.load(f)\n",
    "    \n",
    "indices = ['freq', 'time_int']\n",
    "resid_cols = ['residual', 'norm_residual']\n",
    "vis_list = list(map(str, np.arange(md['no_unq_bls']*2).tolist()))\n",
    "cvis_list = ['C' + vis_id for vis_id in list(map(str, np.arange(md['no_unq_bls']).tolist()))]\n",
    "gain_list = list(map(str, np.arange(md['no_unq_bls']*2, (md['no_unq_bls'] + md['no_ants'])*2 ).tolist()))\n",
    "\n",
    "rel_df_path = find_rel_df(jd_time, pol, dist, dir_path)\n",
    "rel_df = pd.read_pickle(rel_df_path)\n",
    "rel_df.drop(columns=resid_cols, inplace=True)\n",
    "\n",
    "Nfreqs = rel_df.index.get_level_values('freq').unique().size\n",
    "Ntints = rel_df.index.get_level_values('time_int').unique().size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading 2nd relatively calibrated dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to an offset in LAST, two relatively calibrated dataframes must be merged, with the appropriate cuts in LAST to align the merged dataframe with the 1st one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find dataset from specified JD that contains visibilities at the same LAST\n",
    "jd_time2 = match_lst(jd_time, jd_comp)\n",
    "rel_df_path2 = find_rel_df(jd_time2, pol, dist, dir_path)\n",
    "\n",
    "# aligning datasets in LAST\n",
    "last_df = pd.read_pickle('jd_lst_map_idr2.pkl')\n",
    "last1 = last_df[last_df['JD_time'] == jd_time]['LASTs'].values[0]\n",
    "last2 = last_df[last_df['JD_time'] == jd_time2]['LASTs'].values[0]\n",
    "_, offset = find_nearest(last2, last1[0])\n",
    "\n",
    "rel_df2 = pd.read_pickle(rel_df_path2)\n",
    "rel_df2 = rel_df2[rel_df2.index.get_level_values('time_int') >= offset]\n",
    "# shifting tints to align with those from jd_time\n",
    "rel_df2.reset_index(inplace=True)\n",
    "rel_df2['time_int'] = np.tile(np.arange(Ntints - offset), Nfreqs)\n",
    "rel_df2.set_index(indices, inplace=True)\n",
    "\n",
    "next_row = np.where(last_df['JD_time'] == jd_time2)[0][0] + 1\n",
    "rel_df_path3 = find_rel_df(last_df.iloc[next_row]['JD_time'], pol, \\\n",
    "                           dist, dir_path)\n",
    "rel_df3 = pd.read_pickle(rel_df_path3)\n",
    "rel_df3 = rel_df3[rel_df3.index.get_level_values('time_int') < offset]\n",
    "# shifting tints to align with those from jd_time\n",
    "rel_df3.reset_index(inplace=True)\n",
    "rel_df3['time_int'] = np.tile(np.arange(Ntints - offset, Ntints), Nfreqs)\n",
    "rel_df3.set_index(indices, inplace=True)\n",
    "\n",
    "# combined results dataframes that is now alinged in LAST by row number\n",
    "# with rel_df:\n",
    "rel_df_c = pd.concat([rel_df2, rel_df3])\n",
    "rel_df_c.sort_index(inplace=True)\n",
    "rel_df_c.drop(columns=resid_cols + gain_list, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Degenerate transformation of the 1st dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_list = ['success', 'status', 'message', 'fun', 'nit']\n",
    "rel_df_d = rel_df[min_list].copy()\n",
    "rel_df_d = rel_df_d.reindex(columns=rel_df_d.columns.values.tolist() + vis_list)\n",
    "rel_df_d.sample(5).sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deg_df_path = find_deg_df(jd_time, pol, 'jd.{}'.format(jd_comp), dist, dir_path)\n",
    "deg_df = pd.read_pickle(deg_df_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deg_df_d = deg_df[['0', '1', '2']].copy().reset_index()\n",
    "deg_df_d.rename(columns={'time_int1': 'time_int', '0': 'amp', '1': 'tilt_x', '2':'tilt_y'}, inplace=True)\n",
    "deg_df_d.set_index(indices, inplace=True)\n",
    "deg_df_d.sort_index(inplace=True)\n",
    "rel_df.drop(columns=gain_list, inplace=True)\n",
    "rel_df = rel_df.join(deg_df_d)\n",
    "rel_df.sample(5).sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ant_sep = red_ant_sep(md['redg'], md['antpos'])\n",
    "vis_list = list(map(str, np.arange(md['no_unq_bls']*2).tolist()))\n",
    "rel_df_d[vis_list] = rel_df.apply(lambda row: pd.Series(decomposeCArray(degVis(ant_sep, \\\n",
    "                     makeCArray(row[len(min_list):len(min_list) + md['no_unq_bls']*2].values.astype(float)), \n",
    "                     *row[-3:].values.astype(float)))), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rel_df_d.sample(5).sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combining degenerately consistent dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merging dataframes\n",
    "rel_df_d['JD'] = int(jd_time)\n",
    "rel_df_c['JD'] = int(jd_comp)\n",
    "\n",
    "rel_df_t = pd.concat([rel_df_d, rel_df_c])\n",
    "\n",
    "rel_df_t.reset_index(inplace=True)\n",
    "rel_df_t.set_index(['freq', 'time_int', 'JD'], inplace=True)\n",
    "rel_df_t.sort_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rel_df_t.sample(5).sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistics on combined dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rel_df_t[vis_list].groupby(level=['freq', 'time_int']).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rel_df_t[vis_list].groupby(level=['freq', 'time_int']).std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_integration = 20\n",
    "a = rel_df_t.apply(lambda row: pd.Series(makeCArray(row[vis_list].values.astype(float))), axis=1).abs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = a.xs(time_integration, level='time_int', drop_level=True).groupby(level=['freq']).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "piv = pd.pivot_table(b, columns='freq')\n",
    "vmax = np.nanpercentile(piv.values, 95)\n",
    "vmin = 0\n",
    "df_heatmap(piv, xbase=50, ybase=5, vmax=vmax, vmin=vmin, \\\n",
    "           title='Visibility amplitudes for time_integration {}'.format(time_integration), \\\n",
    "           xlabel='Frequency', \\\n",
    "           ylabel='Redundant Baseline Group')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

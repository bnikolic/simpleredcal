{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "disciplinary-lewis",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import yaml\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from hera_cal.io import HERAData\n",
    "\n",
    "from align_utils import idr2_jdsx\n",
    "from fit_diagnostics import abs_residuals, norm_residuals\n",
    "from plot_utils import clipped_heatmap, df_heatmap, flagged_hist, \\\n",
    "plot_res_grouped, plot_res_heatmap\n",
    "from red_likelihood import group_data, makeCArray, relabelAnts, split_rel_results\n",
    "from red_utils import find_nearest, find_zen_file\n",
    "from xd_utils import union_bad_ants, XDgroup_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hairy-riding",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "invalid-habitat",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_figs = False\n",
    "if plot_figs:\n",
    "    import matplotlib as mpl\n",
    "    mpl.rcParams['figure.dpi'] = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "arranged-manor",
   "metadata": {},
   "outputs": [],
   "source": [
    "jd_time = 2458098.43869 # used to find LST that labels dataframe\n",
    "pol = 'ee'\n",
    "ndist = 'gaussian'\n",
    "dir_path = 'xd_rel_dfs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "increased-limitation",
   "metadata": {},
   "outputs": [],
   "source": [
    "lst_df = pd.read_pickle('jd_lst_map_idr2.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "blond-blowing",
   "metadata": {},
   "outputs": [],
   "source": [
    "lst_ref = lst_df[lst_df['JD_time'] == jd_time]['LASTs'].values[0][0]\n",
    "xd_df_path = os.path.join(dir_path, 'xd_rel_df.{:.4f}.{}.{}.pkl'.format(lst_ref, pol, ndist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comparative-sustainability",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(dir_path, 'xd_rel_df.{:.4f}.{}.md.pkl'.format(lst_ref, pol)), 'rb') as f:\n",
    "    md = pickle.load(f)\n",
    "    \n",
    "xd_df = pd.read_pickle(xd_df_path)\n",
    "\n",
    "chans = xd_df.index.get_level_values(level='freq').unique().values\n",
    "tints = xd_df.index.get_level_values(level='time_int').unique().values\n",
    "\n",
    "Nfreqs = chans.size\n",
    "Ntints = tints.size\n",
    "\n",
    "xd_df.sample(5).sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "confident-pastor",
   "metadata": {},
   "source": [
    "## Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "north-priority",
   "metadata": {},
   "source": [
    "### Number of iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "loved-uncle",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_res_grouped(xd_df, 'nit', logy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "frequent-europe",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_res_heatmap(xd_df, 'nit', clip=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "italic-italic",
   "metadata": {},
   "source": [
    "### Log-likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mental-density",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_res_grouped(xd_df, 'fun', logy=True, figsize=(10, 7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cutting-fiber",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_res_heatmap(xd_df, 'fun', clip=True, clip_pctile=98, figsize=(8, 6))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exact-hundred",
   "metadata": {},
   "source": [
    "### Residuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "purple-factory",
   "metadata": {},
   "outputs": [],
   "source": [
    "xd_df[['med_abs_norm_res_Re', 'med_abs_norm_res_Im']] = xd_df.apply(lambda row: \\\n",
    "    pd.Series(abs_residuals(row['norm_residual'])), axis=1)\n",
    "\n",
    "xd_df['med_abs_norm_res_comb'] = np.sqrt(xd_df['med_abs_norm_res_Re']**2 + \\\n",
    "                                         xd_df['med_abs_norm_res_Im']**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "composed-camel",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_res_heatmap(xd_df, 'med_abs_norm_res_comb', vmin=0.16, vmax=0.22, \\\n",
    "                 figsize=(8, 6))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abandoned-disposition",
   "metadata": {},
   "source": [
    "## Gains at sample frequency and time slice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stretch-brunswick",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check results for a given frequency & time integration\n",
    "test_freq = 600\n",
    "test_tint = 53\n",
    "\n",
    "resx = xd_df.loc[(test_freq, test_tint)][5:-5].values.astype(float)\n",
    "test_vis, test_gains = split_rel_results(resx, md['no_unq_bls'], coords='cartesian')\n",
    "test_gains = test_gains.reshape((md['JDs'].size, -1))\n",
    "\n",
    "print('Mean gain amplitude across JDs for test frequency {} and time integration {}: '\\\n",
    "      '\\n{}\\n'.format(test_freq, test_tint, np.mean(np.abs(test_gains), axis=0)))\n",
    "print('Mean gain phase across JDs for test frequency {} and time integration {}: '\\\n",
    "      '\\n{}\\n'.format(test_freq, test_tint, np.mean(np.angle(test_gains), axis=0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gorgeous-stevens",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(nrows=1, ncols=2, figsize=(9, 3.5), sharey=True)\n",
    "\n",
    "sns.heatmap(np.abs(test_gains), cmap=sns.cm.rocket_r, center=1, ax=ax1)\n",
    "sns.heatmap(np.angle(test_gains), cmap='bwr', center=0, ax=ax2, vmin=-np.pi, vmax=np.pi)\n",
    "ax1.set_xlabel('Antenna number')\n",
    "ax2.set_xlabel('Antenna number')\n",
    "\n",
    "ax1.set_yticks(np.arange(md['JDs'].size)+0.5)\n",
    "ax1.set_yticklabels(md['JDs'], rotation=0)\n",
    "ax2.set_yticks(np.arange(md['JDs'].size), minor=True)\n",
    "ax1.tick_params(axis='y', which='minor', color='white')\n",
    "ax2.tick_params(axis='y', which='minor', color='white')\n",
    "\n",
    "ax1.set_xticks(np.arange(md['no_ants'])[::5]+0.5, minor=False)\n",
    "ax1.set_xticklabels(np.arange(md['no_ants'])[::5])\n",
    "ax2.set_xticks(np.arange(md['no_ants'])[::5]+0.5, minor=False)\n",
    "ax2.set_xticklabels(np.arange(md['no_ants'])[::5])\n",
    "\n",
    "ax1.grid(which='minor', axis='y', linestyle='--', lw=0.5)\n",
    "ax2.grid(which='minor', axis='y', linestyle='--', lw=0.5)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "valuable-ferry",
   "metadata": {},
   "source": [
    "## Visibilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acknowledged-cambridge",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_unq_bls = md['no_unq_bls']\n",
    "no_min_p = 5 # number of columns in df that are attributes of the SciPy OptimizeResult \n",
    "vis_df = xd_df.iloc[:, no_min_p:no_unq_bls*2+no_min_p]\n",
    "\n",
    "visC_df = vis_df.apply(lambda row: makeCArray(row.values), axis=1)\n",
    "visC_df = pd.DataFrame(visC_df.values.tolist(), index=visC_df.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "verbal-strengthening",
   "metadata": {},
   "source": [
    "### Visibilities at test time integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "thorough-craft",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = visC_df.xs(53, level='time_int').abs().transpose()\n",
    "vmax = np.nanpercentile(df.values, 98)\n",
    "vmin = np.nanpercentile(df.values, 2)\n",
    "df_heatmap(df, xbase=25, ybase=5, \\\n",
    "           xlabel='Channel', ylabel='Redundant Baseline Group', \\\n",
    "           vmin=vmin, vmax=vmax, figsize=(8, 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "circular-breed",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = visC_df.xs(53, level='time_int').applymap(np.angle).transpose()\n",
    "df_heatmap(df, xbase=25, ybase=5, cmap='bwr', vmin=-np.pi, vmax=np.pi, center=0, \\\n",
    "           xlabel='Channel', ylabel='Redundant Baseline Group', figsize=(8, 6))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "welsh-slope",
   "metadata": {},
   "source": [
    "## Flagging methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "handled-niagara",
   "metadata": {},
   "source": [
    "#### Get flags from .smooth_abs.calfits files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "breathing-brand",
   "metadata": {},
   "outputs": [],
   "source": [
    "idr2_flags = np.load('idr2_flags.npz')['arr_0'].astype(bool)\n",
    "idr2_flags = idr2_flags[:, chans - 50, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "married-miller",
   "metadata": {},
   "source": [
    "#### MAD-clipping flags from LST-Binning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "supported-dining",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists('/lustre/aoc/projects/hera/H1C_IDR2/'):\n",
    "    local_work = False\n",
    "    lst_binned_dir = '/lustre/aoc/projects/hera/H1C_IDR2/IDR2_2/LSTBIN/one_group/grp1'\n",
    "else:\n",
    "    lst_binned_dir = '/Users/matyasmolnar/Downloads/HERA_Data/robust_cal/'\n",
    "    local_work = True\n",
    "    \n",
    "lst_binned_file = os.path.join(lst_binned_dir, 'zen.grp1.of1.LST.1.40949.HH.OCRSL.uvh5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "informative-poultry",
   "metadata": {},
   "outputs": [],
   "source": [
    "hd_lstb, _, LSTdata = group_data(lst_binned_file, pol, chans=chans, tints=None, \\\n",
    "                                 bad_ants=union_bad_ants(idr2_jdsx), \\\n",
    "                                 flag_path=None, noise=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "varied-arrival",
   "metadata": {},
   "outputs": [],
   "source": [
    "hd_lstb.lsts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "olympic-religion",
   "metadata": {},
   "outputs": [],
   "source": [
    "hd = HERAData(find_zen_file(jd_time))\n",
    "hd.lsts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "martial-integrity",
   "metadata": {},
   "outputs": [],
   "source": [
    "lst_binned_files = glob.glob(os.path.join(lst_binned_dir, 'zen.grp1.of1.LST.*.HH.OCRSL.uvh5'))\n",
    "dtst_lsts = [float('.'.join(os.path.basename(lst_f).split('.')[4:6])) for lst_f in lst_binned_files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rubber-debut",
   "metadata": {},
   "outputs": [],
   "source": [
    "lst_idx1 = find_nearest(dtst_lsts, hd.lsts[0], condition='leq')[1]\n",
    "lst_idx2 = find_nearest(dtst_lsts, hd.lsts[0], condition='geq')[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "strategic-sculpture",
   "metadata": {},
   "outputs": [],
   "source": [
    "hd_lstb1, _, LSTdata1 = group_data(lst_binned_files[lst_idx1], pol, chans=chans, \n",
    "                                   tints=None, bad_ants=union_bad_ants(idr2_jdsx), \\\n",
    "                                   flag_path=None, noise=False)\n",
    "\n",
    "hd_lstb2, _, LSTdata2 = group_data(lst_binned_files[lst_idx2], pol, chans=chans, \n",
    "                                   tints=None, bad_ants=union_bad_ants(idr2_jdsx), \\\n",
    "                                   flag_path=None, noise=False)\n",
    "\n",
    "concat_lsts = np.concatenate((hd_lstb1.lsts, hd_lstb2.lsts))\n",
    "if (hd.lsts[0] < concat_lsts).all() or (hd.lsts[-1] > concat_lsts).all():\n",
    "    raise Exception('Could not find LST-binned files.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "directed-small",
   "metadata": {},
   "outputs": [],
   "source": [
    "align_idxs = []\n",
    "for i in hd.lsts:\n",
    "    align_idxs.append(find_nearest(concat_lsts, i)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "expected-justice",
   "metadata": {},
   "outputs": [],
   "source": [
    "hd.lsts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "international-wallet",
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_lsts[align_idxs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dress-paint",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nsamples[(12, 13, 'ee')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "differential-salvation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data[(12, 13, 'ee')]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dried-apparel",
   "metadata": {},
   "source": [
    "#### Additional flags by Nick Kern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "superb-jones",
   "metadata": {},
   "outputs": [],
   "source": [
    "if local_work:\n",
    "    nkern_flg_dir = lst_binned_dir\n",
    "else:\n",
    "    nkern_flg_dir = '/lustre/aoc/projects/hera/H1C_IDR2/IDR2_2_pspec/v2/one_group/'\n",
    "\n",
    "nkern_flg_file = os.path.join(nkern_flg_dir, 'preprocess_params.yaml')\n",
    "\n",
    "# Read YAML file\n",
    "with open(nkern_flg_file, 'r') as stream:\n",
    "    data_loaded = yaml.safe_load(stream)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "continental-silicon",
   "metadata": {},
   "outputs": [],
   "source": [
    "man_flags = np.concatenate([np.arange(i[0], i[1]+1) for i in \\\n",
    "                            data_loaded['algorithm']['fg_filt']['flag_chans']]).ravel()\n",
    "rel_nflags = man_flags[np.where(np.logical_and(man_flags >= chans[0], man_flags <= chans[-1]))] -  chans[0]\n",
    "idr2_flags[:, rel_nflags, :] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "satellite-fashion",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "# Get mad-clipped flags at LST-binning stage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "clinical-tissue",
   "metadata": {},
   "source": [
    "#### Flags used in H1C_IDR2 limits paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "favorite-protocol",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = clipped_heatmap(idr2_flags.sum(axis=0).transpose(), 'Time Integration', 'Channel', \\\n",
    "                          vmin=0, clip_pctile=100, figsize=(8, 5), xoffset=-chans[0])\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "limiting-south",
   "metadata": {},
   "source": [
    "### Negative log-likelihood histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "processed-teaching",
   "metadata": {},
   "outputs": [],
   "source": [
    "nll_upper_cut = 1\n",
    "xd_rel_values = xd_df['fun'].values.astype(float)\n",
    "\n",
    "flgs_all = np.zeros_like(idr2_flags[0, ...])\n",
    "flg_pct = 50 / 100\n",
    "flgs_all[np.where(idr2_flags.mean(axis=0) > flg_pct)] = True # if 50% of days flagged\n",
    "flgs_all = flgs_all.ravel(order='F')\n",
    "\n",
    "flagged_hist(xd_rel_values, flgs_all, \\\n",
    "             xlabel=r'$-\\ln(\\mathcal{L}^C_\\mathrm{xd\\_rel})$', \\\n",
    "             lower_cut=0.1, upper_cut=nll_upper_cut, bin_width=0.02, hist_start=0, ylim=(0, 1500))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "natural-nelson",
   "metadata": {},
   "outputs": [],
   "source": [
    "sus_slices = np.where((xd_rel_values > 10) & ~flgs_all)[0]\n",
    "xd_df.index[sus_slices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exclusive-description",
   "metadata": {},
   "outputs": [],
   "source": [
    "xd_rel_values[sus_slices]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sonic-clock",
   "metadata": {},
   "source": [
    "### Calculating the NLLs had the minimization been done with Gaussian distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "complex-maldives",
   "metadata": {},
   "outputs": [],
   "source": [
    "if ndist == 'gaussian':\n",
    "    nll_dist = 'cauchy'\n",
    "if ndist == 'cauchy':\n",
    "    nll_dist = 'gaussian'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "russian-cisco",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_cols = [col for col in xd_df.columns.values if col.isdigit()]\n",
    "\n",
    "# Retrieve solved gains in array format\n",
    "xd_gains = xd_df[res_cols[no_unq_bls*2:]].values.reshape((Nfreqs, Ntints, md['JDs'].size, -1))\n",
    "xd_gains = np.moveaxis(xd_gains, [2, 0, 1, 3], [0, 1, 2, 3])\n",
    "y = xd_gains.reshape(xd_gains.shape[:3] + (md['no_ants'], -1, 2))\n",
    "xd_gains = np.squeeze(y[..., 0] + 1j*y[..., 1])\n",
    "\n",
    "# Retrieve solved visibilities in array format\n",
    "xd_vis = xd_df[res_cols[:no_unq_bls*2]].values.reshape((Nfreqs, Ntints, -1, 2))\n",
    "xd_vis = xd_vis[..., 0] + 1j*xd_vis[..., 1]\n",
    "xd_vis = np.tile(np.expand_dims(xd_vis, axis=0), (md['JDs'].size, 1, 1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "protective-interview",
   "metadata": {},
   "outputs": [],
   "source": [
    "if Ntints == md['Ntimes']:\n",
    "    tints = None\n",
    "if (md['JDs'] == idr2_jdsx).all():\n",
    "    jds = idr2_jdsx\n",
    "else:\n",
    "    jds = md['JDs']\n",
    "\n",
    "if os.path.exists('test_idr2_cdata.npz'):\n",
    "    local_work = True\n",
    "    local_jd = 2458098.43869\n",
    "    if jd_time == local_jd:\n",
    "    # retrieve data locally\n",
    "        cdata = np.load('test_idr2_cdata.npz')['arr_0']\n",
    "        cndata = np.load('test_idr2_cndata.npz')['arr_0']\n",
    "    else:\n",
    "        raise Exception('Only H1C_IDR2 visibility data across JDs aligned with {} '\n",
    "                        'is available locally.'.format(local_jd))\n",
    "else:\n",
    "    _, _, cdata, cndata = XDgroup_data(jd_time, jds, pol, chans=chans, \\\n",
    "        tints=tints, bad_ants=True, use_flags='first', noise=True)\n",
    "    cdata = cdata.data\n",
    "\n",
    "credg = relabelAnts(md['redg'])     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "automated-timer",
   "metadata": {},
   "outputs": [],
   "source": [
    "NLLFN = {'cauchy': lambda delta: np.log(1 + np.square(np.abs(delta))).sum(axis=(0, -1)),\n",
    "         'gaussian': lambda delta: np.square(np.abs(delta)).sum(axis=(0, -1))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "instructional-discovery",
   "metadata": {},
   "outputs": [],
   "source": [
    "credg = relabelAnts(md['redg'])\n",
    "gvis = xd_vis[..., credg[:, 0]]*xd_gains[..., credg[:, 1]]*np.conj(xd_gains[..., credg[:, 2]])\n",
    "delta = cdata - gvis\n",
    "nlog_likelihood = NLLFN[nll_dist](delta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "guilty-peter",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = clipped_heatmap(nlog_likelihood.transpose(), ylabel='Time integration', \n",
    "                          clip_pctile=98, figsize=(8, 6), clip_rnd=100, xoffset=-chans[0])\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "breeding-indianapolis",
   "metadata": {},
   "source": [
    "### Residuals between solved visibilities and gain transformed observed visibilities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interim-centre",
   "metadata": {},
   "source": [
    "With across days redundant calibration, we obtain a single set of visibilities. We wish to compare these solved visibilities to the observed visibilities on different days, to find potential outliers. The amplitudes of these visibilities could be compared; their phases, however, cannot, since there are degenerate offsets between them. We do not wish to calculate these degenerate offsets, as this is computationally expensive - this would require doing pairs of comparison between the solved xd_rel_cal solutions and each day. What we can do, however, is take the observed visibilities and divide them by the solved gains to get a quantity that is comparable as it is degenerately consistent. The residual between this quantity and the true visibilities is what we use for outlier detection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "laughing-occasions",
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_vis = cdata / xd_gains[..., credg[:, 1]] / np.conj(xd_gains[..., credg[:, 2]])\n",
    "tr_res = xd_vis[..., credg[:, 0]] - tr_vis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "small-settlement",
   "metadata": {},
   "source": [
    "#### Modified Z-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "medieval-pattern",
   "metadata": {},
   "outputs": [],
   "source": [
    "correction = 1.4826\n",
    "mad = np.median(np.abs(tr_res), axis=0) # Median Absolute Deviation\n",
    "modz = np.abs(tr_res)/(correction*np.tile(np.expand_dims(mad, axis=0), \\\n",
    "                                          (md['JDs'].size, 1, 1, 1))) # Modified Z-score\n",
    "# Note that these quantities are about the solve visibility values, and not\n",
    "# about their medians"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "conservative-talent",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_modz = np.mean(modz, axis=(0, -1)) # mean over days and baselines\n",
    "fig, ax = clipped_heatmap(mean_modz.transpose(), 'Time Integration', 'Channel', \\\n",
    "                          clip_pctile=99, figsize=(8, 5), xoffset=-chans[0])\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spanish-collection",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean modified Z-score\n",
    "bad_slicesz = np.where(np.logical_and(modz.mean(axis=-1) > 0.8, ~idr2_flags))\n",
    "print('{} potentially bad slices found that are not flagged through the '\\\n",
    "      'hera_cal pipeline, through z-score considerations'.format(bad_slicesz[0].size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "major-helping",
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at individual baselines\n",
    "bad_slicesz_bl = np.where(np.logical_and(modz > 5.5, \\\n",
    "    ~np.tile(np.expand_dims(idr2_flags, axis=-1), (1, 1, 1, md['redg'].shape[0]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "arranged-consumer",
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_slicesz_bl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "changed-makeup",
   "metadata": {},
   "source": [
    "#### $\\mathcal{R}_{\\mathrm{man}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "retained-genius",
   "metadata": {},
   "source": [
    "$\\mathcal{R}_{\\mathrm{man}}$ already calculated above, but run on last baseline dimension too - should be similar results to modified Z-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sharing-jacob",
   "metadata": {},
   "outputs": [],
   "source": [
    "nrm_resid = norm_residuals(xd_vis[..., credg[:, 0]], tr_vis)\n",
    "abs_resid = np.median(np.abs(nrm_resid), axis=-1) # median over the baseline axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hybrid-consumer",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_abs_resid = np.mean(abs_resid, axis=0) # mean over days\n",
    "vmin = np.nanpercentile(mean_abs_resid, 1)\n",
    "fig, ax = clipped_heatmap(mean_abs_resid.transpose(), 'Time Integration', 'Channel', \\\n",
    "                          clip_pctile=98, vmin=vmin, figsize=(8, 5), xoffset=-chans[0])\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "harmful-jewelry",
   "metadata": {},
   "outputs": [],
   "source": [
    "idr2_jdsx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "single-gasoline",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "# Histograms of NLL, NLL / Noise, R_man to find outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cosmetic-clone",
   "metadata": {},
   "source": [
    "#### LST-Binned files that contain MAD Clipping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "derived-reserve",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

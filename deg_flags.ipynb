{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run fit_diagnostics.py\n",
    "%run red_likelihood.py\n",
    "%run red_utils.py\n",
    "%run plot_utils.py\n",
    "%run test_fns.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config Completer.use_jedi = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final flagging from smooth_abs calfits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib.colors import LinearSegmentedColormap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_figs = True\n",
    "if plot_figs:\n",
    "    import matplotlib as mpl\n",
    "    mpl.rcParams['figure.dpi'] = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "JD1 = 2458098.43869\n",
    "JD_comp = 2458099\n",
    "JD2 = match_lst(JD1, JD_comp, tint=0)\n",
    "JD3 = match_lst(JD1, JD_comp, tint=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "band_edge = 50 # frequency channels to cut\n",
    "add_ba = 14 # additional bad antennas\n",
    "\n",
    "flags1 = np.mean(calfits_to_flags(JD1, 'smooth_abs', pol='ee', add_bad_ants=add_ba), \\\n",
    "                 axis=2).astype(int)[band_edge:-band_edge, :]\n",
    "flags2 = np.mean(calfits_to_flags(JD2, 'smooth_abs', pol='ee', add_bad_ants=add_ba), \\\n",
    "                 axis=2).astype(int)[band_edge:-band_edge, :]\n",
    "flags3 = np.mean(calfits_to_flags(JD3, 'smooth_abs', pol='ee', add_bad_ants=add_ba), \\\n",
    "                 axis=2).astype(int)[band_edge:-band_edge, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_df = pd.read_pickle('jd_lst_map_idr2.pkl')\n",
    "last1 = last_df[last_df['JD_time'] == JD1]['LASTs'].values[0]\n",
    "last2 = last_df[last_df['JD_time'] == JD2]['LASTs'].values[0]\n",
    "_, offset = find_nearest(last2, last1[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flagsc = np.concatenate((flags2[:, offset:], flags3[:, :offset]), axis=1) * 2\n",
    "flagsf = flags1 + flagsc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(11, 7))\n",
    "\n",
    "# Define colors\n",
    "colors = ((1.0, 1.0, 1.0), 'C2', 'C10', (1., 0., 0.))\n",
    "cmap = LinearSegmentedColormap.from_list('Custom', colors, len(colors))\n",
    "\n",
    "ax = sns.heatmap(flagsf.transpose(), cmap=cmap, vmin=0, vmax=3)\n",
    "ax.xaxis.set_major_locator(ticker.MultipleLocator(50))\n",
    "ax.xaxis.set_major_formatter(ticker.ScalarFormatter(useOffset=-50))\n",
    "ax.yaxis.set_major_locator(ticker.MultipleLocator(5))\n",
    "ax.yaxis.set_major_formatter(ticker.ScalarFormatter())\n",
    "ax.set_xlabel('Frequency channel')\n",
    "ax.set_ylabel('Time integration')\n",
    "\n",
    "# Set the colorbar labels\n",
    "colorbar = ax.collections[0].colorbar\n",
    "colorbar.set_ticks(np.array([0., 0.75, 1.5, 2.25]) + 0.375)\n",
    "colorbar.set_ticklabels(['False', '98', '99', 'Both'])\n",
    "# colorbar.set_ticks(np.arange(0, 1.1, 0.1))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Negative log-likelihood histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deg_df_path = 'deg_dfs'\n",
    "rel_df_path = 'rel_dfs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deg_df_j = find_deg_df(JD1, 'ee', 'jd', 'gaussian', dir=deg_df_path)\n",
    "df_j = pd.read_pickle(deg_df_j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flagsr = flagsf.ravel(order='F').astype(int).astype(bool)\n",
    "deg_values = df_j['fun'].values.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flagged_hist(deg_values, flagsr, xlabel=r'$-\\ln(\\mathcal{L}^G_\\mathrm{deg})$', lower_cut=None, \\\n",
    "             upper_cut=0.008, bin_width=0.0002, hist_start=0, ylim=(0, 7000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "suspect_threshold = 0.009\n",
    "suspect_slices = []\n",
    "for i, n in enumerate(deg_values):\n",
    "    if ~flagsr[i]:\n",
    "        if n > suspect_threshold:\n",
    "            suspect_slices.append(df_j.index.values[i] + (i, n))\n",
    "suspect_slices            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Median absolute normalized residual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_j[['med_abs_norm_res_Re', 'med_abs_norm_res_Im']] = df_j.apply(lambda row: \\\n",
    "pd.Series(abs_residuals(row['norm_residual'])), axis=1)\n",
    "\n",
    "df_j['med_abs_norm_res_comb'] = np.sqrt((df_j['med_abs_norm_res_Re']**2 + \\\n",
    "                                        df_j['med_abs_norm_res_Im']**2).values)\n",
    "\n",
    "rman_values = df_j['med_abs_norm_res_comb'].values.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run plot_utils.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flagged_hist(rman_values, flagsr, xlabel=r'$\\mathcal{R}_{man}$', lower_cut=None, \\\n",
    "             upper_cut=0.2, bin_width=0.0025, hist_start=0, ylim=(0, 9000), figsize=(6,6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "suspect_threshold = 0.2\n",
    "suspect_slices = []\n",
    "for i, n in enumerate(rman_values):\n",
    "    if ~flagsr[i]:\n",
    "        if n > suspect_threshold:\n",
    "            suspect_slices.append(df_j.index.values[i] + (i, n))\n",
    "suspect_slices            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_res_heatmap(df_j, 'fun', index='time_int1', columns='freq', clip=True, clip_pctile=95, vmin=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize negative log-likelihoods by visibility amplitude mean/median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_res_heatmap(df_j, 'fun', index='time_int1', columns='freq', clip=True, clip_pctile=95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rel_df_j = pd.read_pickle(find_rel_df(JD1, 'ee', 'gaussian', dir=rel_df_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join('rel_dfs', 'rel_df.{}.{}.md.pkl'.format(JD1, 'ee')), 'rb') as f:\n",
    "    md = pickle.load(f)\n",
    "\n",
    "no_unq_bls = md['no_unq_bls']\n",
    "no_min_p = 5 # number of columns in df that are attributes of the SciPy OptimizeResult \n",
    "vis_df = rel_df_j.iloc[:, no_min_p:no_unq_bls*2+no_min_p]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis_df['vamp_mean'] = vis_df.apply(lambda row: \\\n",
    "                      np.mean(np.abs(makeCArray(row[:no_unq_bls*2].values.astype(float)))), \\\n",
    "                      axis=1)\n",
    "\n",
    "vis_df['vamp_median'] = vis_df.apply(lambda row: \\\n",
    "                        np.median(np.abs(makeCArray(row[:no_unq_bls*2].values.astype(float)))), \\\n",
    "                        axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rel_df_j2a = pd.read_pickle(find_rel_df(JD2, 'ee', 'gaussian', dir=rel_df_path))\n",
    "rel_df_j2b = pd.read_pickle(find_rel_df(JD3, 'ee', 'gaussian', dir=rel_df_path))\n",
    "\n",
    "Nfreqs = rel_df_j.index.get_level_values('freq').unique().size\n",
    "Ntints = rel_df_j.index.get_level_values('time_int').unique().size\n",
    "\n",
    "indices = ['freq', 'time_int']\n",
    "rel_df_j2a = rel_df_j2a[rel_df_j2a.index.get_level_values('time_int') >= offset]\n",
    "rel_df_j2a.reset_index(inplace=True)\n",
    "rel_df_j2a['time_int'] = np.tile(np.arange(Ntints - offset), Nfreqs)\n",
    "rel_df_j2a.set_index(indices, inplace=True)\n",
    "\n",
    "rel_df_j2b = rel_df_j2b[rel_df_j2b.index.get_level_values('time_int') < offset]\n",
    "rel_df_j2b.reset_index(inplace=True)\n",
    "rel_df_j2b['time_int'] = np.tile(np.arange(Ntints - offset, Ntints), Nfreqs)\n",
    "rel_df_j2b.set_index(indices, inplace=True)\n",
    "\n",
    "rel_df_j2 = pd.concat([rel_df_j2a, rel_df_j2b])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis_df2 = rel_df_j2.iloc[:, no_min_p:no_unq_bls*2+no_min_p]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis_df2['vamp_mean'] = vis_df2.apply(lambda row: \\\n",
    "                       np.mean(np.abs(makeCArray(row[:no_unq_bls*2].values.astype(float)))), \\\n",
    "                       axis=1)\n",
    "\n",
    "vis_df2['vamp_median'] = vis_df2.apply(lambda row: \\\n",
    "                         np.median(np.abs(makeCArray(row[:no_unq_bls*2].values.astype(float)))), \\\n",
    "                         axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis_df['vamp_mean_xdmean'] = (vis_df['vamp_mean'] + vis_df2['vamp_mean']) / 2\n",
    "vis_df['vamp_median_xdmean'] = (vis_df['vamp_median'] + vis_df2['vamp_median']) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_res_heatmap(vis_df, 'vamp_mean', clip=True, clip_pctile=97)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_res_heatmap(vis_df, 'vamp_median', clip=True, clip_pctile=97)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_res_heatmap(vis_df, 'vamp_mean_xdmean', clip=True, clip_pctile=97)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_res_heatmap(vis_df, 'vamp_median_xdmean', clip=True, clip_pctile=97)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis_df.reset_index(inplace=True)\n",
    "vis_df.rename(columns={'time_int': 'time_int1'}, inplace=True)\n",
    "vis_df.set_index(['time_int1', 'freq'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_j['mean_nrm_nll'] = df_j['fun'] / vis_df['vamp_mean']**2\n",
    "df_j['median_nrm_nll'] = df_j['fun'] / vis_df['vamp_median']**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_res_heatmap(df_j, 'mean_nrm_nll', index='time_int1', columns='freq', clip=True, clip_pctile=97)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_res_heatmap(df_j, 'median_nrm_nll', index='time_int1', columns='freq', clip=True, clip_pctile=97)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_nrm_nll = df_j['mean_nrm_nll'].values.astype(float)\n",
    "median_nrm_nll = df_j['median_nrm_nll'].values.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flagged_hist(mean_nrm_nll, flagsr, xlabel=r'$-\\ln(\\mathcal{L}^G_\\mathrm{deg}) \\; / \\; \\overline{\\left| V_\\mathrm{obs} \\right|}$', \\\n",
    "             lower_cut=None, upper_cut=25, bin_width=0.5, hist_start=0, ylim=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flagged_hist(median_nrm_nll, flagsr, xlabel=r'$-\\ln(\\mathcal{L}^G_\\mathrm{deg}) \\; / \\; \\mathrm{med} \\left( \\left| V_\\mathrm{obs} \\right| \\right)}$', lower_cut=None, \\\n",
    "             upper_cut=7, bin_width=0.1, hist_start=0, ylim=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "suspect_threshold = 7.5\n",
    "suspect_slices = []\n",
    "for i, n in enumerate(median_nrm_nll):\n",
    "    if ~flagsr[i]:\n",
    "        if n > suspect_threshold:\n",
    "            suspect_slices.append(df_j.index.values[i] + (n,))\n",
    "suspect_slices            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Noise from autos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load inferred noise on data\n",
    "noise_file = os.path.join('..', 'zen.{}.HH.noise_std.uvh5'.format(JD1))\n",
    "hd_noise = HERAData(noise_file)\n",
    "noise, noise_flags, _  = hd_noise.read()\n",
    "RedG = md['redg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bl_var = np.empty((RedG.shape[0], md['Ntimes'], md['Nfreqs']), dtype=complex)\n",
    "for i in range(bl_var.shape[0]):\n",
    "    bl_var[i, ...] = noise[(int(RedG[i, 1]), int(RedG[i, 1]), 'ee')] * \\\n",
    "                     noise[(int(RedG[i, 2]), int(RedG[i, 2]), 'ee')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(11, 7))\n",
    "arr = np.absolute(bl_var.mean(axis=0))[:, 50:-50]\n",
    "vmax = numpy.ceil(numpy.nanpercentile(arr, 92)*100)/100\n",
    "ax = sns.heatmap(arr, vmax=vmax, vmin=None, cmap=sns.cm.rocket_r, center=None)\n",
    "ax.xaxis.set_major_locator(ticker.MultipleLocator(50))\n",
    "ax.xaxis.set_major_formatter(ticker.ScalarFormatter(useOffset=-50))\n",
    "ax.yaxis.set_major_locator(ticker.MultipleLocator(5))\n",
    "ax.yaxis.set_major_formatter(ticker.ScalarFormatter())\n",
    "ax.set_xlabel('freq')\n",
    "ax.set_ylabel('time_int')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_nrm_nll = df_j['fun'].values.astype(float) / arr.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(11, 7))\n",
    "arr = noise_nrm_nll.reshape((60, 924))\n",
    "vmax = numpy.ceil(numpy.nanpercentile(arr, 95)*10000)/10000\n",
    "ax = sns.heatmap(arr, vmax=vmax, vmin=0, cmap=sns.cm.rocket_r, center=None)\n",
    "ax.xaxis.set_major_locator(ticker.MultipleLocator(50))\n",
    "ax.xaxis.set_major_formatter(ticker.ScalarFormatter(useOffset=-50))\n",
    "ax.yaxis.set_major_locator(ticker.MultipleLocator(5))\n",
    "ax.yaxis.set_major_formatter(ticker.ScalarFormatter())\n",
    "ax.set_xlabel('freq')\n",
    "ax.set_ylabel('time_int')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flagged_hist(noise_nrm_nll, flagsr, xlabel=r'$-\\ln(\\mathcal{L}^G_\\mathrm{deg}) \\; / \\; \\sigma_{98}^2} $', lower_cut=None, \\\n",
    "             upper_cut=vmax, bin_width=None, hist_start=0, ylim=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "suspect_threshold = 0.0001\n",
    "suspect_slices = []\n",
    "for i, n in enumerate(noise_nrm_nll):\n",
    "    if ~flagsr[i]:\n",
    "        if n > suspect_threshold:\n",
    "            suspect_slices.append(df_j.index.values[i] + (n,))\n",
    "suspect_slices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load inferred noise on data from 2nd dat\n",
    "noise_file = os.path.join('..', 'zen.{}.HH.noise_std.uvh5'.format(JD2))\n",
    "hd_noise = HERAData(noise_file)\n",
    "noise, _, _  = hd_noise.read()\n",
    "\n",
    "bl_var2a = np.empty((RedG.shape[0], md['Ntimes'], md['Nfreqs']), dtype=complex)\n",
    "for i in range(bl_var2a.shape[0]):\n",
    "    bl_var2a[i, ...] = noise[(int(RedG[i, 1]), int(RedG[i, 1]), 'ee')] * \\\n",
    "                       noise[(int(RedG[i, 2]), int(RedG[i, 2]), 'ee')]\n",
    "    \n",
    "# Load inferred noise on data from 2nd dat\n",
    "noise_file = os.path.join('..', 'zen.{}.HH.noise_std.uvh5'.format(JD3))\n",
    "hd_noise = HERAData(noise_file)\n",
    "noise, _, _  = hd_noise.read()\n",
    "\n",
    "bl_var2b = np.empty((RedG.shape[0], md['Ntimes'], md['Nfreqs']), dtype=complex)\n",
    "for i in range(bl_var2b.shape[0]):\n",
    "    bl_var2b[i, ...] = noise[(int(RedG[i, 1]), int(RedG[i, 1]), 'ee')] * \\\n",
    "                       noise[(int(RedG[i, 2]), int(RedG[i, 2]), 'ee')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bl_var2 = np.concatenate((bl_var2a[:, offset:, :], bl_var2a[:, :offset, :]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bl_varca = (bl_var + bl_var2) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import mode\n",
    "hd = HERAData(find_zen_file(JD1))\n",
    "reds = fltBad(get_reds(hd.antpos, pols=['ee']), get_bad_ants(find_zen_file(JD_time=JD1)))\n",
    "bl_types = RedG[:, 0]\n",
    "slct_bl_type_id = mode(bl_types)[0][0] # selecting modal value for baseline type\n",
    "slct_bl_type = reds[slct_bl_type_id][0]\n",
    "print(slct_bl_type) # 14 m EW baselines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ew_14_bls = numpy.where(RedG[:, 0] == slct_bl_type_id)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bl_varcr = bl_varca[ew_14_bls, ...] # selecting only 14m EW baselines\n",
    "bl_varcr = numpy.mean(np.abs(bl_varcr), axis=0) # average over 14m EW baselines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import savgol_filter\n",
    "from astropy.stats import sigma_clip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nan_helper(y):\n",
    "    return np.isnan(y), lambda z: z.nonzero()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bl_varc = numpy.empty_like(bl_varcr)\n",
    "for i in range(bl_varcr.shape[1]):\n",
    "    bl_varc[:, i] = sigma_clip(bl_varcr[:, i], sigma=4, cenfunc='median').filled(fill_value=np.nan)\n",
    "    nans, x = nan_helper(bl_varc[:, i])\n",
    "    bl_varc[:, i][nans]= np.interp(x(nans), x(~nans), bl_varc[:, i][~nans])\n",
    "    \n",
    "# Savitzky-Golay filter\n",
    "for i in range(bl_varc.shape[1]):\n",
    "    bl_varc[:, i] = savgol_filter(bl_varc[:, i], window_length=17, polyorder=3, mode='interp')\n",
    "    \n",
    "bl_varc[bl_varc < 0] = 1e-8 # zero pad bottom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_freq = 381\n",
    "plt.plot(bl_varcr[:, test_freq])\n",
    "plt.plot(bl_varc[:, test_freq])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.nonparametric.kernel_regression import KernelReg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = KernelReg(bl_varc[test_tint, :], numpy.arange(hd.Nfreqs), var_type='c', reg_type='ll', bw = 'cv_ls')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.fit()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mf = numpy.ma.masked_array(bl_varcr[test_tint, :], fff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_tint = 30\n",
    "fff = numpy.append(numpy.zeros(50), numpy.append(flagsf[:, test_tint], numpy.zeros(50))).astype(bool)\n",
    "plt.plot(bl_varcr[test_tint, :])\n",
    "plt.plot(mf)\n",
    "plt.plot(y_pred)\n",
    "plt.ylim((0, 300))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(11, 7))\n",
    "arr = np.absolute(bl_varca.mean(axis=0))[:, 50:-50]\n",
    "vmax = numpy.ceil(numpy.nanpercentile(arr, 93)*100)/100\n",
    "ax = sns.heatmap(arr, vmax=vmax, vmin=0, cmap=sns.cm.rocket_r, center=None)\n",
    "ax.xaxis.set_major_locator(ticker.MultipleLocator(50))\n",
    "ax.xaxis.set_major_formatter(ticker.ScalarFormatter(useOffset=-50))\n",
    "ax.yaxis.set_major_locator(ticker.MultipleLocator(5))\n",
    "ax.yaxis.set_major_formatter(ticker.ScalarFormatter())\n",
    "ax.set_xlabel('freq')\n",
    "ax.set_ylabel('time_int')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(11, 7))\n",
    "snoise_arr = np.absolute(bl_varc)[:, 50:-50]\n",
    "vmax = numpy.ceil(numpy.nanpercentile(snoise_arr, 93)*100)/100\n",
    "ax = sns.heatmap(snoise_arr, vmax=vmax, vmin=0, cmap=sns.cm.rocket_r, center=None)\n",
    "ax.xaxis.set_major_locator(ticker.MultipleLocator(50))\n",
    "ax.xaxis.set_major_formatter(ticker.ScalarFormatter(useOffset=-50))\n",
    "ax.yaxis.set_major_locator(ticker.MultipleLocator(5))\n",
    "ax.yaxis.set_major_formatter(ticker.ScalarFormatter())\n",
    "ax.set_xlabel('freq')\n",
    "ax.set_ylabel('time_int')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_nrm_nll = df_j['fun'].values.astype(float) / snoise_arr.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(11, 7))\n",
    "arr = noise_nrm_nll.reshape((60, 924))\n",
    "vmax = numpy.ceil(numpy.nanpercentile(arr, 95)*10000)/10000\n",
    "ax = sns.heatmap(arr, vmax=vmax, vmin=0, cmap=sns.cm.rocket_r, center=None)\n",
    "ax.xaxis.set_major_locator(ticker.MultipleLocator(50))\n",
    "ax.xaxis.set_major_formatter(ticker.ScalarFormatter(useOffset=-50))\n",
    "ax.yaxis.set_major_locator(ticker.MultipleLocator(5))\n",
    "ax.yaxis.set_major_formatter(ticker.ScalarFormatter())\n",
    "ax.set_xlabel('freq')\n",
    "ax.set_ylabel('time_int')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run plot_utils.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flagged_hist(noise_nrm_nll, flagsr, xlabel=r'$-\\ln(\\mathcal{L}^G_\\mathrm{deg}) \\; / \\; \\sigma_{14m}^2 $', lower_cut=None, \\\n",
    "             upper_cut=0.000098, bin_width=vmax/50, hist_start=0, logy=False, ylim=None, figsize=(6, 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snoise_arr[1, 311]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_nrm_nll[34472] / snoise_arr.ravel()[34472]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "0.000098"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "suspect_threshold = 0.000098\n",
    "suspect_slices = []\n",
    "for i, n in enumerate(noise_nrm_nll):\n",
    "    if ~flagsr[i]:\n",
    "        if n > suspect_threshold:\n",
    "            tint, freq = df_j.index.values[i]\n",
    "            suspect_slices.append(df_j.index.values[i] + (i, n, rman_values[i], deg_values[i], snoise_arr.ravel()[i],))\n",
    "#             suspect_slices.append((deg_values[i], arr[i], rman_values[i])\n",
    "suspect_slices.sort(key=lambda x: x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "suspect_slices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[(44, 908, 41514, 0.2005497625082851), (31, 910, 29504, 0.20712143320814252)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 41514\n",
    "print(df_j.index.values[i] + (i, noise_nrm_nll[i], rman_values[i], deg_values[i], snoise_arr.ravel()[i],))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis_list = list(map(str, np.arange(md['no_unq_bls']*2).tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visC_df = vis_df[vis_list].apply(lambda row: makeCArray(row.values), axis=1)\n",
    "visC_df = pd.DataFrame(visC_df.values.tolist(), index=visC_df.index)\n",
    "# visC_tint_df = visC_df.loc[pd.IndexSlice[:, test_tint], :].droplevel(level=1)\n",
    "# visamp_tint_df = np.abs(visC_tint_df)\n",
    "# visphase_tint_df = visC_tint_df.apply(np.angle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visC_14ew = visC_df[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%gui qt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import napari"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = visC_14ew.loc[:, 311].values\n",
    "np.var(a.real) + np.var(a.imag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.angle(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.abs(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = vis_df[vis_list[::2]].groupby(level=['freq']).std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.mean(axis=1)[51]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.loc[50, ]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "193px",
    "width": "395px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

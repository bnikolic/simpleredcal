{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import numpy\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy import stats as stats\n",
    "\n",
    "from red_likelihood import degVis, doRelCal, doOptCal, doDegVisVis, group_data, gVis, \\\n",
    "makeCArray, red_ant_sep, relabelAnts\n",
    "from red_utils import abs_residuals, cplot, find_zen_file, find_nearest, get_bad_ants, norm_residuals, \\\n",
    "plot_red_vis, split_rel_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numpy.set_printoptions(threshold=sys.maxsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "pol = 'ee'\n",
    "freq_channel = 300\n",
    "time_integration = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = find_zen_file(2458098.43869)\n",
    "bad_ants = get_bad_ants(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdraw, RedG, cData = group_data(filename, pol, freq_channel, bad_ants)\n",
    "\n",
    "# mitigating for multiple freqs - only chooses first one\n",
    "if cData.shape[0] > 1:\n",
    "    cData = cData[0, ...]\n",
    "    print('Frequency channel {} selected for notebook analysis'.format(freq_channel[0]))\n",
    "cData = numpy.squeeze(cData)\n",
    "\n",
    "ants = numpy.unique(RedG[:,1:])\n",
    "no_unq_bls = numpy.unique(RedG[:, 0]).size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_red_vis(cData, RedG, vis_type='amp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Redundant calibration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fundamentally, the problem of calibration boils down to the measurement equation:\n",
    "\n",
    "$$ V_{ij}^{\\text{obs}} (\\nu) = g_i (\\nu) g_j^* (\\nu) V_{ij}^{\\text{true}}(\\nu) + n_{ij} (\\nu) $$\n",
    "\n",
    "where the observed visibility $V_{ij}$ between antennas $i$ and $j$ at a given time and frequency is related to the true, underlying visibility by a pair of complex and frequency-dependent gain factors, $g_i$ and $g_j$, if we assume per-antenna gains, along with uncorrelated Gaussian random noise $n_{ij}$. The ultimate aim of calibration is to solve for these gains and visibilities. \n",
    "\n",
    "For a redundant array, we have a system of equations for all antenna pairs $i$ and $j$, given by\n",
    "\n",
    "$$ V_{ij}^{\\text{obs}} (\\nu) = g_i (\\nu) g_j^* (\\nu) U_{\\alpha}(\\nu) $$\n",
    "\n",
    "where $U_{\\alpha}(\\nu) = V(\\mathbf{r}_i-\\mathbf{r}_j)$, the visibility for the baseline vector $ \\mathbf{b}_{ij} = \\mathbf{r}_i-\\mathbf{r}_j$, which corresponds to a redundant baseline set that we index by $\\alpha$. Two pairs of identical elements with precisely the same baseline separation between them are sensitive to the same mode on the sky, and are thus measuring the same $V_{ij}^{\\text{true}}$.\n",
    "\n",
    "In highly redundant arrays, there are many more observations than there are unique baselines. For the full HERA array, there are 331 elements in the hexagonal core, corresponding to $N_{\\mathrm{bl}} = 331(331-1)/2 = 54,615$ baselines. The hexagonal core only has 630 unique baseline separations, this means we have a non-linear system of $54,615$ equations to determine 630 unique visibilities and the 331 complex gains; the system is vastly overdetermined."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Relative calibration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gaussian distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By imposing that the true sky visibilities from redundant baselines are equal, relative redundant calibration solves for the true sky visibilities for each redundant baseline set $V_{i-j}^{\\text{sol}}$, alongside the gains of the individual antennas.\n",
    "\n",
    "Assuming Gaussian uncorrelated noise with variance $\\sigma_{ij}^2$, a maximum-likelihood estimate for the gains and sky visibilities can be constructed:\n",
    "\n",
    "$$ \\mathcal{L} (\\{g_i(\\nu)\\}, \\{U_{\\alpha}(\\nu)\\} | \\{V_{ij}^{\\text{obs}}(\\nu)\\} \\propto \\prod_{\\nu} \\prod_{\\alpha} \\prod_{\\{i,j\\}_{\\alpha}} \\exp{\\left( -\\frac{1}{2} \\left( \\frac{ \\left| V_{ij}^{\\text{obs}} (\\nu) - g_i (\\nu) g_j^{*} (\\nu) U_{\\alpha}(\\nu) \\right|^2}{\\sigma_{ij}^2(\\nu)} \\right) \\right)} $$\n",
    "\n",
    "where $\\{i,j\\}_{\\alpha}$ are sets of antennas that belong to each redundant baseline type $\\alpha$. Maximizing this function is equivalent to minimizing:\n",
    "\n",
    "$$ \\chi_{\\mathrm{rel}}^{2} (\\nu) = \\sum_{\\alpha} \\sum_{\\{i,j\\}_{\\alpha}} \\frac{ \\left| V_{ij}^{\\text{obs}} (\\nu) - g_i (\\nu) g_j^* (\\nu) U_{\\alpha}(\\nu) \\right|^2 }{\\sigma_{ij}^2(\\nu)} $$\n",
    "\n",
    "by varying $g_k(\\nu)$ and $U_{\\alpha}(\\nu)$ for each frequency $\\nu$.\n",
    "\n",
    "This non-linear least-squares optimization can be done independently between frequencies and time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cauchy distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We no longer assume that the noise in the measurement equation is Gaussian. Empirically, it is found that visibility observations can have a lot of outliers, and the visibilities follow a distribution with fatter tails than a Gaussian. We wish to be insensitive to outliers, so we need to employ robust statistics to adequately deal with such measurements.\n",
    "\n",
    "Instead of fitting the visibilities to a Gaussian, we fit them to a Cauchy distribution, when solving the redundant calibration parameter estimation.\n",
    "\n",
    "The Cauchy distribution is given by\n",
    "\n",
    "$$ f(x; x_0, \\gamma) = \\frac{1}{\\pi \\gamma \\left[ 1 + \\left( \\frac{x - x_0}{\\gamma}  \\right)^2  \\right] }$$\n",
    "\n",
    "where $x_0$ is the location parameter (the median) and $\\gamma$ is the scale parameter, which specifies the half-width at half-maximum (HWHM).\n",
    "\n",
    "Working in a maximum likelihood framework, the likelihood when solving for the measurement equation for redundant baseline sets is given by\n",
    "\n",
    "$$ \\mathcal{L} = \\prod_{\\nu} \\prod_{\\alpha} \\prod_{\\{i,j\\}_{\\alpha}} \\frac{1}{\\pi \\gamma_{\\alpha} (\\nu)} \\left[ 1 + \\left( \\frac{\\left| V_{ij}^{\\text{obs}} (\\nu) - g_i (\\nu) g_j^* (\\nu) U_{\\alpha}(\\nu) \\right|}{\\gamma_{\\alpha} (\\nu)}  \\right)^2  \\right]^{-1} $$\n",
    "\n",
    "The negative log-likelihood is therefore given by\n",
    "\n",
    "$$ -\\ln(\\mathcal{L}) (\\nu) = \\sum_{\\alpha} \\sum_{\\{i,j\\}_{\\alpha}} \\ln(\\pi \\gamma_{\\alpha} (\\nu)) + \\ln \\left( 1 + \\left( \\frac{\\left| V_{ij}^{\\text{obs}} (\\nu) - g_i (\\nu) g_j^* (\\nu) U_{\\alpha}(\\nu) \\right|}{\\gamma_{\\alpha}(\\nu)}  \\right)^2 \\right) $$\n",
    "\n",
    "where we have dropped the sum over frequency, as we can solve independently for each frequency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_vis = cData[time_integration, :]\n",
    "res_rel = doRelCal(RedG, obs_vis, distribution='cauchy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_rel_vis, res_rel_gains = split_rel_results(res_rel, no_unq_bls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Residuals for relative redundant step\n",
    "pred_rel_vis = gVis(res_rel_vis, relabelAnts(RedG), res_rel_gains)\n",
    "rel_residuals = obs_vis - pred_rel_vis\n",
    "cplot(rel_residuals, xlabel='Baseline', ylabel='Residual')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Relative residuals normalized by amplitude\n",
    "norm_rel_residuals = norm_residuals(obs_vis, pred_rel_vis)\n",
    "cplot(norm_rel_residuals, xlabel='Redundant baseline type', ylabel='Residual')\n",
    "print('Median absolute normalized residual - Real: {}, Imag: {}'.format(*abs_residuals(norm_rel_residuals)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "autoscroll": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "## Optimal calibration (solving for degeneracies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Relative calibration yields degenerate solutions, that can be parameterized as four terms per frequency:\n",
    " - Overall amplitude $A(\\nu)$\n",
    " - Overall phase $\\Delta(\\nu)$\n",
    " - Phase gradient components $\\Delta_x(\\nu)$ and $\\Delta_y(\\nu)$\n",
    " \n",
    "The below transformations of these degenerate parameters leave $-\\ln(\\mathcal{L})$ (for both Gaussian and Cauchy distributions) unchanged:\n",
    " - $g_i \\rightarrow A g_i$ accompanied by $U_{\\alpha} \\rightarrow A^{-2} U_{\\alpha}$\n",
    " - $g_k = |g_k|e^{i\\phi_k} \\rightarrow |g_k|e^{i(\\phi_k + \\Delta)}$ corresponds to $g_k g_l^{*} = |g_k| |g_l| e^{i(\\phi_k - \\phi_l)} \\rightarrow |g_k| |g_l| e^{i(\\phi_k + \\Delta - \\phi_l - \\Delta)} = g_k g_l^{*}$\n",
    " - $g_k = |g_k|e^{i\\phi_k} \\rightarrow |g_k|e^{i(\\phi_k + \\Delta_x x_k + \\Delta_y y_k)}$ accompanied by $U_{\\alpha} = |U_{\\alpha}| e^{i\\phi_{\\alpha}} \\rightarrow |U_{\\alpha}| e^{i(\\phi_{\\alpha} - \\Delta_x x_{\\alpha} - \\Delta_y y_{\\alpha})}$\n",
    " \n",
    "Where in the last line, the array is assumed to be co-planar, and $(x_k, y_k)$ are the coordinates of the position of antennas $k$, and $(x_{\\alpha}, y_{\\alpha})$ are the separations of the antennas that form baselines in redundant set $\\alpha$.\n",
    "\n",
    "These degeneracies must be constrained - this is the \"absolute\" part of redundant calibration. The degenerate parameters can either calculated from a sky model, or can be solved for using optimal absolute calibration, which calculates the degenerate parameters directly from the $\\chi^2$ or $-\\ln(\\mathcal{L})$ by applying a few conditions.\n",
    "\n",
    " - Gaussian distribution:\n",
    " \n",
    "$$ \\chi_{\\text{opt}}^2 (\\nu) = \\sum_{\\alpha} \\sum_{\\{i,j\\}_{\\alpha}} \\frac{ \\left|  V_{ij}^{\\text{obs}} (\\nu) - h_i (\\nu) h_j^{*} (\\nu) W_{\\alpha} (\\nu) \\right|^2 }{\\sigma_{ij}^2(\\nu)} $$\n",
    "\n",
    "\n",
    "where\n",
    "\n",
    "$$ W_{\\alpha} (\\nu) = A^2(\\nu) e^{i \\left[ \\Delta_{x} (\\nu) x_{\\alpha} + \\Delta_{y} (\\nu) y_{\\alpha} \\right]} U_{\\alpha} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_opt = doOptCal(RedG, obs_vis, hdraw.antpos, res_rel_vis, distribution='cauchy', \\\n",
    "                   ref_ant=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_gain_params, new_deg_params = numpy.split(res_opt['x'], [ants.size*2,])\n",
    "new_gains = makeCArray(new_gain_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Degenerate parameters: {}'.format(str(new_deg_params)[1: -1]))\n",
    "print('Amplitude average: {}'.format(numpy.average(numpy.abs(new_gains))))\n",
    "print('Phase circular mean: {}'.format(stats.circmean(numpy.angle(new_gains))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimal residuals for optimal redundant step\n",
    "ant_sep = red_ant_sep(RedG, hdraw.antpos)\n",
    "opt_w_alpha = degVis(ant_sep, res_rel_vis, *new_deg_params[[0, 2, 3]])\n",
    "pred_opt_vis = gVis(opt_w_alpha, relabelAnts(RedG), new_gains)\n",
    "opt_residuals =  obs_vis - pred_opt_vis\n",
    "cplot(opt_residuals, xlabel='Baseline', ylabel='Residual')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 8))\n",
    "plt.plot(obs_vis.real)\n",
    "plt.plot(pred_opt_vis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Residuals normalized by amplitude\n",
    "norm_opt_residuals = norm_residuals(obs_vis, pred_opt_vis)\n",
    "cplot(norm_opt_residuals, xlabel='Redundant baseline type', ylabel='Residual')\n",
    "print('Median absolute normalized residual - Real: {}, Imag: {}'.format(*abs_residuals(norm_opt_residuals)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing relative calibrations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To monitor the consistency of the \"true\" visibility solutions for each baseline set, we calculate the relative calibration visibility solutions from another JD and compare them to the relative solutions of the initial dataset. These should be consistent, up to the degenerate parameters $A$, $\\Delta$, $\\Delta_x$ and $\\Delta_y$ - solving for these parameters with an MLE framework enables us to compare these solutions.\n",
    "\n",
    "We need to minimize:\n",
    "\n",
    "- Assuming Gaussian distributions:\n",
    "\n",
    "$$ \\chi^2_{\\text{deg}} (\\nu) = \\sum_{\\alpha} \\sum_{\\{i,j\\}_{\\alpha}} \\frac{ \\left| U_{\\alpha}' (\\nu) - W_{\\alpha} (\\nu) \\right|^2 }{\\sigma_{\\alpha}^2(\\nu)} $$\n",
    "\n",
    "- Assuming Cauchy distributions:\n",
    "\n",
    "$$-\\ln(\\mathcal{L}) = \\sum_{\\alpha} \\sum_{\\{i,j\\}_{\\alpha}} \\ln(\\pi \\gamma_{\\alpha}) + \\ln \\left( 1 + \\left( \\frac{\\left| U_{\\alpha}' (\\nu) - W_{\\alpha} (\\nu) \\right|}{\\gamma_{\\alpha}}  \\right)^2 \\right) $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename2 = find_zen_file(2458099.43869)\n",
    "bad_ants2 = get_bad_ants(filename2)\n",
    "print('Do {} and {} have the same bad antennas? {}'.format(os.path.basename(filename), \\\n",
    "      os.path.basename(filename2), bad_ants == bad_ants2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdraw2, RedG2, cData2 = group_data(filename2, pol, freq_channel, bad_ants2)\n",
    "if cData2.shape[0] > 1:\n",
    "    cData2 = cData2[0, ...]\n",
    "cData2 = numpy.squeeze(cData2)  \n",
    "\n",
    "no_unq_bls2 = numpy.unique(RedG2[:, 0]).size\n",
    "print('Do {} and {} have the same redundant grouping? {}'.format(os.path.basename(filename), \\\n",
    "      os.path.basename(filename2), (RedG==RedG2).all()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find time integration in dataset 2 that corresponds to closest LST to that of dataset 1\n",
    "# This currently assumes that dataset 2 contains the correct time integration...\n",
    "time_integration2 = find_nearest(hdraw2.lsts, hdraw.lsts[time_integration])[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_red_vis(cData2, RedG2, vis_type='amp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Relative calibration for the 2nd dataset\n",
    "res_rel2 = doRelCal(RedG2, cData2[time_integration2, :], distribution='cauchy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_rel_vis2, res_rel_gains2 = split_rel_results(res_rel2, no_unq_bls2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_deg = doDegVisVis(RedG, hdraw.antpos, res_rel_vis, res_rel_vis2, distribution='cauchy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deg_tr_params = res_deg['x']\n",
    "print(deg_tr_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Residuals for degenerate comparison\n",
    "deg_w_alpha = degVis(ant_sep, res_rel_vis, *deg_tr_params[[0, 2, 3]])\n",
    "deg_residuals = res_rel_vis2 - deg_w_alpha\n",
    "cplot(deg_residuals, xlabel='Redundant baseline type', ylabel='Residual')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Degenerate residuals normalized by amplitude\n",
    "norm_deg_residuals = norm_residuals(res_rel_vis2, deg_w_alpha)\n",
    "cplot(norm_deg_residuals, xlabel='Redundant baseline type', ylabel='Residual')\n",
    "print('Median absolute normalized residual - Real: {}, Imag: {}'.format(*abs_residuals(norm_deg_residuals)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "name": "SimpleRedCal.ipynb",
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "12px",
    "width": "252px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": null,
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

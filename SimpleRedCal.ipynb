{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "import numpy\n",
    "import scipy\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy import stats as stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numpy.set_printoptions(threshold=sys.maxsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "%run red_likelihood.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "pol = 'ee'\n",
    "freq_channel = 300\n",
    "time_integration = 0\n",
    "bad_ants = [0, 2, 11, 24, 50, 53, 54, 67, 69, 98, 122, 136, 139]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdm_fn = '/Users/matyasmolnar/Downloads/HERA_Data/robust_cal/zen.2458098.43869.HH.uvh5'\n",
    "if os.path.exists(mdm_fn):\n",
    "    filename = mdm_fn\n",
    "else:\n",
    "    filename = './zen.2458098.43869.HH.uvh5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdraw, cRedG, cData = group_data(filename, pol, freq_channel, bad_ants)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "def plot_red_vis(data, redg, vis_type='amp'):\n",
    "    \"\"\"Pot visibility amplitudes or phases, grouped by redundant type\"\"\"\n",
    "    vis_calc = {'amp':np.absolute, 'phase': np.angle}\n",
    "    bl_id_seperations = numpy.unique(redg[:, 0], return_index=True)[1][1:]\n",
    "    fig, ax = plt.subplots(figsize=(13,4))\n",
    "    ax.matshow(vis_calc[vis_type](data), aspect='auto')\n",
    "    for bl_id_seperation in bl_id_seperations:\n",
    "        plt.axvline(x=bl_id_seperation, color='white', linestyle='-.', linewidth=1)\n",
    "    ax.grid(False)\n",
    "    ax.set_xlabel('Baseline ID')\n",
    "    ax.set_ylabel('Time Integration')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_red_vis(cData, cRedG, vis_type='amp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Redundant calibration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fundamentally, the problem of calibration boils down to the measurement equation:\n",
    "\n",
    "$$ V_{ij}^{\\text{obs}} (\\nu) = g_i (\\nu) g_j^* (\\nu) V_{ij}^{\\text{true}}(\\nu) + n_{ij} (\\nu) $$\n",
    "\n",
    "where the observed visibility $V_{ij}$ between antennas $i$ and $j$ at a given time and frequency is related to the true, underlying visibility by a pair of complex and frequency-dependent gain factors, $g_i$ and $g_j$, if we assume per-antenna gains, along with uncorrelated Gaussian random noise $n_{ij}$. The ultimate aim of calibration is to solve for these gains and visibilities. \n",
    "\n",
    "For a redundant array, we have a system of equations for all antenna pairs $i$ and $j$, given by\n",
    "\n",
    "$$ V_{ij}^{\\text{obs}} (\\nu) = g_i (\\nu) g_j^* (\\nu) U_{\\alpha}(\\nu) $$\n",
    "\n",
    "where $U_{\\alpha}(\\nu) = V(\\mathbf{r}_i-\\mathbf{r}_j)$, the visibility for the baseline vector $ \\mathbf{b}_{ij} = \\mathbf{r}_i-\\mathbf{r}_j$, which corresponds to a redundant baseline set that we index by $\\alpha$. Two pairs of identical elements with precisely the same baseline separation between them are sensitive to the same mode on the sky, and are thus measuring the same $V_{ij}^{\\text{true}}$.\n",
    "\n",
    "In highly redundant arrays, there are many more observations than there are unique baselines. For the full HERA array, there are 331 elements in the hexagonal core, corresponding to $N_{\\mathrm{bl}} = 331(331-1)/2 = 54,615$ baselines. The hexagonal core only has 630 unique baseline separations, this means we have a non-linear system of $54,615$ equations to determine 630 unique visibilities and the 331 complex gains; the system is vastly overdetermined."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Relative calibration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gaussian distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By imposing that the true sky visibilities from redundant baselines are equal, relative redundant calibration solves for the true sky visibilities for each redundant baseline set $V_{i-j}^{\\text{sol}}$, alongside the gains of the individual antennas.\n",
    "\n",
    "Assuming Gaussian uncorrelated noise with variance $\\sigma_{ij}^2$, a maximum-likelihood estimate for the gains and sky visibilities can be constructed:\n",
    "\n",
    "$$ \\mathcal{L} (\\{g_i(\\nu)\\}, \\{U_{\\alpha}(\\nu)\\} | \\{V_{ij}^{\\text{obs}}(\\nu)\\} \\propto \\prod_{\\nu} \\prod_{\\alpha} \\prod_{\\{i,j\\}_{\\alpha}} \\exp{\\left( -\\frac{1}{2} \\left( \\frac{ \\left| V_{ij}^{\\text{obs}} (\\nu) - g_i (\\nu) g_j^{*} (\\nu) U_{\\alpha}(\\nu) \\right|^2}{\\sigma_{ij}^2(\\nu)} \\right) \\right)} $$\n",
    "\n",
    "where $\\{i,j\\}_{\\alpha}$ are sets of antennas that belong to each redundant baseline type $\\alpha$. Maximizing this function is equivalent to minimizing:\n",
    "\n",
    "$$ \\chi_{\\mathrm{rel}}^{2} (\\nu) = \\sum_{\\alpha} \\sum_{\\{i,j\\}_{\\alpha}} \\frac{ \\left| V_{ij}^{\\text{obs}} (\\nu) - g_i (\\nu) g_j^* (\\nu) U_{\\alpha}(\\nu) \\right|^2 }{\\sigma_{ij}^2(\\nu)} $$\n",
    "\n",
    "by varying $g_k(\\nu)$ and $U_{\\alpha}(\\nu)$ for each frequency $\\nu$.\n",
    "\n",
    "This non-linear least-squares optimization can be done independently between frequencies and time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cauchy distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We no longer assume that the noise in the measurement equation is Gaussian. Empirically, it is found that visibility observations can have a lot of outliers, and the visibilities follow a distribution with fatter tails than a Gaussian. We wish to be insensitive to outliers, so we need to employ robust statistics to adequately deal with such measurements.\n",
    "\n",
    "Instead of fitting the visibilities to a Gaussian, we fit them to a Cauchy distribution, when solving the redundant calibration parameter estimation.\n",
    "\n",
    "The Cauchy distribution is given by\n",
    "\n",
    "$$ f(x; x_0, \\gamma) = \\frac{1}{\\pi \\gamma \\left[ 1 + \\left( \\frac{x - x_0}{\\gamma}  \\right)^2  \\right] }$$\n",
    "\n",
    "where $x_0$ is the location parameter (the median) and $\\gamma$ is the scale parameter, which specifies the half-width at half-maximum (HWHM).\n",
    "\n",
    "Working in a maximum likelihood framework, the likelihood when solving for the measurement equation for redundant baseline sets is given by\n",
    "\n",
    "$$ \\mathcal{L} = \\prod_{\\nu} \\prod_{\\alpha} \\prod_{\\{i,j\\}_{\\alpha}} \\frac{1}{\\pi \\gamma_{\\alpha} (\\nu)} \\left[ 1 + \\left( \\frac{\\left| V_{ij}^{\\text{obs}} (\\nu) - g_i (\\nu) g_j^* (\\nu) U_{\\alpha}(\\nu) \\right|}{\\gamma_{\\alpha} (\\nu)}  \\right)^2  \\right]^{-1} $$\n",
    "\n",
    "The negative log-likelihood is therefore given by\n",
    "\n",
    "$$ -\\ln(\\mathcal{L}) (\\nu) = \\sum_{\\alpha} \\sum_{\\{i,j\\}_{\\alpha}} \\ln(\\pi \\gamma_{\\alpha} (\\nu)) + \\ln \\left( 1 + \\left( \\frac{\\left| V_{ij}^{\\text{obs}} (\\nu) - g_i (\\nu) g_j^* (\\nu) U_{\\alpha}(\\nu) \\right|}{\\gamma_{\\alpha}(\\nu)}  \\right)^2 \\right) $$\n",
    "\n",
    "where we have dropped the sum over frequency, as we can solve independently for each frequency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# Finding all the antennas used in our flagged data\n",
    "ants = numpy.unique(cRedG[:,1:])\n",
    "no_unq_bls = numpy.unique(cRedG[:, 0]).size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# Setup initial parameters\n",
    "xvis = numpy.ones(no_unq_bls*2) # Number of unique baselines; complex vis\n",
    "xgains = numpy.ones(ants.size*2) # Complex gain\n",
    "rel_xparams = numpy.hstack([xvis, xgains])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# This creates a compiled version of likelihood where the first (the redundant groups),\n",
    "# second (the error distribution) and third (observed visibilities) parameters \n",
    "# have already been filled in [-- this is \"partial\" fn application]\n",
    "ff = jit(functools.partial(relative_logLkl, relabelAnts(cRedG), 'cauchy', \\\n",
    "                           cData[time_integration, :]))\n",
    "res_rel = scipy.optimize.minimize(ff, rel_xparams, jac=jacrev(ff))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "def split_rel_results(results):\n",
    "    \"\"\"Split results from minimization into visibility and gains arrays\"\"\"\n",
    "    vis_params, gains_params = numpy.split(results['x'], [no_unq_bls*2,])\n",
    "    vis_params = vis_params.reshape((-1, 2))\n",
    "    gains_params = gains_params.reshape((-1, 2))\n",
    "    res_vis = vis_params[:, 0] + 1j*vis_params[:, 1]\n",
    "    res_gains = gains_params[:, 0] + 1j*gains_params[:, 1]\n",
    "    return res_vis, res_gains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_rel_vis, res_rel_gains = split_rel_results(res_rel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "autoscroll": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "## Optimal calibration (solving for degeneracies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Relative calibration yields degenerate solutions, that can be parameterized as four terms per frequency:\n",
    " - Overall amplitude $A(\\nu)$\n",
    " - Overall phase $\\Delta(\\nu)$\n",
    " - Phase gradient components $\\Delta_x(\\nu)$ and $\\Delta_y(\\nu)$\n",
    " \n",
    "The below transformations of these degenerate parameters leave $-\\ln(\\mathcal{L})$ (for both Gaussian and Cauchy distributions) unchanged:\n",
    " - $g_i \\rightarrow A g_i$ accompanied by $U_{\\alpha} \\rightarrow A^{-2} U_{\\alpha}$\n",
    " - $g_k = |g_k|e^{i\\phi_k} \\rightarrow |g_k|e^{i(\\phi_k + \\Delta)}$ corresponds to $g_k g_l^{*} = |g_k| |g_l| e^{i(\\phi_k - \\phi_l)} \\rightarrow |g_k| |g_l| e^{i(\\phi_k + \\Delta - \\phi_l - \\Delta)} = g_k g_l^{*}$\n",
    " - $g_k = |g_k|e^{i\\phi_k} \\rightarrow |g_k|e^{i(\\phi_k + \\Delta_x x_k + \\Delta_y y_k)}$ accompanied by $U_{\\alpha} = |U_{\\alpha}| e^{i\\phi_{\\alpha}} \\rightarrow |U_{\\alpha}| e^{i(\\phi_{\\alpha} - \\Delta_x x_{\\alpha} - \\Delta_y y_{\\alpha})}$\n",
    " \n",
    "Where in the last line, the array is assumed to be co-planar, and $(x_k, y_k)$ are the coordinates of the position of antennas $k$, and $(x_{\\alpha}, y_{\\alpha})$ are the separations of the antennas that form baselines in redundant set $\\alpha$.\n",
    "\n",
    "These degeneracies must be constrained - this is the \"absolute\" part of redundant calibration. The degenerate parameters can either calculated from a sky model, or can be solved for using optimal absolute calibration, which calculates the degenerate parameters directly from the $\\chi^2$ or $-\\ln(\\mathcal{L})$ by applying a few conditions.\n",
    "\n",
    " - Gaussian distribution:\n",
    " \n",
    "$$ \\chi_{\\text{opt}}^2 (\\nu) = \\sum_{\\alpha} \\sum_{\\{i,j\\}_{\\alpha}} \\frac{ \\left|  V_{ij}^{\\text{obs}} (\\nu) - h_i (\\nu) h_j^{*} (\\nu) W_{\\alpha} (\\nu) \\right|^2 }{\\sigma_{ij}^2(\\nu)} $$\n",
    "\n",
    "\n",
    "where\n",
    "\n",
    "$$ W_{\\alpha} (\\nu) = A^2(\\nu) e^{i \\left[ \\Delta_{x} (\\nu) x_{\\alpha} + \\Delta_{y} (\\nu) y_{\\alpha} \\right]} U_{\\alpha} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup initial parameters\n",
    "xamp = 1.\n",
    "xoverall_phase = 1.\n",
    "xphase_grad_x = 1.\n",
    "xphase_grad_y = 1.\n",
    "opt_xparams = numpy.hstack([xgains, xamp, xoverall_phase, xphase_grad_x, xphase_grad_y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_ant = 12 # reference antenna number to set overall phase\n",
    "\n",
    "constraints = Deg_Constraints(ants, ref_ant, hdraw.antpos)\n",
    "cons = [{'type': 'eq', 'fun': constraints.avg_amp},\n",
    "        {'type': 'eq', 'fun': constraints.avg_phase},\n",
    "        {'type': 'eq', 'fun': constraints.ref_phase},\n",
    "        {'type': 'eq', 'fun': constraints.phase_grad}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ff = jit(functools.partial(optimal_logLkl, relabelAnts(cRedG), 'gaussian', \\\n",
    "                           red_ant_sep(cRedG, hdraw.antpos), cData[time_integration, :], \\\n",
    "                           res_rel_vis))\n",
    "res_deg = scipy.optimize.minimize(ff, opt_xparams, constraints=cons, jac=jacrev(ff), \\\n",
    "                                  method='trust-constr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_gain_params, deg_params = np.split(res_deg['x'], [ants.size*2,])\n",
    "new_gain_params = new_gain_params.reshape((-1, 2))\n",
    "new_gains = new_gain_params[:, 0] + 1j*new_gain_params[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Degenerate parameters: {}'.format(str(deg_params)[1: -1]))\n",
    "print('Amplitude average: {}'.format(np.average(np.abs(new_gains))))\n",
    "print('Phase circular mean: {}'.format(stats.circmean(np.angle(new_gains))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing relative calibrations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To monitor the consistency of the \"true\" visibility solutions for each baseline set, we calculate the relative calibration visibility solutions from another JD and compare them to the relative solutions of the initial dataset. These should be consistent, up to the degenerate parameters $A$, $\\Delta$, $\\Delta_x$ and $\\Delta_y$ - solving for these parameters with an MLE framework enables us to compare these solutions.\n",
    "\n",
    "We need to minimize:\n",
    "\n",
    "- Assuming Gaussian distributions:\n",
    "\n",
    "$$ \\chi^2_{\\text{deg}} (\\nu) = \\sum_{\\alpha} \\sum_{\\{i,j\\}_{\\alpha}} \\frac{ \\left| U_{\\alpha}' (\\nu) - W_{\\alpha} (\\nu) \\right|^2 }{\\sigma_{\\alpha}^2(\\nu)} $$\n",
    "\n",
    "- Assuming Cauchy distributions:\n",
    "\n",
    "$$-\\ln(\\mathcal{L}) = \\sum_{\\alpha} \\sum_{\\{i,j\\}_{\\alpha}} \\ln(\\pi \\gamma_{\\alpha}) + \\ln \\left( 1 + \\left( \\frac{\\left| U_{\\alpha}' (\\nu) - W_{\\alpha} (\\nu) \\right|}{\\gamma_{\\alpha}}  \\right)^2 \\right) $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdm_fn2 = '/Users/matyasmolnar/Downloads/HERA_Data/robust_cal/zen.2458099.43869.HH.uvh5'\n",
    "if os.path.exists(mdm_fn2):\n",
    "    filename2 = mdm_fn2\n",
    "else:\n",
    "    filename2 = './zen.2458099.43869.HH.uvh5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdraw2, cRedG2, cData2 = group_data(filename2, pol, freq_channel, bad_ants)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Do {} and {} have the same redundant grouping? {}'.format(os.path.basename(filename), \\\n",
    "      os.path.basename(filename2), (cRedG==cRedG2).all()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_red_vis(cData2, cRedG2, vis_type='amp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Relative calibration for the 2nd dataset\n",
    "ff = jit(functools.partial(relative_logLkl, relabelAnts(cRedG2), 'cauchy', \\\n",
    "                           cData2[time_integration, :]))\n",
    "res_rel2 = scipy.optimize.minimize(ff, rel_xparams, jac=jacrev(ff))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_rel_vis2, res_rel_gains2 = split_rel_results(res_rel2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deg_xparams = numpy.hstack([xamp, xoverall_phase, xphase_grad_x, xphase_grad_y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run red_likelihood\n",
    "# Calculate degenerate parameters that translate between dataset 1 and dataset 2\n",
    "ff = jit(functools.partial(deg_logLkl, 'cauchy', red_ant_sep(cRedG2, hdraw2.antpos), \\\n",
    "                           res_rel_vis, res_rel_vis2))\n",
    "res_deg = scipy.optimize.minimize(ff, deg_xparams, jac=jacrev(ff))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "name": "SimpleRedCal.ipynb",
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "12px",
    "width": "252px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": null,
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from fit_diagnostics import abs_residuals, norm_residuals\n",
    "from plot_utils import cplot, plot_red_vis\n",
    "from red_likelihood import degVis, doRelCal, doOptCal, doDegVisVis, group_data, gVis, \\\n",
    "makeEArray, norm_rel_sols, red_ant_sep, relabelAnts, doRelCalRP\n",
    "from red_utils import find_flag_file, find_nearest, find_zen_file, get_bad_ants, \\\n",
    "match_lst, split_rel_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numpy.set_printoptions(threshold=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "JD = 2458098.43869\n",
    "pol = 'ee'\n",
    "freq_channel = 600\n",
    "time_integration = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zen_fn = find_zen_file(JD)\n",
    "bad_ants = get_bad_ants(zen_fn)\n",
    "flags_fn = find_flag_file(JD, 'first') # import flags from firstcal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdraw, RedG, cMData = group_data(zen_fn, pol, freq_channel, None, bad_ants, flags_fn)\n",
    "cData = cMData.filled() # filled with nans for flags\n",
    "flags = cMData.mask\n",
    "\n",
    "# mitigating for multiple freqs - only chooses first one\n",
    "if cData.shape[0] > 1:\n",
    "    cData = cData[0, ...]\n",
    "    flags = flags[0, ...]\n",
    "    print('Frequency channel {} selected for notebook analysis\\n'.format(freq_channel[0]))\n",
    "cData = numpy.squeeze(cData)\n",
    "flags = numpy.squeeze(flags)\n",
    "\n",
    "if all(numpy.isnan(cData[time_integration, :])):\n",
    "    print('All visibilities for channel {} and time integration {} are flagged '\\\n",
    "          '- choose different values'.format(freq_channel, time_integration))\n",
    "\n",
    "ants = numpy.unique(RedG[:, 1:])\n",
    "no_unq_bls = numpy.unique(RedG[:, 0]).size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_red_vis(cData, RedG, vis_type='amp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Redundant calibration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fundamentally, the problem of calibration boils down to the measurement equation:\n",
    "\n",
    "$$ V_{ij}^{\\text{obs}} (\\nu) = g_i (\\nu) g_j^* (\\nu) V_{ij}^{\\text{true}}(\\nu) + n_{ij} (\\nu) $$\n",
    "\n",
    "where the observed visibility $V_{ij}$ between antennas $i$ and $j$ at a given time and frequency is related to the true, underlying visibility by a pair of complex and frequency-dependent gain factors, $g_i$ and $g_j$, if we assume per-antenna gains, along with uncorrelated Gaussian random noise $n_{ij}$. The ultimate aim of calibration is to solve for these gains and visibilities. \n",
    "\n",
    "For a redundant array, we have a system of equations for all antenna pairs $i$ and $j$, given by\n",
    "\n",
    "$$ V_{ij}^{\\text{obs}} (\\nu) = g_i (\\nu) g_j^* (\\nu) U_{\\alpha}(\\nu) $$\n",
    "\n",
    "where $U_{\\alpha}(\\nu) = V(\\mathbf{r}_i-\\mathbf{r}_j)$, the visibility for the baseline vector $ \\mathbf{b}_{ij} = \\mathbf{r}_i-\\mathbf{r}_j$, which corresponds to a redundant baseline set that we index by $\\alpha$. Two pairs of identical elements with precisely the same baseline separation between them are sensitive to the same mode on the sky, and are thus measuring the same $V_{ij}^{\\text{true}}$.\n",
    "\n",
    "In highly redundant arrays, there are many more observations than there are unique baselines. For the full HERA array, there are 331 elements in the hexagonal core, corresponding to $N_{\\mathrm{bl}} = 331(331-1)/2 = 54,615$ baselines. The hexagonal core only has 630 unique baseline separations, this means we have a non-linear system of $54,615$ equations to determine 630 unique visibilities and the 331 complex gains; the system is vastly overdetermined."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Relative calibration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gaussian distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By imposing that the true sky visibilities from redundant baselines are equal, relative redundant calibration solves for the true sky visibilities for each redundant baseline set $V_{i-j}^{\\text{sol}}$, alongside the gains of the individual antennas.\n",
    "\n",
    "Assuming Gaussian uncorrelated noise with variance $\\sigma_{ij}^2$, a maximum-likelihood estimate for the gains and sky visibilities can be constructed:\n",
    "\n",
    "$$ \\mathcal{L} (\\{g_i(\\nu)\\}, \\{U_{\\alpha}(\\nu)\\} | \\{V_{ij}^{\\text{obs}}(\\nu)\\} \\propto \\prod_{\\nu} \\prod_{\\alpha} \\prod_{\\{i,j\\}_{\\alpha}} \\exp{\\left( -\\frac{1}{2} \\left( \\frac{ \\left| V_{ij}^{\\text{obs}} (\\nu) - g_i (\\nu) g_j^{*} (\\nu) U_{\\alpha}(\\nu) \\right|^2}{\\sigma_{ij}^2(\\nu)} \\right) \\right)} $$\n",
    "\n",
    "where $\\{i,j\\}_{\\alpha}$ are sets of antennas that belong to each redundant baseline type $\\alpha$. Maximizing this function is equivalent to minimizing:\n",
    "\n",
    "$$ \\chi_{\\mathrm{rel}}^{2} (\\nu) = \\sum_{\\alpha} \\sum_{\\{i,j\\}_{\\alpha}} \\frac{ \\left| V_{ij}^{\\text{obs}} (\\nu) - g_i (\\nu) g_j^* (\\nu) U_{\\alpha}(\\nu) \\right|^2 }{\\sigma_{ij}^2(\\nu)} $$\n",
    "\n",
    "by varying $g_k(\\nu)$ and $U_{\\alpha}(\\nu)$ for each frequency $\\nu$.\n",
    "\n",
    "This non-linear least-squares optimization can be done independently between frequencies and time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cauchy distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We no longer assume that the noise in the measurement equation is Gaussian. Empirically, it is found that visibility observations can have a lot of outliers, and the visibilities follow a distribution with fatter tails than a Gaussian. We wish to be insensitive to outliers, so we need to employ robust statistics to adequately deal with such measurements.\n",
    "\n",
    "Instead of fitting the visibilities to a Gaussian, we fit them to a Cauchy distribution, when solving the redundant calibration parameter estimation.\n",
    "\n",
    "The Cauchy distribution is given by\n",
    "\n",
    "$$ f(x; x_0, \\gamma) = \\frac{1}{\\pi \\gamma \\left[ 1 + \\left( \\frac{x - x_0}{\\gamma}  \\right)^2  \\right] }$$\n",
    "\n",
    "where $x_0$ is the location parameter (the median) and $\\gamma$ is the scale parameter, which specifies the half-width at half-maximum (HWHM).\n",
    "\n",
    "Working in a maximum likelihood framework, the likelihood when solving for the measurement equation for redundant baseline sets is given by\n",
    "\n",
    "$$ \\mathcal{L} = \\prod_{\\nu} \\prod_{\\alpha} \\prod_{\\{i,j\\}_{\\alpha}} \\frac{1}{\\pi \\gamma_{\\alpha} (\\nu)} \\left[ 1 + \\left( \\frac{\\left| V_{ij}^{\\text{obs}} (\\nu) - g_i (\\nu) g_j^* (\\nu) U_{\\alpha}(\\nu) \\right|}{\\gamma_{\\alpha} (\\nu)}  \\right)^2  \\right]^{-1} $$\n",
    "\n",
    "The negative log-likelihood is therefore given by\n",
    "\n",
    "$$ -\\ln(\\mathcal{L}) (\\nu) = \\sum_{\\alpha} \\sum_{\\{i,j\\}_{\\alpha}} \\ln(\\pi \\gamma_{\\alpha} (\\nu)) + \\ln \\left( 1 + \\left( \\frac{\\left| V_{ij}^{\\text{obs}} (\\nu) - g_i (\\nu) g_j^* (\\nu) U_{\\alpha}(\\nu) \\right|}{\\gamma_{\\alpha}(\\nu)}  \\right)^2 \\right) $$\n",
    "\n",
    "where we have dropped the sum over frequency, as we can solve independently for each frequency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_vis = cData[time_integration, :]\n",
    "res_rel = doRelCal(RedG, obs_vis, distribution='cauchy')\n",
    "res_rel_vis, res_rel_gains = split_rel_results(res_rel['x'], no_unq_bls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Profiling methods\n",
    "\n",
    "# import cProfile\n",
    "# %load_ext line_profiler\n",
    "\n",
    "# %lprun -f doRelCal doRelCal(RedG, obs_vis, distribution='cauchy')\n",
    "# %prun doRelCal(RedG, obs_vis, distribution='cauchy')\n",
    "# cProfile.run(\"doRelCal(RedG, obs_vis, distribution='cauchy')\", sort='cumtime')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# renormalize after solving\n",
    "numpy.abs(res_rel_gains) / numpy.mean(numpy.abs(res_rel_gains))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try with alternative calibration method whereby the number of parameters in the minimization\n",
    "# is reduced such that the average amplitude and phase are constrained\n",
    "res_relRP, _ = doRelCalRP(RedG, obs_vis, distribution='cauchy')\n",
    "RP_vis, RP_gains = split_rel_results(res_relRP['x'], no_unq_bls, coords='polar')\n",
    "RP_mean = numpy.mean(numpy.abs(RP_gains))\n",
    "print('Average amp: {}, product of amps: {}, average phase: {}'.format(RP_mean, \\\n",
    "      numpy.prod(numpy.abs(RP_gains)), numpy.mean(numpy.angle(RP_gains))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Residuals for relative redundant step\n",
    "pred_rel_vis = gVis(res_rel_vis, relabelAnts(RedG), res_rel_gains)\n",
    "rel_residuals = obs_vis - pred_rel_vis\n",
    "cplot(rel_residuals, xlabel='Baseline', ylabel='Residual')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Relative residuals normalized by amplitude\n",
    "norm_rel_residuals = norm_residuals(obs_vis, pred_rel_vis)\n",
    "cplot(norm_rel_residuals, xlabel='Baseline', ylabel='Normalized residual')\n",
    "print('Median absolute normalized residual - Real: {}, Imag: {}'.format(*abs_residuals(norm_rel_residuals)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "autoscroll": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "## Optimal calibration (solving for degeneracies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Relative calibration yields degenerate solutions, that can be parameterized as four terms per frequency:\n",
    " - Overall amplitude $A(\\nu)$\n",
    " - Overall phase $\\Delta(\\nu)$\n",
    " - Phase gradient components $\\Delta_x(\\nu)$ and $\\Delta_y(\\nu)$\n",
    " \n",
    "The below transformations of these degenerate parameters leave $-\\ln(\\mathcal{L})$ (for both Gaussian and Cauchy distributions) unchanged:\n",
    " - $g_i \\rightarrow A g_i$ accompanied by $U_{\\alpha} \\rightarrow A^{-2} U_{\\alpha}$\n",
    " - $g_k = |g_k|e^{i\\phi_k} \\rightarrow |g_k|e^{i(\\phi_k + \\Delta)}$ corresponds to $g_k g_l^{*} = |g_k| |g_l| e^{i(\\phi_k - \\phi_l)} \\rightarrow |g_k| |g_l| e^{i(\\phi_k + \\Delta - \\phi_l - \\Delta)} = g_k g_l^{*}$\n",
    " - $g_k = |g_k|e^{i\\phi_k} \\rightarrow |g_k|e^{i(\\phi_k + \\Delta_x x_k + \\Delta_y y_k)}$ accompanied by $U_{\\alpha} = |U_{\\alpha}| e^{i\\phi_{\\alpha}} \\rightarrow |U_{\\alpha}| e^{i(\\phi_{\\alpha} - \\Delta_x x_{\\alpha} - \\Delta_y y_{\\alpha})}$\n",
    " \n",
    "Where in the last line, the array is assumed to be co-planar, and $(x_k, y_k)$ are the coordinates of the position of antennas $k$, and $(x_{\\alpha}, y_{\\alpha})$ are the separations of the antennas that form baselines in redundant set $\\alpha$.\n",
    "\n",
    "These degeneracies must be constrained - this is the \"absolute\" part of redundant calibration. The degenerate parameters can either calculated from a sky model, or can be solved for using optimal absolute calibration, which calculates the degenerate parameters directly from the $\\chi^2$ or $-\\ln(\\mathcal{L})$ by applying a few conditions.\n",
    "\n",
    " - Gaussian distribution:\n",
    " \n",
    "$$ \\chi_{\\text{opt}}^2 (\\nu) = \\sum_{\\alpha} \\sum_{\\{i,j\\}_{\\alpha}} \\frac{ \\left|  V_{ij}^{\\text{obs}} (\\nu) - h_i (\\nu) h_j^{*} (\\nu) W_{\\alpha} (\\nu) \\right|^2 }{\\sigma_{ij}^2(\\nu)} $$\n",
    "\n",
    " - Cauchy distribution:\n",
    "\n",
    "$$  -\\ln(\\mathcal{L}) = \\sum_{\\alpha} \\sum_{\\{i,j\\}_{\\alpha}} \\ln(\\pi \\gamma_{\\alpha} (\\nu)) + \\ln \\left( 1 + \\left( \\frac{\\left| V_{ij}^{\\text{obs}} (\\nu) - h_i (\\nu) h_j^{*} (\\nu) W_{\\alpha} (\\nu) \\right|}{\\gamma_{\\alpha}(\\nu)}  \\right)^2 \\right) $$\n",
    "\n",
    "where\n",
    "\n",
    "$$ W_{\\alpha} (\\nu) = A^2(\\nu) e^{i \\left[ \\Delta_{x} (\\nu) x_{\\alpha} + \\Delta_{y} (\\nu) y_{\\alpha} \\right]} U_{\\alpha} $$\n",
    "\n",
    "with the following constraints applied to the $h_i$ parameters:\n",
    "\n",
    "$$\\frac{1}{N} \\sum_i^N |h_i| = 1$$\n",
    "\n",
    "$$\\frac{1}{N} \\sum_i^N \\mathrm{Arg} (h_i) = 0$$\n",
    "\n",
    "$$\\sum_i^N x_i \\mathrm{Arg} (h_i) = 0$$\n",
    "\n",
    "$$\\sum_i^N y_i \\mathrm{Arg} (h_i) = 0$$\n",
    "\n",
    "which translate to:\n",
    " - A mean gain amplitude of 1\n",
    " - A mean gain phase of 0\n",
    " - Phase gradients (also known as tilts) in both the x & y directions of 0\n",
    " \n",
    "The overall phase is also degenerate, and is set by requiring that the phase of the gain of a reference antenna is null:\n",
    "\n",
    "$$ \\mathrm{Arg} (h_\\text{ref}) = 0 $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_opt = doOptCal(RedG, obs_vis, hdraw.antpos, res_rel_vis, distribution='cauchy', \\\n",
    "                   ref_ant=85)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_opt['x'][-4:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_gain_params, new_deg_params = numpy.split(res_opt['x'], [ants.size*2,])\n",
    "new_amps = new_gain_params[:ants.size*2:2]\n",
    "new_phases = new_gain_params[1:ants.size*2:2]\n",
    "new_gains = makeEArray(new_gain_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Degenerate parameters: {}'.format(str(new_deg_params)[1: -1]))\n",
    "print('Amplitude mean: {}'.format(numpy.mean(new_amps)))\n",
    "print('Phase mean: {}'.format(numpy.mean(new_phases)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimal residuals for optimal redundant step\n",
    "ant_sep = red_ant_sep(RedG, hdraw.antpos)\n",
    "opt_w_alpha = degVis(ant_sep, res_rel_vis, *new_deg_params[[0, 2, 3]])\n",
    "pred_opt_vis = gVis(opt_w_alpha, relabelAnts(RedG), new_gains)\n",
    "opt_residuals =  obs_vis - pred_opt_vis\n",
    "cplot(opt_residuals, xlabel='Baseline', ylabel='Residual')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalized amplitude residuals\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.plot(norm_residuals(numpy.abs(obs_vis), numpy.abs(pred_opt_vis)))\n",
    "plt.xlabel('Baseline')\n",
    "plt.ylabel('Normalized residual')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Phase residuals\n",
    "diff_phases = numpy.angle(obs_vis) - numpy.angle(pred_opt_vis)\n",
    "# wrap between {-pi, pi}\n",
    "diff_phases_wrapped = (diff_phases + numpy.pi) % (2 * numpy.pi) - numpy.pi\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.plot(diff_phases)\n",
    "plt.plot(diff_phases_wrapped, label='wrapped')\n",
    "plt.xlabel('Baseline')\n",
    "plt.ylabel('Normalized residual')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Residuals normalized by amplitude\n",
    "norm_opt_residuals = norm_residuals(obs_vis, pred_opt_vis)\n",
    "cplot(norm_opt_residuals, xlabel='Baseline', ylabel='Residual')\n",
    "print('Median absolute normalized residual - Real: {}, Imag: {}'.\\\n",
    "      format(*abs_residuals(norm_opt_residuals)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing relative calibrations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To monitor the consistency of the \"true\" visibility solutions for each baseline set, we calculate the relative calibration visibility solutions from another JD and compare them to the relative solutions of the initial dataset. These should be consistent, up to the degenerate parameters $A$, $\\Delta_x$ and $\\Delta_y$ - solving for these parameters with an MLE framework enables us to compare these solutions.\n",
    "\n",
    "We need to minimize:\n",
    "\n",
    "- Assuming Gaussian distributions:\n",
    "\n",
    "$$ \\chi^2_{\\text{deg}} (\\nu) = \\sum_{\\alpha} \\sum_{\\{i,j\\}_{\\alpha}} \\frac{ \\left| U_{\\alpha}' (\\nu) - W_{\\alpha} (\\nu) \\right|^2 }{\\sigma_{\\alpha}^2(\\nu)} $$\n",
    "\n",
    "- Assuming Cauchy distributions:\n",
    "\n",
    "$$-\\ln(\\mathcal{L}) = \\sum_{\\alpha} \\sum_{\\{i,j\\}_{\\alpha}} \\ln(\\pi \\gamma_{\\alpha}) + \\ln \\left( 1 + \\left( \\frac{\\left| U_{\\alpha}' (\\nu) - W_{\\alpha} (\\nu) \\right|}{\\gamma_{\\alpha}}  \\right)^2 \\right) $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "JD2 = match_lst(JD, 2458099, tint=time_integration) # finding the JD_time of the zen_file\n",
    "# that matches the LAST of the dataset used in 1.\n",
    "\n",
    "zen_fn2 = find_zen_file(JD2)\n",
    "bad_ants2 = get_bad_ants(zen_fn2)\n",
    "flags_fn2 = find_flag_file(JD2, 'first') # import flags from firstcal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdraw2, RedG2, cMData2 = group_data(zen_fn2, pol, freq_channel, None, bad_ants2, flags_fn2)\n",
    "cData2 = cMData2.filled()\n",
    "flags2 = cMData2.mask\n",
    "\n",
    "if cData2.shape[0] > 1:\n",
    "    cData2 = cData2[0, ...]\n",
    "    flags2 = flags2[0, ...]\n",
    "cData2 = numpy.squeeze(cData2)\n",
    "flags2 = numpy.squeeze(flags2)  \n",
    "\n",
    "no_unq_bls2 = numpy.unique(RedG2[:, 0]).size\n",
    "\n",
    "print('Do the visibilities for JDs {} and {} have:\\n'\\\n",
    "      'the same bad antennas? {}\\n'\\\n",
    "      'the same flags? {}\\n'\\\n",
    "      'the same redundant grouping? {}'.format(JD, JD2, (bad_ants == bad_ants2).all(), \\\n",
    "      (flags == flags2).all(), (RedG==RedG2).all()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find time integration in dataset 2 that corresponds to closest LST to that of dataset 1\n",
    "# This currently assumes that dataset 2 contains the correct time integration...\n",
    "time_integration2 = find_nearest(hdraw2.lsts, hdraw.lsts[time_integration])[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_red_vis(cData2, RedG2, vis_type='amp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Relative calibration for the 2nd dataset\n",
    "res_rel2 = doRelCal(RedG2, cData2[time_integration2, :], distribution='cauchy')\n",
    "res_rel_vis2, res_rel_gains2 = split_rel_results(res_rel2['x'], no_unq_bls2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Digging into results further as there are discrepencies with results stored in rel_df*\n",
    "# that do not produce the same degenerate fitting results, when the deg_cal script is run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_rel['fun']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_rel2['fun']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking if normalizing the solutions changes anything...\n",
    "res_rel_vis, res_rel_gains = split_rel_results(norm_rel_sols(res_rel['x'], no_unq_bls), no_unq_bls)\n",
    "res_rel_vis2, res_rel_gains2 = split_rel_results(norm_rel_sols(res_rel2['x'], no_unq_bls), no_unq_bls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numpy.abs(res_rel_vis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numpy.abs(res_rel_vis2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numpy.angle(res_rel_vis).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numpy.angle(res_rel_vis2).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Translating between relatively calibrated visibility sets\n",
    "res_deg = doDegVisVis(RedG, hdraw.antpos, res_rel_vis, res_rel_vis2, distribution='cauchy')\n",
    "deg_tr_params = res_deg['x']\n",
    "print(deg_tr_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_deg['fun']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Residuals for degenerate comparison\n",
    "deg_w_alpha = degVis(ant_sep, res_rel_vis, *deg_tr_params)\n",
    "deg_residuals = res_rel_vis2 - deg_w_alpha\n",
    "cplot(deg_residuals, xlabel='Redundant baseline type', ylabel='Residual')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Degenerate residuals normalized by amplitude\n",
    "norm_deg_residuals = norm_residuals(res_rel_vis2, deg_w_alpha)\n",
    "cplot(norm_deg_residuals, xlabel='Redundant baseline type', ylabel='Residual')\n",
    "print('Median absolute normalized residual - Real: {}, Imag: {}'.format(*abs_residuals(norm_deg_residuals)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "name": "SimpleRedCal.ipynb",
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "12px",
    "width": "252px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": null,
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

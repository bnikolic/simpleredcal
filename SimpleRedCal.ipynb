{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from fit_diagnostics import abs_residuals, norm_residuals\n",
    "from plot_utils import cplot, plot_red_vis\n",
    "from red_likelihood import degVis, doRelCal, doRelCalRP, doOptCal, doDegVisVis, \\\n",
    "group_data, gVis, makeEArray, norm_rel_sols, red_ant_sep, relabelAnts, rotate_phase\n",
    "from red_utils import find_flag_file, find_nearest, find_zen_file, get_bad_ants, \\\n",
    "match_lst, split_rel_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numpy.set_printoptions(threshold=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "JD = 2458098.43869\n",
    "pol = 'ee'\n",
    "freq_channel = 605\n",
    "time_integration = 0\n",
    "distribution = 'cauchy' # fitting distribution for neg log-likelihood minimizations\n",
    "rel_cal_coords = 'polar' # parameter coordinate system\n",
    "bounded_rel_cal = False # bound gain and visibility amplitudes in relative calibration\n",
    "RP_results = True # use reduced parameter relative calibration method\n",
    "rot_phase = False # rotate phases of relative calibration gains with negative amplitudes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zen_fn = find_zen_file(JD)\n",
    "bad_ants = get_bad_ants(zen_fn)\n",
    "flags_fn = find_flag_file(JD, 'first') # import flags from firstcal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdraw, RedG, cMData = group_data(zen_fn, pol, freq_channel, None, bad_ants, flags_fn)\n",
    "cData = cMData.filled() # filled with nans for flags\n",
    "flags = cMData.mask\n",
    "\n",
    "# mitigating for multiple freqs - only chooses first one\n",
    "if cData.shape[0] > 1:\n",
    "    cData = cData[0, ...]\n",
    "    flags = flags[0, ...]\n",
    "    print('Frequency channel {} selected for notebook analysis\\n'.format(freq_channel[0]))\n",
    "cData = numpy.squeeze(cData)\n",
    "flags = numpy.squeeze(flags)\n",
    "\n",
    "if all(numpy.isnan(cData[time_integration, :])):\n",
    "    print('All visibilities for channel {} and time integration {} are flagged '\\\n",
    "          '- choose different values'.format(freq_channel, time_integration))\n",
    "\n",
    "ants = numpy.unique(RedG[:, 1:])\n",
    "no_ants = ants.size\n",
    "no_unq_bls = numpy.unique(RedG[:, 0]).size\n",
    "cRedG = relabelAnts(RedG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_red_vis(cData, RedG, vis_type='amp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Redundant calibration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fundamentally, the problem of calibration boils down to the measurement equation:\n",
    "\n",
    "$$ V_{ij}^{\\text{obs}} (\\nu) = g_i (\\nu) g_j^* (\\nu) V_{ij}^{\\text{true}}(\\nu) + n_{ij} (\\nu) $$\n",
    "\n",
    "where the observed visibility $V_{ij}^{\\text{obs}}$ between antennas $i$ and $j$ at a given time and frequency is related to the true underlying visibility $V_{ij}^{\\text{true}}$ by a pair of complex and frequency-dependent gain factors, $g_i$ and $g_j$, if we assume per-antenna gains, along with uncorrelated Gaussian random noise $n_{ij}$. The ultimate aim of calibration is to solve for these gains and true visibilities. \n",
    "\n",
    "An array with regularly spaced antennas has few unique baselines, hence there are many redundant visibilities with precisely the same baseline separation between them that are sensitive to the very same modes on the sky. In redundant calibration, we impose the prior that the true sky visibilities $V_{ij}^{\\text{true}}$ from redundant baselines are equal. We therefore have a system of equations for all antenna pairs $i$ and $j$, given by\n",
    "\n",
    "$$ V_{ij}^{\\text{obs}} (\\nu) = g_i (\\nu) g_j^* (\\nu) U_{\\alpha}(\\nu) + n_{ij} (\\nu) $$\n",
    "\n",
    "where $U_{\\alpha}(\\nu) = V(\\mathbf{r}_i-\\mathbf{r}_j)$, the visibility for the baseline vector $\\mathbf{b}_{ij} = \\mathbf{r}_i-\\mathbf{r}_j$, corresponds to a redundant baseline set that we index by $\\alpha$.\n",
    "\n",
    "In highly redundant arrays, like \\gls{hera}, there are many more observations than there are unique baselines. For the full HERA array, there are 331 elements in the hexagonal core, corresponding to $N_{\\mathrm{bl}} = 331(331-1)/2 = 54,615$ baselines. The hexagonal core only has 630 unique baseline separations, this means that we have a non-linear system of $54,615$ equations to determine the 630 unique true visibilities and the 331 complex gains; the system is vastly overdetermined. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Relative calibration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Relative calibration is the process whereby true sky visibilities from redundant baselines are set to be equal (i.e. $V_{ij}^{\\text{true}} = U_{\\alpha}(\\nu)$). From this prior, an MLE for the gains and true visibilities can be constructed by assuming a distribution for the observed visibility noise. However, during this process, degeneracies arise, which must be constrained with absolute calibration. We call relative calibration the part that solves up to the degenerate parameters, and absolute calibration the part that constrains them. Redundant calibration consists of both of these components together."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gaussian distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By imposing that the true sky visibilities from redundant baselines are equal, relative redundant calibration solves for the true sky visibilities for each redundant baseline set $V_{i-j}^{\\text{sol}}$, alongside the gains of the individual antennas.\n",
    "\n",
    "Assuming Gaussian uncorrelated noise with variance $\\sigma_{ij}^2$, the \\gls{mle} in solving for the gains and true visibilities produces the following likelihood function:\n",
    "\n",
    "$$ \t\\mathcal{L}^G_{\\mathrm{rel}} (\\{g_i(\\nu)\\}, \\{U_{\\alpha}(\\nu)\\} | \\{V_{ij}^{\\text{obs}}(\\nu)\\} \\propto \\prod_{\\nu} \\prod_{\\alpha} \\prod_{\\{i,j\\}_{\\alpha}} \\exp\\left( -\\frac{1}{2} \\frac{ \\left| V_{ij}^{\\text{obs}} (\\nu) - g_i (\\nu) g_j^{*} (\\nu) U_{\\alpha}(\\nu) \\right|^2}{\\sigma_{ij}^2(\\nu)} \\right) $$\n",
    "\n",
    "where $\\{i,j\\}_{\\alpha}$ are sets of antennas that belong to each redundant baseline type $\\alpha$. Maximizing this function is equivalent to minimizing:\n",
    "\n",
    "$$ \\chi_{\\mathrm{rel}}^{2} (\\nu) = \\sum_{\\alpha} \\sum_{\\{i,j\\}_{\\alpha}} \\frac{ \\left| V_{ij}^{\\text{obs}} (\\nu) - g_i (\\nu) g_j^* (\\nu) U_{\\alpha}(\\nu) \\right|^2 }{\\sigma_{ij}^2(\\nu)} $$\n",
    "\n",
    "by varying $g_k(\\nu)$ and $U_{\\alpha}(\\nu)$ for each frequency $\\nu$.\n",
    "\n",
    "This non-linear least-squares optimization can be done independently between frequencies and time (although adjacent solutions in time and frequencies are expected to be very similar). Solving the above $\\chi_{\\mathrm{rel}}^{2}$ has been the main focus of redundant calibration methods, with many opting to linearize the redundant measurement equation for computational ease. In this work, we follow through with the full $\\chi_{\\mathrm{rel}}^{2}$ evaluation, as well as assuming other model distributions in the MLE, with the belief that such computations can be greatly accelerated with novel software and GPUs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cauchy distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Empirically, it is found that the noise from visibility observations from a redundant set may not be Gaussian, due to non-redundancies from instrumental effects and the presence of outliers (from e.g. RFI), and that the visibilities may follow a distribution with fatter tails. We wish to be insensitive to outliers, so we need to employ robust statistics to adequately deal with such measurements.\n",
    "\n",
    "It is clear that outliers will affect any Gaussian or mean-centred fitting, therefore resulting in inaccurate gain and true sky visibility solutions. The Cauchy distribution, however, is median-centred (its mean is undefined); it is given by\n",
    "\n",
    "$$ f(x; x_0, \\gamma) = \\frac{1}{\\pi \\gamma \\left[ 1 + \\left( \\frac{x - x_0}{\\gamma} \\right)^2 \\right] }$$\n",
    "\n",
    "where $x_0$ is the location parameter (the median) and $\\gamma$ is the scale parameter, which specifies the HWHM. These are both robust measures of central tendency and statistical dispersion, respectively, that are not unduly affected by outliers..\n",
    "\n",
    "We no longer assume that the noise in the measurement equation is Gaussian, and instead, assume it is Cauchy distributed when solving for the relative redundant calibration parameters.\n",
    "\n",
    "Working in a maximum likelihood framework, the likelihood when solving for the measurement equation for redundant baseline sets is given by\n",
    "\n",
    "$$ \\mathcal{L}^C_{\\mathrm{rel}} (\\{g_i(\\nu)\\}, \\{U_{\\alpha}(\\nu)\\} | \\{V_{ij}^{\\text{obs}}(\\nu)\\} = \\\\ \\prod_{\\nu} \\prod_{\\alpha} \\prod_{\\{i,j\\}_{\\alpha}} \\frac{1}{\\pi \\gamma_{\\alpha} (\\nu)} \\left[ 1 + \\left( \\frac{\\left| V_{ij}^{\\text{obs}} (\\nu) - g_i (\\nu) g_j^* (\\nu) U_{\\alpha}(\\nu) \\right|}{\\gamma_{\\alpha} (\\nu)} \\right)^2 \\right]^{-1} $$\n",
    "\n",
    "The negative log-likelihood is therefore given by\n",
    "\n",
    "$$ -\\ln(\\mathcal{L}^C_{\\mathrm{rel}}) (\\nu) = \\sum_{\\alpha} \\sum_{\\{i,j\\}_{\\alpha}} \\ln(\\pi \\gamma_{\\alpha} (\\nu)) + \\ln \\left( 1 + \\left( \\frac{\\left| V_{ij}^{\\text{obs}} (\\nu) - g_i (\\nu) g_j^* (\\nu) U_{\\alpha}(\\nu) \\right|}{\\gamma_{\\alpha}(\\nu)} \\right)^2 \\right) $$\n",
    "\n",
    "where we have dropped the sum over frequency, as we can solve independently for each frequency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_vis = cData[time_integration, :]\n",
    "res_rel = doRelCal(cRedG, obs_vis, no_unq_bls, no_ants, distribution=distribution, \\\n",
    "                   coords=rel_cal_coords, bounded=bounded_rel_cal, norm_gains=True)\n",
    "res_relx = numpy.array(res_rel['x'])\n",
    "if rel_cal_coords == 'polar' and rot_phase and (res_relx[-2*no_ants::2] < 0).any():\n",
    "    # adjustement if negative amplitude solutions are found, where the absolute values\n",
    "    # of amplitudes are taken, and phases of affected antennas are rotated by +pi\n",
    "    print('Rotating gain and visibility phases to have positive amplitudes.')\n",
    "    res_relx = rotate_phase(res_relx, no_unq_bls, norm_gains=True)\n",
    "    \n",
    "res_rel_vis, res_rel_gains = split_rel_results(res_relx, no_unq_bls, \\\n",
    "                                               coords=rel_cal_coords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gain amplitudes\n",
    "if rel_cal_coords == 'polar':\n",
    "    print(res_relx[-2*no_ants::2])\n",
    "if rel_cal_coords == 'cartesian':\n",
    "    print(numpy.abs(res_rel_gains))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gain phases\n",
    "if rel_cal_coords == 'polar':\n",
    "    print(res_relx[-2*no_ants+1::2])\n",
    "if rel_cal_coords == 'cartesian':\n",
    "    print(numpy.angle(res_rel_gains))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try JAX minimization\n",
    "jres_rel = doRelCal(cRedG, obs_vis, no_unq_bls, no_ants, distribution=distribution, \\\n",
    "                    coords=rel_cal_coords, jax_minimizer=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try with alternative calibration method whereby the number of parameters in the\n",
    "# minimization is reduced such that the average gain amplitude and phase are constrained\n",
    "res_relRP, _ = doRelCalRP(cRedG, obs_vis, no_unq_bls, no_ants, distribution=distribution, \\\n",
    "                          constr_phase=True, amp_constr='prod', bounded=True)\n",
    "res_relRPx = numpy.array(res_relRP['x'])\n",
    "if rot_phase:\n",
    "    res_relRPx = rotate_phase(res_relRPx, no_unq_bls)\n",
    "RP_vis, RP_gains = split_rel_results(res_relRPx, no_unq_bls, coords='polar')\n",
    "RP_mean = numpy.mean(numpy.abs(RP_gains))\n",
    "print('Gains - average amp: {}, product of amps: {}, average phase: {}'.format(RP_mean, \\\n",
    "      numpy.prod(numpy.abs(RP_gains)), numpy.mean(numpy.angle(RP_gains))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# jres_relRP, _ = doRelCalRP(cRedG, obs_vis, no_unq_bls, no_ants, distribution=distribution, \\\n",
    "#                            constr_phase=True, bounded=False, amp_constr='prod', jax_minimizer=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gain amplitudes for the reduced parameter method\n",
    "res_relRPx[::2][-no_ants:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if RP_results:\n",
    "    res_rel = res_relRP\n",
    "    res_relx = res_relRPx\n",
    "    res_rel_gains = RP_gains\n",
    "    res_rel_vis = RP_vis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Residuals for relative redundant step\n",
    "pred_rel_vis = gVis(res_rel_vis, cRedG, res_rel_gains)\n",
    "rel_residuals = obs_vis - pred_rel_vis\n",
    "cplot(rel_residuals, xlabel='Baseline', ylabel='Residual')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Relative residuals normalized by amplitude\n",
    "norm_rel_residuals = norm_residuals(obs_vis, pred_rel_vis)\n",
    "cplot(norm_rel_residuals, xlabel='Baseline', ylabel='Normalized residual')\n",
    "print('Median absolute normalized residual - Real: {}, Imag: {}'\\\n",
    "      .format(*abs_residuals(norm_rel_residuals)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "autoscroll": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "## Optimal calibration (solving for degeneracies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Relative calibration yields degenerate solutions, which can be parameterized as four terms per frequency:\n",
    " - Overall amplitude $A(\\nu)$\n",
    " - Overall phase $\\Delta(\\nu)$\n",
    " - Phase gradient components $\\Delta_x(\\nu)$ and $\\Delta_y(\\nu)$\n",
    " \n",
    "since the below transformations of these degenerate parameters leave $-\\ln(\\mathcal{L})$ (for both the Gaussian and Cauchy distributions) unchanged:\n",
    " - $g_i \\rightarrow A g_i$ accompanied by $U_{\\alpha} \\rightarrow A^{-2} U_{\\alpha}$\n",
    " - $g_k = |g_k|e^{i\\phi_k} \\rightarrow |g_k|e^{i(\\phi_k + \\Delta)}$, s.t. $g_k g_l^{*} = |g_k| |g_l| e^{i(\\phi_k - \\phi_l)} \\rightarrow |g_k| |g_l| e^{i(\\phi_k + \\Delta - \\phi_l - \\Delta)} = g_k g_l^{*}$\n",
    " - $g_k = |g_k|e^{i\\phi_k} \\rightarrow |g_k|e^{i(\\phi_k + \\Delta_x x_k + \\Delta_y y_k)}$ accompanied by $U_{\\alpha} = |U_{\\alpha}| e^{i\\phi_{\\alpha}} \\rightarrow |U_{\\alpha}| e^{i(\\phi_{\\alpha} - \\Delta_x x_{\\alpha} - \\Delta_y y_{\\alpha})}$\n",
    " \n",
    "where in the last line, the array is assumed to be co-planar, and $(x_k, y_k)$ are the positional coordinates of antenna $k$, and $(x_{\\alpha}, y_{\\alpha})$ are the separations of the antennas that form baselines in redundant set $\\alpha$.\n",
    "\n",
    "These degeneracies must be constrained - this is the absolute part of redundant calibration. The degenerate parameters can be calculated from a sky model in an absolute calibration step. Alternatively, the degenerate parameters can be solved for by using optimal absolute calibration, which calculates the degenerate parameters directly from the $\\chi^2$ or $-\\ln(\\mathcal{L})$ by applying a few conditions. This latter method, however, still ultimately needs to reference the sky to set the flux scale and pointing centre. These two absolute calibration methods are not mathematically equivalent, but yield consistent results. We describe optimal absolute calibration below, for both Gaussian and Cauchy distributed visibilities.\n",
    "\n",
    "We define a set of parameters $h_i$ to be the gains that obey the following constraints:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "    \\frac{1}{N} \\sum_i^N |h_i| = 1 \\quad \\rightarrow \\quad & \\text{mean gain amplitude of 1} \\\\\n",
    "\t\\frac{1}{N} \\sum_i^N \\mathrm{Arg} (h_i) = 0 \\quad \\rightarrow \\quad & \\text{mean gain phase of 0} \\\\\n",
    "    \\sum_i^N x_i \\mathrm{Arg} (h_i) = 0 \\quad \\rightarrow \\quad & \\text{phase gradient of 0 in }x \\\\\n",
    "\t\\sum_i^N y_i \\mathrm{Arg} (h_i) = 0 \\quad \\rightarrow \\quad & \\text{phase gradient of 0 in }y\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "such that the antenna gains can be written as\n",
    "\n",
    "$$ \tg_i (\\nu) = A(\\nu) e^{i \\left[ \\Delta (\\nu) + \\Delta_{x} (\\nu) x_{i} + \\Delta_{y} (\\nu) y_{i} \\right]} h_i (\\nu) $$\n",
    "\n",
    "where $(x_i, y_i)$ is the position of antenna $i$, and all degenerate dependencies have been removed out of $h_i$.\n",
    "\n",
    "Non-degenerate formulations of are therefore given by \n",
    "\n",
    " - Gaussian distribution:\n",
    " \n",
    "$$ \\chi_{\\text{opt}}^2 (\\nu) = \\sum_{\\alpha} \\sum_{\\{i,j\\}_{\\alpha}} \\frac{ \\left| V_{ij}^{\\text{obs}} (\\nu) - h_i (\\nu) h_j^{*} (\\nu) W_{\\alpha} (\\nu) \\right|^2 }{\\sigma_{ij}^2(\\nu)} $$\n",
    "\n",
    " - Cauchy distribution:\n",
    "\n",
    "$$ -\\ln(\\mathcal{L}^C_{\\mathrm{opt}}) (\\nu) = \\sum_{\\alpha} \\sum_{\\{i,j\\}_{\\alpha}} \\ln(\\pi \\gamma_{\\alpha} (\\nu)) + \\ln \\left( 1 + \\left( \\frac{\\left| V_{ij}^{\\text{obs}} (\\nu) - h_i (\\nu) h_j^{*} (\\nu) W_{\\alpha} (\\nu) \\right|}{\\gamma_{\\alpha}(\\nu)} \\right)^2 \\right) $$\n",
    "\n",
    "where\n",
    "\n",
    "$$ W_{\\alpha} (\\nu) = A^2(\\nu) e^{i \\left[ \\Delta_{x} (\\nu) x_{\\alpha} + \\Delta_{y} (\\nu) y_{\\alpha} \\right]} U_{\\alpha} $$\n",
    "\n",
    "and $(x_{\\alpha}, y_{\\alpha})$ are the baseline coordinates of redundant set $\\alpha$.\n",
    " \n",
    "The overall phase is also degenerate, and is set by requiring that the phase of the gain of a reference antenna is null:\n",
    "\n",
    "$$ \\mathrm{Arg} (h_\\text{ref}) = 0 $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_ant = 85 # to set the overall phase\n",
    "res_opt = doOptCal(RedG, obs_vis, hdraw.antpos, res_rel_vis, distribution=distribution, \\\n",
    "                   ref_ant=ref_ant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# degenerate parameters\n",
    "res_opt['x'][-4:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_gain_params, new_deg_params = numpy.split(res_opt['x'], [no_ants*2,])\n",
    "new_amps = new_gain_params[:no_ants*2:2]\n",
    "new_phases = new_gain_params[1:no_ants*2:2]\n",
    "new_gains = makeEArray(new_gain_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Degenerate parameters: {}'.format(str(new_deg_params)[1: -1]))\n",
    "print('Amplitude mean: {}'.format(numpy.mean(new_amps)))\n",
    "print('Phase mean: {}'.format(numpy.mean(new_phases)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimal residuals for optimal redundant step\n",
    "ant_sep = red_ant_sep(RedG, hdraw.antpos)\n",
    "opt_w_alpha = degVis(ant_sep, res_rel_vis, *new_deg_params[[0, 2, 3]])\n",
    "pred_opt_vis = gVis(opt_w_alpha, cRedG, new_gains)\n",
    "opt_residuals =  obs_vis - pred_opt_vis\n",
    "cplot(opt_residuals, xlabel='Baseline', ylabel='Residual')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalized amplitude residuals\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.plot(norm_residuals(numpy.abs(obs_vis), numpy.abs(pred_opt_vis)))\n",
    "plt.xlabel('Baseline')\n",
    "plt.ylabel('Normalized residual')\n",
    "plt.ylim((-1, 1))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Phase residuals\n",
    "diff_phases = numpy.angle(obs_vis) - numpy.angle(pred_opt_vis)\n",
    "# wrap between {-pi, pi}\n",
    "diff_phases_wrapped = (diff_phases + numpy.pi) % (2 * numpy.pi) - numpy.pi\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.plot(diff_phases)\n",
    "plt.plot(diff_phases_wrapped, label='wrapped')\n",
    "plt.xlabel('Baseline')\n",
    "plt.ylabel('Normalized residual')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Residuals normalized by amplitude\n",
    "norm_opt_residuals = norm_residuals(obs_vis, pred_opt_vis)\n",
    "cplot(norm_opt_residuals, xlabel='Baseline', ylabel='Residual', ylim=(-1, 1))\n",
    "print('Median absolute normalized residual - Real: {}, Imag: {}'\\\n",
    "      .format(*abs_residuals(norm_opt_residuals)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing relative calibrations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To check the stability of the true visibilities for each baseline set, we perform relative calibration on neighbouring datasets in time, frequency, or JD, and compare their visibility solutions. These should be consistent up to the degenerate parameters $A$, $\\Delta_x$ and $\\Delta_y$. Marginalizing for these parameters with an MLE framework enables us to compare these solutions without having to resort to optimal calibration, which can be computationally expensive.\n",
    "\n",
    "To compare datasets, we need to minimize:\n",
    "\n",
    "- Gaussian distribution:\n",
    "\n",
    "$$ \\chi^2_{\\text{deg}} (\\nu) = \\sum_{\\alpha} \\sum_{\\{i,j\\}_{\\alpha}} \\frac{ \\left| U_{\\alpha}' (\\nu) - W_{\\alpha} (\\nu) \\right|^2 }{\\sigma_{\\alpha}^2(\\nu)} $$\n",
    "\n",
    "- Cauchy distribution:\n",
    "\n",
    "$$ -\\ln(\\mathcal{L}) (\\nu) = \\sum_{\\alpha} \\sum_{\\{i,j\\}_{\\alpha}} \\ln(\\pi \\gamma_{\\alpha} (\\nu)) + \\ln \\left( 1 + \\left( \\frac{\\left| U_{\\alpha}' (\\nu) - W_{\\alpha} (\\nu) \\right|}{\\gamma_{\\alpha} (\\nu)} \\right)^2 \\right) $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "JD2 = match_lst(JD, 2458099, tint=time_integration) # finding the JD_time of the zen_file\n",
    "# that matches the LAST of the dataset used in 1.\n",
    "\n",
    "zen_fn2 = find_zen_file(JD2)\n",
    "bad_ants2 = get_bad_ants(zen_fn2)\n",
    "flags_fn2 = find_flag_file(JD2, 'first') # import flags from firstcal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdraw2, RedG2, cMData2 = group_data(zen_fn2, pol, freq_channel, None, bad_ants2, flags_fn2)\n",
    "cData2 = cMData2.filled()\n",
    "flags2 = cMData2.mask\n",
    "\n",
    "if cData2.shape[0] > 1:\n",
    "    cData2 = cData2[0, ...]\n",
    "    flags2 = flags2[0, ...]\n",
    "cData2 = numpy.squeeze(cData2)\n",
    "flags2 = numpy.squeeze(flags2)  \n",
    "\n",
    "ants2 = numpy.unique(RedG2[:, 1:])\n",
    "no_ants2 = ants2.size\n",
    "no_unq_bls2 = numpy.unique(RedG2[:, 0]).size\n",
    "cRedG2 = relabelAnts(RedG2)\n",
    "\n",
    "print('Do the visibilities for JDs {} and {} have:\\n'\\\n",
    "      'the same bad antennas? {}\\n'\\\n",
    "      'the same flags? {}\\n'\\\n",
    "      'the same redundant grouping? {}'.format(JD, JD2, (bad_ants == bad_ants2).all(), \\\n",
    "      (flags == flags2).all(), (RedG==RedG2).all()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find time integration in dataset 2 that corresponds to closest LST to that of dataset 1\n",
    "# This currently assumes that dataset 2 contains the correct time integration...\n",
    "time_integration2 = find_nearest(hdraw2.lsts, hdraw.lsts[time_integration])[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_red_vis(cData2, RedG2, vis_type='amp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Relative calibration for the 2nd dataset\n",
    "obs_vis2 = cData2[time_integration2, :]\n",
    "if not RP_results:\n",
    "    res_rel2 = doRelCal(cRedG2, obs_vis2, no_unq_bls2, no_ants2, distribution=distribution, \\\n",
    "                        coords=rel_cal_coords, bounded=bounded_rel_cal, norm_gains=True)\n",
    "else:\n",
    "    res_rel2, _ = doRelCalRP(cRedG2, obs_vis2, no_unq_bls2, no_ants2, distribution=distribution, \\\n",
    "                             constr_phase=True, amp_constr='prod', bounded=True)\n",
    "\n",
    "res_relx2 = numpy.array(res_rel2['x'])\n",
    "if (rel_cal_coords == 'polar' or RP_results) and rot_phase and \\\n",
    "   (res_relx2[-2*no_ants::2] < 0).any():\n",
    "    print('Rotating gain and visibility phases to have positive amplitudes.')\n",
    "    res_relx2 = rotate_phase(res_relx2, no_unq_bls, norm_gains=True)\n",
    "    split_coords2 = 'polar'\n",
    "else:\n",
    "    split_coords2 = rel_cal_coords\n",
    "res_rel_vis2, res_rel_gains2 = split_rel_results(res_relx2, no_unq_bls2, \\\n",
    "                                                 coords=split_coords2)\n",
    "\n",
    "print('Gain - average amp: {}, product of amps: {}, average phase: {}'\\\n",
    "      .format(numpy.abs(res_rel_gains2).mean(), numpy.prod(numpy.abs(res_rel_gains2)), \\\n",
    "      numpy.mean(numpy.angle(res_rel_gains2))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The negative log-likelihoods of the 1st and 2nd relative redundant calibrations '\\\n",
    "      'are:\\n{} and\\n{}'.format(res_rel['fun'], res_rel2['fun']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking if normalizing the solutions changes anything...\n",
    "# res_rel_vis, res_rel_gains = split_rel_results(norm_rel_sols(res_relx, \\\n",
    "#                                  no_unq_bls, coords=split_coords2), no_unq_bls, \\\n",
    "#                                  coords=split_coords2)\n",
    "# res_rel_vis2, res_rel_gains2 = split_rel_results(norm_rel_sols(res_relx2, \\\n",
    "#                                    no_unq_bls, coords=split_coords2), no_unq_bls, \\\n",
    "#                                    coords=split_coords2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gain amplitudes for 2nd relative calibration results\n",
    "res_relx[-2*no_ants:][::2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalized gain amplitudes for 2nd relative calibration results\n",
    "numpy.abs(res_rel_gains)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visibility amplitudes from the 1st relative calibration\n",
    "numpy.abs(res_rel_vis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visibility amplitudes from the 2nd relative calibration\n",
    "numpy.abs(res_rel_vis2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numpy.angle(res_rel_vis).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numpy.angle(res_rel_vis2).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Translating between relatively calibrated visibility sets\n",
    "res_deg = doDegVisVis(RedG, hdraw.antpos, res_rel_vis, res_rel_vis2, \\\n",
    "                      distribution=distribution)\n",
    "deg_tr_params = res_deg['x']\n",
    "\n",
    "print('Degenerate parameters from degenerate fitting are: {}'.format(deg_tr_params))\n",
    "print('The negative log-likelihood for this fitting is: {}'.format(res_deg['fun']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Residuals for degenerate comparison\n",
    "deg_w_alpha = degVis(ant_sep, res_rel_vis, *deg_tr_params)\n",
    "deg_residuals = res_rel_vis2 - deg_w_alpha\n",
    "cplot(deg_residuals, xlabel='Redundant baseline type', ylabel='Residual')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Degenerate residuals normalized by amplitude\n",
    "norm_deg_residuals = norm_residuals(res_rel_vis2, deg_w_alpha)\n",
    "cplot(norm_deg_residuals, xlabel='Redundant baseline type', ylabel='Residual')\n",
    "print('Median absolute normalized residual - Real: {}, Imag: {}'\\\n",
    "      .format(*abs_residuals(norm_deg_residuals)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing optimally calibrated solutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_opt2 = doOptCal(RedG2, obs_vis2, hdraw.antpos, res_rel_vis2, \\\n",
    "                    distribution=distribution, ref_ant=ref_ant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, new_deg_params2 = numpy.split(res_opt2['x'], [no_ants*2,])\n",
    "opt_w_alpha2 = degVis(ant_sep, res_rel_vis2, *new_deg_params2[[0, 2, 3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_opt_deg = doDegVisVis(RedG, hdraw.antpos, opt_w_alpha, opt_w_alpha2, \\\n",
    "                          distribution=distribution)\n",
    "deg_opt_tr_params = res_deg['x']\n",
    "\n",
    "print('Degenerate parameters from degenerate fitting are: {}'.format(deg_tr_params))\n",
    "print('The negative log-likelihood for this fitting is: {}'.format(res_deg['fun']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Degenerate residuals normalized by amplitude\n",
    "deg_opt_w_alpha = degVis(ant_sep, opt_w_alpha, *deg_opt_tr_params)\n",
    "norm_deg_opt_residuals = norm_residuals(opt_w_alpha2, deg_opt_w_alpha)\n",
    "cplot(norm_deg_opt_residuals, xlabel='Redundant baseline type', ylabel='Residual')\n",
    "print('Median absolute normalized residual - Real: {}, Imag: {}'\\\n",
    "      .format(*abs_residuals(norm_deg_opt_residuals)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "name": "SimpleRedCal.ipynb",
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "12px",
    "width": "252px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": null,
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

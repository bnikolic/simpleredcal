{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><strong><font size=+3>A Generalized Approach to Redundant Calibration with JAX</font></center>\n",
    "<br><br>\n",
    "</center>\n",
    "<center><strong><font size=+2>Matyas Molnar and Bojan Nikolic</font><br></strong></center>\n",
    "<br><center><strong><font size=+1>Astrophysics Group, Cavendish Laboratory, University of Cambridge</font></strong></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example notebook that performs redundant calibration with a generalized MLE framework (ยง1, see [HERA Memorandum #84](http://reionization.org/wp-content/uploads/2013/03/HERA084__A_Generalized_Approach_to_Redundant_Calibration_with_JAX.pdf)) and that compares redundantly calibrated visibilities across days by solving for degenerate parameter offsets between them (ยง2, see [HERA Memorandum #94](http://reionization.org/manual_uploads/HERA094__Comparing_Visibility_Solutions_from_Relative_Redundant_Calibration_by_Degenerate_Translation.pdf)).\n",
    "\n",
    "[JAX](https://github.com/google/jax) is used for the calibration computations, which offers considerable speed-up, with great ease (compared to pure NumPy and SciPy), even when moving away from Gaussianity and without the need to linearize or approximate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from fit_diagnostics import abs_residuals, norm_residuals\n",
    "from plot_utils import cplot, plot_red_vis\n",
    "from red_likelihood import condenseMap, degVis, doRelCal, doRelCalD, doOptCal, \\\n",
    "doDegVisVis, flt_ant_pos, group_data, gVis, makeEArray, norm_rel_sols, red_ant_sep, \\\n",
    "relabelAnts, rotate_phase, split_rel_results, XDgVis\n",
    "from red_utils import find_flag_file, find_nearest, find_zen_file, get_bad_ants, \\\n",
    "match_lst\n",
    "from xd_utils import XDgroup_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numpy.set_printoptions(threshold=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_figs = False\n",
    "if plot_figs:\n",
    "    import matplotlib as mpl\n",
    "    mpl.rcParams['figure.dpi'] = 300\n",
    "\n",
    "from matplotlib import rc\n",
    "rc('font',**{'family':'serif','serif':['cm']})\n",
    "rc('text', usetex=True)\n",
    "rc('text.latex', preamble=r'\\usepackage{amssymb} \\usepackage{amsmath}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# Inputs\n",
    "JD = 2458098.43869\n",
    "JD_comp = 2458099 # for degenerate comparison\n",
    "pol = 'ee' # polarization\n",
    "freq_channel = 613 # frequency channel\n",
    "time_integration = 5 # time integration of the 1st dataset on day JD\n",
    "distribution = 'gaussian' # fitting distribution for neg log-likelihood minimizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Other options (development purposes only)\n",
    "rel_cal_coords = 'cartesian' # parameter coordinate system\n",
    "bounded_rel_cal = False # bound gain and visibility amplitudes in relative calibration\n",
    "logamp = False # log(gain amplitude) parameter method to force positive amplitudes\n",
    "lovamp = False # log(vis amplitude) parameter method to force positive amplitudes\n",
    "rc_ref_ant_idx = None # constrain gain of reference antenna\n",
    "tilt_reg = False # regularization term to constrain tilt shifts to 0\n",
    "gphase_reg = False # regularization term to constrain the gain phase mean to 0\n",
    "rot_phase = False # rotate phases of relative calibration gains with negative amplitudes "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieving the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zen_fn = find_zen_file(JD)\n",
    "bad_ants = get_bad_ants(zen_fn)\n",
    "flags_fn = find_flag_file(JD, 'first') # import flags from firstcal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding and loading the zen_file on JD_comp that matches the LAST of the 1st dataset\n",
    "JD2 = match_lst(JD, JD_comp, tint=time_integration)\n",
    "if len(str(JD2)) < 13:\n",
    "    JD2 = str(JD2) + '0' # add a trailing 0 that is omitted in float\n",
    "zen_fn2 = find_zen_file(JD2)\n",
    "bad_ants2 = get_bad_ants(zen_fn2)\n",
    "flags_fn2 = find_flag_file(JD2, 'first') # import flags from firstcal\n",
    "\n",
    "# Taking the union of the bad antenna arrays for both datasets, if they're not equal\n",
    "if not numpy.array_equal(bad_ants, bad_ants2):\n",
    "    print('The visibilities for datasets {} and {} do not have the same bad antennas. '\\\n",
    "          'Selecting the union of the bad antennas for those datasets in this analysis.'.\\\n",
    "          format(JD, JD2))\n",
    "    bad_ants = numpy.union1d(bad_ants, bad_ants2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdraw, RedG, cMData = group_data(zen_fn, pol, freq_channel, None, bad_ants, flags_fn)\n",
    "cData = cMData.filled() # filled with nans for flags\n",
    "flags = cMData.mask\n",
    "\n",
    "# mitigating for multiple freqs - only chooses first one\n",
    "if cData.shape[0] > 1:\n",
    "    cData = cData[0, ...]\n",
    "    flags = flags[0, ...]\n",
    "    print('Frequency channel {} selected for notebook analysis\\n'.format(freq_channel[0]))\n",
    "cData = numpy.squeeze(cData)\n",
    "flags = numpy.squeeze(flags)\n",
    "\n",
    "if all(numpy.isnan(cData[time_integration, :])):\n",
    "    print('All visibilities for channel {} and time integration {} are flagged '\\\n",
    "          '- choose different values'.format(freq_channel, time_integration))\n",
    "\n",
    "ants = numpy.unique(RedG[:, 1:])\n",
    "no_ants = ants.size\n",
    "no_unq_bls = numpy.unique(RedG[:, 0]).size\n",
    "cRedG = relabelAnts(RedG)\n",
    "ant_pos_arr = flt_ant_pos(hdraw.antpos, ants)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_red_vis(cData, RedG, vis_type='amp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Redundant calibration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fundamentally, the problem of calibration boils down to the measurement equation:\n",
    "\n",
    "$$ V_{ij}^{\\text{obs}} (\\nu) = g_i (\\nu) g_j^* (\\nu) V_{ij}^{\\text{true}}(\\nu) + n_{ij} (\\nu) $$\n",
    "\n",
    "where the observed visibility $V_{ij}^{\\text{obs}}$ between antennas $i$ and $j$ at a given time and frequency is related to the true underlying visibility $V_{ij}^{\\text{true}}$ by a pair of complex and frequency-dependent gain factors, $g_i$ and $g_j$, if we assume per-antenna gains, along with uncorrelated random noise $n_{ij}$. The ultimate aim of calibration is to solve for these gains and true visibilities. \n",
    "\n",
    "An array with regularly spaced antennas has many redundant visibilities that are sensitive to the same modes on the sky. Redundant calibration uses the fact that the true visibilities from redundant baselines are equal. Supposing there are no direction-dependent calibration effects, we therefore have a system of equations for all antenna pairs $i$ and $j$:\n",
    "\n",
    "$$ V_{ij}^{\\text{obs}} (\\nu) = g_i (\\nu) g_j^* (\\nu) U_{\\alpha}(\\nu) + n_{ij} (\\nu) $$\n",
    "\n",
    "where $U_{\\alpha}(\\nu) = V(\\mathbf{r}_i-\\mathbf{r}_j)$, the visibility for the baseline vector $\\mathbf{b}_{ij} = \\mathbf{r}_i-\\mathbf{r}_j$, corresponds to a redundant baseline set that we index by $\\alpha$.\n",
    "\n",
    "For the planned full HERA array, there will be 331 elements in the hexagonal core, corresponding to $N_{\\mathrm{bl}} = 331(331-1)/2 = 54,615$ baselines. The core only has 630 unique baselines, which means that we have a non-linear system of $54,615$ equations to determine the 630 true visibilities and 331 gains."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Relative calibration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the redundant calibration prior, an MLE for the gains and true visibilities can be constructed by assuming a distribution for the observed visibility noise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gaussian distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assuming Gaussian uncorrelated noise with variance $\\sigma_{ij}^2$, which is the expected noise from the receivers and the sky, through MLE considerations, the gains and true visibilities can be found by minimizing the following negative log-likelihood function:\n",
    "\n",
    "$$ -\\ln(\\mathcal{L}^G_{\\mathrm{rel}})(\\nu) = \\frac{1}{2} \\sum_{\\alpha} \\sum_{\\{i,j\\}_{\\alpha}} \\ln(2 \\pi \\sigma_{ij}^2(\\nu)) + \\frac{ \\left| V_{ij}^{\\text{obs}} (\\nu) - g_i (\\nu) g_j^{*} (\\nu) U_{\\alpha}(\\nu) \\right|^2}{\\sigma_{ij}^2(\\nu)} $$\n",
    "\n",
    "where $\\{i,j\\}_{\\alpha}$ are sets of antennas that belong to baseline group $\\alpha$. This minimization is equivalent to minimizing the $\\chi^2$:\n",
    "\n",
    "$$ \\chi_{\\mathrm{rel}}^{2} (\\nu) = \\sum_{\\alpha} \\sum_{\\{i,j\\}_{\\alpha}} \\frac{ \\left| V_{ij}^{\\text{obs}} (\\nu) - g_i (\\nu) g_j^* (\\nu) U_{\\alpha}(\\nu) \\right|^2 }{\\sigma_{ij}^2(\\nu)} $$\n",
    "\n",
    "This non-linear least-squares optimization can be done independently between frequencies and time. Solving $ \\chi_{\\mathrm{rel}}^{2}$ has been the main focus of redundant calibration methods, with current efforts opting to linearize the measurement equation for computational ease."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cauchy distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Empirically, it is found that the noise from visibility observations from a redundant set may not be Gaussian, due to non-redundancies from instrumental effects and the presence of outliers (from e.g. RFI), and that the visibilities may follow a distribution with fatter tails. To be insensitive to outliers, so can employ robust statistics.\n",
    "\n",
    "We can extend the MLE analysis to different distributions for the visibility noise. As an example, we can assume a Cauchy distribution for the visibility noise, which has the median as its location parameter. This is a robust measure of central tendency and is used to reduce the effect of RFI; it is given by\n",
    "\n",
    "$$ f(x; x_0, \\gamma) = \\frac{1}{\\pi \\gamma \\left[ 1 + \\left( \\frac{x - x_0}{\\gamma} \\right)^2 \\right] }$$\n",
    "\n",
    "where $x_0$ is the location parameter (the median) and $\\gamma$ is the scale parameter, which specifies the HWHM.\n",
    "\n",
    "We no longer assume that the noise in the measurement equation is Gaussian, and instead, assume it is Cauchy distributed when solving for the relative redundant calibration parameters.\n",
    "\n",
    "Working in a maximum likelihood framework, the likelihood when solving for the measurement equation for redundant baseline sets is given by\n",
    "\n",
    "If we assume Cauchy distributed data, the negative log-likelihood when solving for redundant baseline sets is given by\n",
    "\n",
    "$$ -\\ln(\\mathcal{L}^C_{\\mathrm{rel}}) (\\nu) = \\sum_{\\alpha} \\sum_{\\{i,j\\}_{\\alpha}} \\ln(\\pi \\gamma_{ij} (\\nu)) + \\ln \\left( 1 + \\left( \\frac{\\left| V_{ij}^{\\text{obs}} (\\nu) - g_i (\\nu) g_j^* (\\nu) U_{\\alpha}(\\nu) \\right|}{\\gamma_{ij}(\\nu)} \\right)^2 \\right) $$\n",
    "\n",
    "This MLE with Cauchy-distributed noise fully encapsulates the distribution of the data, without being distorted by outliers, and is the best median estimator of the data.\n",
    "\n",
    "The advantage of the Cauchy distribution in fitting for redundant baselines is not clear-cut: while it does reduce the impact of outliers, it only performs better than the Gaussian in the presence of RFI, which is in the minority of cases. However, the use of the Cauchy could still be significant, especially if weak RFI is not picked up by flagging and the observations are integrated down. Further investigation is required to see if there is any merit in using the Cauchy distribution in such MLE computations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_vis = cData[time_integration, :]\n",
    "res_rel, initp = doRelCal(cRedG, obs_vis, no_unq_bls, no_ants, distribution=distribution, \\\n",
    "                   coords=rel_cal_coords, bounded=bounded_rel_cal, norm_gains=True, \\\n",
    "                   logamp=logamp, lovamp=lovamp, tilt_reg=tilt_reg, ant_pos_arr=ant_pos_arr, \\\n",
    "                   gphase_reg=gphase_reg, ref_ant_idx=rc_ref_ant_idx, max_nit=5000, return_initp=True)\n",
    "res_relx = numpy.array(res_rel['x'])\n",
    "if rel_cal_coords == 'polar' and rot_phase and (res_relx[-2*no_ants::2] < 0).any():\n",
    "    # adjustement if negative amplitude solutions are found, where the absolute values\n",
    "    # of amplitudes are taken, and phases of affected antennas are rotated by +pi\n",
    "    print('Rotating gain and visibility phases to have positive amplitudes.')\n",
    "    res_relx = rotate_phase(res_relx, no_unq_bls, norm_gains=True)\n",
    "    \n",
    "res_rel_vis, res_rel_gains = split_rel_results(res_relx, no_unq_bls, coords=rel_cal_coords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gain amplitudes\n",
    "if rel_cal_coords == 'polar':\n",
    "    gamps = res_relx[-2*no_ants::2]\n",
    "if rel_cal_coords == 'cartesian':\n",
    "    gamps = numpy.abs(res_rel_gains)\n",
    "print(gamps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gain phases\n",
    "if rel_cal_coords == 'polar':\n",
    "    gphases = res_relx[-2*no_ants+1::2]\n",
    "if rel_cal_coords == 'cartesian':\n",
    "    gphases = numpy.angle(res_rel_gains)\n",
    "print(gphases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some gain stats\n",
    "print('Gains - average amp: {}, product of amps: {}, average phase: {}'.format(gamps.mean(), \\\n",
    "      gamps.prod(), gphases.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tilt shifts\n",
    "tiltx = (gphases * ant_pos_arr[:, 0]).sum()\n",
    "tilty = (gphases * ant_pos_arr[:, 1]).sum()\n",
    "print('Tilt in x-coordinate: {}\\nTilt in y-coordinate: {}'.format(tiltx, tilty))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Residuals for relative redundant step\n",
    "pred_rel_vis = gVis(res_rel_vis, cRedG, res_rel_gains)\n",
    "rel_residuals = obs_vis - pred_rel_vis\n",
    "cplot(rel_residuals, xlabel='Baseline', ylabel='Residual')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Relative residuals normalized by amplitude\n",
    "norm_rel_residuals = norm_residuals(obs_vis, pred_rel_vis)\n",
    "cplot(norm_rel_residuals, xlabel='Baseline', ylabel='Normalized residual')\n",
    "print('Median absolute normalized residual - Real: {}, Imag: {}'\\\n",
    "      .format(*abs_residuals(norm_rel_residuals)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "autoscroll": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "## Constraining degeneracies (optimal calibration)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See [HERA Memo 63](http://reionization.org/wp-content/uploads/2013/03/HERA063_abs_cal_compare.pdf) for further details about constraining these degeneracies.\n",
    "\n",
    "Relative calibration yields solutions with degeneracies that can be parameterized as four terms per frequency:\n",
    " - Overall amplitude $A(\\nu)$\n",
    " - Overall phase $\\Delta(\\nu)$\n",
    " - Phase gradient components $\\Delta_x(\\nu)$ and $\\Delta_y(\\nu)$\n",
    " \n",
    "since the below transformations of these degenerate parameters leave $-\\ln(\\mathcal{L})$ (for both the Gaussian and Cauchy distributions) unchanged:\n",
    " - $g_i \\rightarrow A g_i$ accompanied by $U_{\\alpha} \\rightarrow A^{-2} U_{\\alpha}$\n",
    " - $g_k = |g_k|e^{i\\phi_k} \\rightarrow |g_k|e^{i(\\phi_k + \\Delta)}$, s.t. $g_k g_l^{*} = |g_k| |g_l| e^{i(\\phi_k - \\phi_l)} \\rightarrow |g_k| |g_l| e^{i(\\phi_k + \\Delta - \\phi_l - \\Delta)} = g_k g_l^{*}$\n",
    " - $g_k = |g_k|e^{i\\phi_k} \\rightarrow |g_k|e^{i(\\phi_k + \\Delta_x x_k + \\Delta_y y_k)}$ accompanied by $U_{\\alpha} = |U_{\\alpha}| e^{i\\phi_{\\alpha}} \\rightarrow |U_{\\alpha}| e^{i(\\phi_{\\alpha} - \\Delta_x x_{\\alpha} - \\Delta_y y_{\\alpha})}$\n",
    " \n",
    "where in the last line, the array is assumed to be co-planar, and $(x_k, y_k)$ are the positional coordinates of antenna $k$, and $(x_{\\alpha}, y_{\\alpha})$ are the separations of the antennas that form baselines in redundant set $\\alpha$.\n",
    "\n",
    "The degenerate parameters can be calculated from a sky model in an absolute calibration step. Alternatively, we can solve for these degenerate parameters by calculating them directly from the $-\\ln(\\mathcal{L})$ by applying a few conditions. This method, however, still ultimately needs to reference the sky to set the flux scale and phase centre.\n",
    "\n",
    "We first define a set of parameters $h_i$ to be the gains that obey the following constraints:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "    \\frac{1}{N} \\sum_i^N |h_i| = 1 \\quad \\rightarrow \\quad & \\text{mean gain amplitude of 1} \\\\\n",
    "\t\\frac{1}{N} \\sum_i^N \\mathrm{Arg} (h_i) = 0 \\quad \\rightarrow \\quad & \\text{mean gain phase of 0} \\\\\n",
    "    \\sum_i^N x_i \\mathrm{Arg} (h_i) = 0 \\quad \\rightarrow \\quad & \\text{phase gradient of 0 in }x \\\\\n",
    "\t\\sum_i^N y_i \\mathrm{Arg} (h_i) = 0 \\quad \\rightarrow \\quad & \\text{phase gradient of 0 in }y\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "such that the antenna gains can be written as\n",
    "\n",
    "$$ g_i (\\nu) = A(\\nu) e^{i \\left[ \\Delta (\\nu) + \\Delta_{x} (\\nu) x_{i} + \\Delta_{y} (\\nu) y_{i} \\right]} h_i (\\nu) $$\n",
    "\n",
    "where $(x_i, y_i)$ is the position of antenna $i$, so that all degenerate dependencies are removed from $h_i$. We note that these constraints are arbitrary.\n",
    "\n",
    "Non-degenerate formulations of the negative log-likelihoods from relative calibration are therefore given by \n",
    "\n",
    " - Gaussian distribution:\n",
    " \n",
    "$$ -\\ln(\\mathcal{L}^G_{\\mathrm{constr}})(\\nu) = \\frac{1}{2} \\sum_{\\alpha} \\sum_{\\{i,j\\}_{\\alpha}} \\ln(2 \\pi \\sigma_{ij}^2(\\nu)) + \\frac{ \\left| V_{ij}^{\\text{obs}} (\\nu) - h_i (\\nu) h_j^{*} (\\nu) W_{\\alpha} (\\nu) \\right|^2 }{\\sigma_{ij}^2(\\nu)} $$\n",
    "\n",
    " - Cauchy distribution:\n",
    "\n",
    "$$ -\\ln(\\mathcal{L}^C_{\\mathrm{constr}}) (\\nu) = \\sum_{\\alpha} \\sum_{\\{i,j\\}_{\\alpha}} \\ln(\\pi \\gamma_{ij} (\\nu)) + \\ln \\left( 1 + \\left( \\frac{\\left| V_{ij}^{\\text{obs}} (\\nu) - h_i (\\nu) h_j^{*} (\\nu) W_{\\alpha} (\\nu) \\right|}{\\gamma_{ij}(\\nu)} \\right)^2 \\right) $$\n",
    "\n",
    "where\n",
    "\n",
    "$$ W_{\\alpha} (\\nu) = A^2(\\nu) e^{i \\left[ \\Delta_{x} (\\nu) x_{\\alpha} + \\Delta_{y} (\\nu) y_{\\alpha} \\right]} U_{\\alpha} $$\n",
    "\n",
    "and $(x_{\\alpha}, y_{\\alpha})$ are the baseline coordinates of redundant set $\\alpha$.\n",
    " \n",
    "The overall phase is also degenerate and is set by requiring that the phase of the gain of a reference antenna is null; it is an arbitrary convention with no physical significance:\n",
    "\n",
    "$$ \\mathrm{Arg} (h_\\text{ref}) = 0 $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_ant = 85 # to set the overall phase\n",
    "ref_ant_idx = condenseMap(ants)[ref_ant]\n",
    "ant_sep = red_ant_sep(RedG, hdraw.antpos)\n",
    "\n",
    "res_opt = doOptCal(cRedG, obs_vis, no_ants, ant_pos_arr, ant_sep, res_rel_vis, \\\n",
    "                   distribution=distribution, ref_ant_idx=ref_ant_idx, logamp=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_gain_params, new_deg_params = numpy.split(res_opt['x'], [no_ants*2,])\n",
    "new_amps = new_gain_params[:no_ants*2:2]\n",
    "new_phases = new_gain_params[1:no_ants*2:2]\n",
    "new_gains = makeEArray(new_gain_params)\n",
    "\n",
    "print('Degenerate parameters: {}'.format(str(new_deg_params)[1: -1]))\n",
    "print('Amplitude mean: {}'.format(numpy.mean(new_amps)))\n",
    "print('Phase mean: {}'.format(numpy.mean(new_phases)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimal residuals for optimal redundant step\n",
    "opt_w_alpha = degVis(ant_sep, res_rel_vis, *new_deg_params[[0, 2, 3]])\n",
    "pred_opt_vis = gVis(opt_w_alpha, cRedG, new_gains)\n",
    "opt_residuals =  obs_vis - pred_opt_vis\n",
    "cplot(opt_residuals, xlabel='Baseline', ylabel='Residual')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalized amplitude residuals\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "ax.plot(norm_residuals(numpy.abs(obs_vis), numpy.abs(pred_opt_vis)))\n",
    "\n",
    "ax.set_xlabel('Baseline')\n",
    "ax.set_ylabel('Normalized residual')\n",
    "ax.set_ylim((-1, 1))\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Phase residuals\n",
    "diff_phases = numpy.angle(obs_vis) - numpy.angle(pred_opt_vis)\n",
    "# wrap between {-pi, pi}\n",
    "diff_phases_wrapped = (diff_phases + numpy.pi) % (2 * numpy.pi) - numpy.pi\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "ax.plot(diff_phases)\n",
    "ax.plot(diff_phases_wrapped, label='wrapped')\n",
    "\n",
    "ax.set_xlabel('Baseline')\n",
    "ax.set_ylabel('Normalized residual')\n",
    "ax.legend(loc='best')\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Residuals normalized by amplitude\n",
    "norm_opt_residuals = norm_residuals(obs_vis, pred_opt_vis)\n",
    "cplot(norm_opt_residuals, xlabel='Baseline', ylabel='Residual', ylim=(-1, 1))\n",
    "print('Median absolute normalized residual - Real: {}, Imag: {}'\\\n",
    "      .format(*abs_residuals(norm_opt_residuals)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing relative calibrations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To check the stability of the true visibilities for each baseline set, we perform relative calibration on neighbouring datasets in time, frequency, or JD, and compare their visibility solutions. These should be consistent up to the degenerate parameters $A$, $\\Delta_x$ and $\\Delta_y$. Marginalizing for these parameters with an MLE framework enables us to compare these solutions without having to first constrain their degeneracies, which can be computationally expensive.\n",
    "\n",
    "To compare datasets, we need to minimize:\n",
    "\n",
    "- Gaussian distribution:\n",
    "\n",
    "$$ -\\ln(\\mathcal{L}^G_{\\mathrm{deg}}) (\\nu) = \\frac{1}{2} \\sum_{\\alpha} \\sum_{\\{i,j\\}_{\\alpha}} \\ln(2 \\pi \\sigma_{ij}^2(\\nu)) + \\frac{ \\left| U_{\\alpha}' (\\nu) - W_{\\alpha} (\\nu) \\right|^2 }{\\sigma_{ij}^2(\\nu)} $$\n",
    "\n",
    "- Cauchy distribution:\n",
    "\n",
    "$$ -\\ln(\\mathcal{L}^C_{\\mathrm{deg}}) (\\nu) = \\sum_{\\alpha} \\sum_{\\{i,j\\}_{\\alpha}} \\ln(\\pi \\gamma_{ij} (\\nu)) + \\ln \\left( 1 + \\left( \\frac{\\left| U_{\\alpha}' (\\nu) - W_{\\alpha} (\\nu) \\right|}{\\gamma_{ij} (\\nu)} \\right)^2 \\right) $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdraw2, RedG2, cMData2 = group_data(zen_fn2, pol, freq_channel, None, bad_ants, flags_fn2)\n",
    "cData2 = cMData2.filled()\n",
    "flags2 = cMData2.mask\n",
    "\n",
    "if cData2.shape[0] > 1:\n",
    "    cData2 = cData2[0, ...]\n",
    "    flags2 = flags2[0, ...]\n",
    "cData2 = numpy.squeeze(cData2)\n",
    "flags2 = numpy.squeeze(flags2)  \n",
    "\n",
    "ants2 = numpy.unique(RedG2[:, 1:])\n",
    "no_ants2 = ants2.size\n",
    "no_unq_bls2 = numpy.unique(RedG2[:, 0]).size\n",
    "cRedG2 = relabelAnts(RedG2)\n",
    "\n",
    "redg_eq = numpy.array_equal(RedG, RedG2)\n",
    "print('Do the visibilities for JDs {} and {} have:\\n'\\\n",
    "      'the same flags? {}\\n'\\\n",
    "      'the same redundant grouping? {}'.format(JD, JD2, \\\n",
    "      numpy.array_equal(flags, flags2), redg_eq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find time integration in dataset 2 that corresponds to closest LST to that of dataset 1\n",
    "# This currently assumes that dataset 2 contains the correct time integration...\n",
    "time_integration2 = find_nearest(hdraw2.lsts, hdraw.lsts[time_integration])[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_red_vis(cData2, RedG2, vis_type='amp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Relative calibration for the 2nd dataset\n",
    "obs_vis2 = cData2[time_integration2, :]\n",
    "if not redg_eq:\n",
    "    initp = None\n",
    "    phase_reg_initp = False\n",
    "else:\n",
    "    phase_reg_initp = True\n",
    "res_rel2 = doRelCal(cRedG2, obs_vis2, no_unq_bls2, no_ants2, distribution=distribution, \\\n",
    "                    coords=rel_cal_coords, bounded=bounded_rel_cal, norm_gains=True, \\\n",
    "                    logamp=logamp, lovamp=lovamp, tilt_reg=tilt_reg, ant_pos_arr=ant_pos_arr, \\\n",
    "                    gphase_reg=gphase_reg, ref_ant_idx=rc_ref_ant_idx, max_nit=5000, initp=initp, \\\n",
    "                    phase_reg_initp=phase_reg_initp)\n",
    "res_relx2 = numpy.array(res_rel2['x'])\n",
    "\n",
    "if rel_cal_coords == 'polar' and rot_phase and (res_relx2[-2*no_ants::2] < 0).any():\n",
    "    print('Rotating gain and visibility phases to have positive amplitudes.')\n",
    "    res_relx2 = rotate_phase(res_relx2, no_unq_bls, norm_gains=True)\n",
    "\n",
    "res_rel_vis2, res_rel_gains2 = split_rel_results(res_relx2, no_unq_bls2, coords=rel_cal_coords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The negative log-likelihoods of the 1st and 2nd relative redundant calibrations '\\\n",
    "      'are:\\n{} and\\n{}'.format(res_rel['fun'], res_rel2['fun']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gain amplitudes for 2nd relative calibration results\n",
    "if rel_cal_coords == 'polar':\n",
    "    gamps2 = res_relx2[-2*no_ants::2]\n",
    "elif rel_cal_coords == 'cartesian':\n",
    "    gamps2 = numpy.abs(res_rel_gains2)\n",
    "print(gamps2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gain phases for 2nd relative calibration results\n",
    "if rel_cal_coords == 'polar':\n",
    "    gphases2 = res_relx2[-2*no_ants+1::2]\n",
    "elif rel_cal_coords == 'cartesian':\n",
    "    gphases2 = numpy.angle(res_rel_gains2)\n",
    "print(gphases2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Gains - average amp: {}, product of amps: {}, average phase: {}'.format(gamps2.mean(), \\\n",
    "      gamps2.prod(), gphases2.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ant_pos_arr2 = flt_ant_pos(hdraw2.antpos, ants2)\n",
    "tiltx2 = (gphases2 * ant_pos_arr2[:, 0]).sum()\n",
    "tilty2 = (gphases2 * ant_pos_arr2[:, 1]).sum()\n",
    "print('Tilt in x-coordinate: {}\\nTilt in y-coordinate: {}'.format(tiltx2, tilty2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visibility amplitudes from the 1st relative calibration\n",
    "numpy.abs(res_rel_vis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visibility amplitudes from the 2nd relative calibration\n",
    "numpy.abs(res_rel_vis2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visibility phases from the 1st relative calibration\n",
    "numpy.angle(res_rel_vis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visibility phases from the 2nd relative calibration\n",
    "numpy.angle(res_rel_vis2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Translating between relatively calibrated visibility sets\n",
    "res_deg = doDegVisVis(ant_sep, res_rel_vis, res_rel_vis2, \\\n",
    "                      distribution=distribution)\n",
    "deg_tr_params = res_deg['x']\n",
    "\n",
    "print('Degenerate parameters from degenerate fitting are: {}'.format(deg_tr_params))\n",
    "print('The negative log-likelihood for this fitting is: {}'.format(res_deg['fun']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Residuals for degenerate comparison\n",
    "deg_w_alpha = degVis(ant_sep, res_rel_vis, *deg_tr_params)\n",
    "deg_residuals = res_rel_vis2 - deg_w_alpha\n",
    "cplot(deg_residuals, xlabel='Redundant baseline type', ylabel='Residual')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Degenerate residuals normalized by amplitude\n",
    "norm_deg_residuals = norm_residuals(res_rel_vis2, deg_w_alpha)\n",
    "cplot(norm_deg_residuals, xlabel='Redundant baseline type', ylabel='Residual')\n",
    "print('Median absolute normalized residual - Real: {}, Imag: {}'\\\n",
    "      .format(*abs_residuals(norm_deg_residuals)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing optimally calibrated solutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ant_sep2 = red_ant_sep(RedG2, hdraw2.antpos)\n",
    "res_opt2 = doOptCal(cRedG2, obs_vis2, no_ants2, ant_pos_arr2, ant_sep2, res_rel_vis2, \\\n",
    "                    distribution=distribution, ref_ant_idx=ref_ant_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2nd optimally calibrated dataset\n",
    "new_gain_params2, new_deg_params2 = numpy.split(res_opt2['x'], [no_ants*2,])\n",
    "new_amps2 = new_gain_params2[:no_ants*2:2]\n",
    "new_phases2 = new_gain_params2[1:no_ants*2:2]\n",
    "new_gains2 = makeEArray(new_gain_params2)\n",
    "\n",
    "print('Degenerate parameters: {}'.format(str(new_deg_params2)[1: -1]))\n",
    "print('Amplitude mean: {}'.format(numpy.mean(new_amps2)))\n",
    "print('Phase mean: {}'.format(numpy.mean(new_phases2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, new_deg_params2 = numpy.split(res_opt2['x'], [no_ants*2,])\n",
    "opt_w_alpha2 = degVis(ant_sep, res_rel_vis2, *new_deg_params2[[0, 2, 3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_opt_deg = doDegVisVis(ant_sep, opt_w_alpha, opt_w_alpha2, \\\n",
    "                          distribution=distribution)\n",
    "deg_opt_tr_params = res_deg['x']\n",
    "\n",
    "print('Degenerate parameters from degenerate fitting are: {}'.format(deg_tr_params))\n",
    "print('The negative log-likelihood for this fitting is: {}'.format(res_deg['fun']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Degenerate residuals normalized by amplitude\n",
    "deg_opt_w_alpha = degVis(ant_sep, opt_w_alpha, *deg_opt_tr_params)\n",
    "norm_deg_opt_residuals = norm_residuals(opt_w_alpha2, deg_opt_w_alpha)\n",
    "cplot(norm_deg_opt_residuals, xlabel='Redundant baseline type', ylabel='Residual')\n",
    "print('Median absolute normalized residual - Real: {}, Imag: {}'\\\n",
    "      .format(*abs_residuals(norm_deg_opt_residuals)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Redundant calibration across JDs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As an extension of the redundant calibration presented in ยง1, we wish to solve for all data across JDs simultaneously to find a single set of redundant visibility solutions for any LAST}, which will give the best location and scale estimates for the redundant visibilities. This unified solver is advantageous for several reason:\n",
    "\n",
    " - The total number of parameters to be solved, compared with solving separately for each JD, is reduced, since only a single set of redundant visibilities is solved for: we require $2 \\times N_{\\text{days}} \\times N_{\\text{ants}} + 2 \\times N_{\\text{unq_bls}}$ parameters instead of $2 \\times N_{\\text{days}} \\times N_{\\text{ants}} + 2 \\times N_{\\text{days}} \\times N_{\\text{unq_bls}}$.\n",
    " - We avoid having to perform the degenerate translation step that finds the degenerate parameter offsets between the redundant visibilities so that they can be compared (see ยง2), which is additional computation.\n",
    " - The statistics of statistics of non-Gaussian distributions can be meaningless (e.g. the median of the median $\\neq$ the median of the whole dataset). By considering the entire dataset, we can obtain the best location and scale parameter estimates that fully encapsulate the data. This is especially relevant when dealing with robust distributions, such as the Cauchy distribution.\n",
    " \n",
    "The solved gains and redundant visibilities can be found by minimizing the following negative log-likelihood functions:\n",
    "\n",
    " - Gaussian uncorrelated noise with variance $\\sigma_{ij}^2$, which is the expected noise from the receivers and the sky\n",
    "\n",
    "$$ -\\ln(\\mathcal{L}^G_{\\mathrm{xd\\_rel}})(\\nu) = \\frac{1}{2} \\sum_{D} \\sum_{\\alpha} \\sum_{\\{i,j\\}_{\\alpha}} \\ln(2 \\pi \\sigma_{ij, d}^2(\\nu)) + \\frac{ \\left| V_{ij, d}^{\\text{obs}} (\\nu) - g_{i, d} (\\nu) g_{j, d}^{*} (\\nu) U_{\\alpha}(\\nu) \\right|^2}{\\sigma_{ij, d}^2(\\nu)} $$\n",
    "\n",
    " - Cauchy assumed distribution for the noise\n",
    "\n",
    "$$ -\\ln(\\mathcal{L}^C_{\\mathrm{xd\\_rel}}) (\\nu) = \\sum_{D} \\sum_{\\alpha} \\sum_{\\{i,j\\}_{\\alpha}} \\ln(\\pi \\gamma_{ij, d} (\\nu)) + \\ln \\left( 1 + \\left( \\frac{\\left| V_{ij, d}^{\\text{obs}} (\\nu) - g_{i, d} (\\nu) g_{j, d}^{*} (\\nu) U_{\\alpha}(\\nu) \\right|}{\\gamma_{ij, d}(\\nu)} \\right)^2 \\right) $$\n",
    "\n",
    "where there is now an added sum across JDs ($D$).\n",
    "\n",
    "The MLE with Cauchy-distributed noise fully encapsulates the distribution of the data, without being distorted by outliers, and is the best median estimator of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, _, xd_cdata, xd_cndata = XDgroup_data(JD, [int(JD), JD_comp], pol, chans=freq_channel, \\\n",
    "    tints=time_integration, bad_ants=True, use_flags='first', noise=True)\n",
    "\n",
    "xd_cdata = numpy.squeeze(xd_cdata.data)\n",
    "no_days = xd_cdata.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xd_res_rel = doRelCalD(cRedG, xd_cdata, no_unq_bls, no_ants, \\\n",
    "                       distribution=distribution, noise=None, initp=None, \\\n",
    "                       return_initp=False, xd=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xd_res_rel_vis, xd_res_rel_gains = split_rel_results(xd_res_rel['x'], no_unq_bls, \\\n",
    "                                                     coords='cartesian')\n",
    "xd_res_rel_gains = xd_res_rel_gains.reshape(no_days, -1)\n",
    "xd_res_rel_vis = numpy.tile(xd_res_rel_vis, no_days).reshape((no_days, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Residuals with observed raw data\n",
    "pred_xd_rel_vis = XDgVis(xd_res_rel_vis, cRedG, xd_res_rel_gains)\n",
    "xd_norm_rel_residuals = norm_residuals(xd_cdata, pred_xd_rel_vis)\n",
    "\n",
    "cplot(xd_norm_rel_residuals.transpose(), xlabel='Baseline', ylabel='Residual', alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Residuals with individually solved redundant calibration\n",
    "# amplitude only since phases are not degenerately consistent\n",
    "res_day1 = norm_residuals(numpy.abs(xd_res_rel_vis[0, :]), numpy.abs(res_rel_vis))\n",
    "res_day2 = norm_residuals(numpy.abs(xd_res_rel_vis[1, :]), numpy.abs(res_rel_vis2))\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "ax.plot(res_day1, label=int(JD))\n",
    "ax.plot(res_day2, label=JD_comp)\n",
    "\n",
    "ax.set_ylabel('Normalized residual of amplitudes')\n",
    "ax.set_xlabel('Baseline')\n",
    "ax.legend(loc='best')\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "name": "SimpleRedCal.ipynb",
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "12px",
    "width": "252px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": null,
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "from textwrap import wrap\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import ticker\n",
    "from scipy import signal\n",
    "from scipy.stats import mode\n",
    "\n",
    "from hera_cal.redcal import get_reds\n",
    "\n",
    "from plot_utils import clipped_heatmap\n",
    "from red_likelihood import fltBad, group_data, makeCArray, red_ant_sep\n",
    "from red_utils import find_flag_file, find_nearest, find_rel_df, find_zen_file, \\\n",
    "get_bad_ants, match_lst, split_rel_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "%matplotlib inline\n",
    "max_title_length = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "JD = 2458098.43869\n",
    "pol = 'ee'\n",
    "statistic = 'median' # {'mean', 'median'} used for averaging visibilities\n",
    "\n",
    "clip_pctile = 98 # for heatmaps to set vmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_figs = True\n",
    "if plot_figs:\n",
    "    import matplotlib as mpl\n",
    "    mpl.rcParams['figure.dpi'] = 300"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Difference in adjacent visibilities as an estimate of noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stat = getattr(numpy, statistic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zen_fn = find_zen_file(JD)\n",
    "bad_ants = get_bad_ants(zen_fn)\n",
    "flags_fn = find_flag_file(JD, 'first')\n",
    "\n",
    "hdraw, RedG, cMData = group_data(zen_fn, pol, None, None, bad_ants, flags_fn)\n",
    "cData_1 = cMData.filled()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Selecting visibilities for a given baseline type and frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_channel = 620"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reds = fltBad(get_reds(hdraw.antpos, pols=[pol]), bad_ants)\n",
    "bl_types = RedG[:, 0]\n",
    "slct_bl_type_id = mode(bl_types)[0][0] # selecting modal value for baseline type\n",
    "slct_bl_type = reds[slct_bl_type_id][0]\n",
    "slct_idxs = numpy.where(bl_types == slct_bl_type_id)[0]\n",
    "print('Selecting visibilities with baseline type {} that are redundant with '\\\n",
    "      'baseline {}, of which there are {}'.format(slct_bl_type_id, slct_bl_type, \\\n",
    "      slct_idxs.size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slct_vis_t = numpy.squeeze(cData_1[numpy.ix_([freq_channel], \\\n",
    "                                             numpy.arange(cData_1.shape[1]), slct_idxs)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis_amp_t = numpy.abs(slct_vis_t)\n",
    "last0 = round(hdraw.lsts[0], 3)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 7))\n",
    "plt.plot(vis_amp_t, alpha=0.5, linewidth=1)\n",
    "plt.plot(numpy.median(vis_amp_t, axis=1), linewidth=2, label='median', color='purple')\n",
    "plt.plot(numpy.mean(vis_amp_t, axis=1), linewidth=2, label='mean', color='orange')\n",
    "plt.xlabel('Time integration')\n",
    "plt.ylabel('Visibility amplitude')\n",
    "plt.title('\\n'.join(wrap('Amplitudes for visibilities with baselines redundant to {} at '\\\n",
    "    'frequency channel {} on JD {} at LAST {}'.format(slct_bl_type, freq_channel, int(JD), \\\n",
    "                                                      last0), 80)))\n",
    "plt.legend(loc=1)\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_t = pd.DataFrame(vis_amp_t).stack().reset_index()\n",
    "df_t.rename(columns={'level_0': 'time_int', 'level_1': 'bl', 0: 'vis_amp'}, inplace=True)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(11, 7))\n",
    "ax = sns.lineplot(x='time_int', y='vis_amp', data=df_t, ci='sd', linewidth=3)\n",
    "plt.xlabel('Time integration')\n",
    "plt.ylabel('Visibility amplitude')\n",
    "plt.title('\\n'.join(wrap(r'Median amplitude for visibilities with baselines redundant to '\\\n",
    "    '{} at frequency channel {} on JD {} at LAST {}, with 1$\\sigma$ confidence interval '\\\n",
    "    'shown'.format(slct_bl_type, freq_channel, int(JD), last0), max_title_length)))\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8, 7))\n",
    "plt.plot(numpy.angle(slct_vis_t), alpha=0.6)\n",
    "plt.xlabel('Time integration')\n",
    "plt.ylabel('Visibility phase')\n",
    "plt.title('\\n'.join(wrap('Phases for visibilities with baselines redundant to {} at '\\\n",
    "    'frequency channel {} on JD {} at LAST {}'\\\n",
    "                         .format(slct_bl_type, freq_channel, int(JD), last0), \\\n",
    "                                 80)))\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Selecting visibilities for a given baseline type and time integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tint = 20\n",
    "slct_vis_f = numpy.squeeze(cData_1[numpy.ix_(numpy.arange(cData_1.shape[0]), [tint], slct_idxs)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis_amp_f = numpy.abs(slct_vis_f)\n",
    "last0 = round(hdraw.lsts[0], 3)\n",
    "\n",
    "ytop = numpy.nanpercentile(vis_amp_f, 98.5)\n",
    "fig, ax = plt.subplots(figsize=(11, 7))\n",
    "plt.plot(vis_amp_f, alpha=0.3, linewidth=1)\n",
    "plt.plot(numpy.median(vis_amp_f, axis=1), linewidth=1.5, label='median', color='purple', alpha=0.8)\n",
    "plt.plot(numpy.mean(vis_amp_f, axis=1), linewidth=1.5, label='mean', color='orange', alpha=0.8)\n",
    "plt.ylim(-0.01, ytop)\n",
    "plt.xlabel('Frequency channel')\n",
    "plt.ylabel('Visibility amplitude')\n",
    "plt.title('\\n'.join(wrap('Amplitudes for visibilities with baselines redundant to {} at '\\\n",
    "    'time integration {} on JD {} at LAST {}'.format(slct_bl_type, int(tint), int(JD), \\\n",
    "                                                      last0), max_title_length)))\n",
    "plt.legend(loc=1)\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(11, 7))\n",
    "plt.plot(numpy.angle(slct_vis_f), alpha=0.5, linewidth=1)\n",
    "plt.xlabel('Time integration')\n",
    "plt.ylabel('Visibility phase')\n",
    "plt.title('\\n'.join(wrap('Phases for visibilities with baselines redundant to {} at '\\\n",
    "    'time integration {} on JD {} at LAST {}'\\\n",
    "                         .format(slct_bl_type, tint, int(JD), last0), \\\n",
    "                                 max_title_length)))\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribution of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting a particular frequency\n",
    "vis_amp_sample = vis_amp_f[freq_channel]\n",
    "\n",
    "from scipy.stats import cauchy, norm\n",
    "# fitting Gaussian and Cauchy distributions\n",
    "mu, std = norm.fit(vis_amp_sample)\n",
    "med, gamma = cauchy.fit(vis_amp_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frange = numpy.arange(freq_channel,freq_channel+5)\n",
    "vis_amp_samples = vis_amp_f[frange]\n",
    "\n",
    "cmap = plt.get_cmap('tab10')\n",
    "fig, ax = plt.subplots(figsize=(11, 7))\n",
    "for i, vis_amp_sample in enumerate(vis_amp_samples):\n",
    "    plt.hist(vis_amp_sample, bins=numpy.arange(0.005, 0.04, 0.002), density=True, alpha=0.2, color=cmap(i))\n",
    "    xmin, xmax = plt.xlim()\n",
    "    x = numpy.linspace(xmin, xmax, 1000)\n",
    "    mu, std = norm.fit(vis_amp_sample)\n",
    "    med, gamma = cauchy.fit(vis_amp_sample)\n",
    "    g = norm.pdf(x, mu, std)\n",
    "    c = cauchy.pdf(x, med, gamma)\n",
    "    plt.plot(x, g, linewidth=2, label='f{} Gaussian; $\\mu$ = {:.4f}, $\\sigma$ = {:.4f}'.format(frange[i], mu, std), color=cmap(i))\n",
    "    plt.plot(x, c, linewidth=2, label='f{} Cauchy; $x$ = {:.4f}, $\\gamma$ = {:.4f}'.format(frange[i], med, gamma), linestyle='dashed', color=cmap(i))\n",
    "#     title = 'Gaussian fit: $\\mu$ = {:.4f}, $\\sigma$ = {:.4f}\\n'.format(mu, std) + \\\n",
    "#             'Cauchy fit: $x$ = {:.4f}, $\\gamma$ = {:.4f}'.format(med, gamma)\n",
    "plt.legend()\n",
    "plt.title('\\n'.join(wrap('Amplitudes for visibilities with baselines redundant to {} at '\\\n",
    "    'frequency channels {}-{} and time integration {} on JD {} at LAST {}'.format(slct_bl_type, frange[0], \\\n",
    "                                                                   frange[-1], int(tint), int(JD), last0), 80)))\n",
    "plt.xlabel('Visibility amplitude')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# showing extreme case where Gaussian suffers\n",
    "frange = numpy.arange(700,702)\n",
    "vis_amp_samples = vis_amp_f[frange]\n",
    "\n",
    "cmap = plt.get_cmap('tab10')\n",
    "fig, ax = plt.subplots(figsize=(11, 7))\n",
    "for i, vis_amp_sample in enumerate(vis_amp_samples):\n",
    "    plt.hist(vis_amp_sample, bins=numpy.arange(0.005, 0.3, 0.002), density=True, alpha=0.2, color=cmap(i))\n",
    "    xmin, xmax = plt.xlim()\n",
    "    x = numpy.linspace(xmin, xmax, 1000)\n",
    "    mu, std = norm.fit(vis_amp_sample)\n",
    "    med, gamma = cauchy.fit(vis_amp_sample)\n",
    "    g = norm.pdf(x, mu, std)\n",
    "    c = cauchy.pdf(x, med, gamma)\n",
    "    plt.plot(x, g, linewidth=2, label='f{} Gaussian; $\\mu$ = {:.4f}, $\\sigma$ = {:.4f}'.format(frange[i], mu, std), color=cmap(i))\n",
    "    plt.plot(x, c, linewidth=2, label='f{} Cauchy; $x$ = {:.4f}, $\\gamma$ = {:.4f}'.format(frange[i], med, gamma), linestyle='dashed', color=cmap(i))\n",
    "#     title = 'Gaussian fit: $\\mu$ = {:.4f}, $\\sigma$ = {:.4f}\\n'.format(mu, std) + \\\n",
    "#             'Cauchy fit: $x$ = {:.4f}, $\\gamma$ = {:.4f}'.format(med, gamma)\n",
    "plt.legend()\n",
    "plt.title('\\n'.join(wrap('Amplitudes for visibilities with baselines redundant to {} at '\\\n",
    "    'frequency channels {}-{} and time integration {} on JD {} at LAST {}'.format(slct_bl_type, frange[0], \\\n",
    "                                                                   frange[-1], int(tint), int(JD), last0), 80)))\n",
    "plt.xlabel('Visibility amplitude')\n",
    "# plt.xlim(0, 0.05)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis_amp_f[383]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# showing extreme case where Gaussian suffers\n",
    "frange = numpy.arange(383,386)\n",
    "vis_amp_samples = vis_amp_f[frange]\n",
    "\n",
    "cmap = plt.get_cmap('tab10')\n",
    "fig, ax = plt.subplots(figsize=(11, 7))\n",
    "for i, vis_amp_sample in enumerate(vis_amp_samples):\n",
    "    plt.hist(vis_amp_sample, bins=numpy.arange(0.005, 0.3, 0.002), density=True, alpha=0.2, color=cmap(i))\n",
    "    xmin, xmax = plt.xlim()\n",
    "    x = numpy.linspace(0, 100, 10000)\n",
    "    mu, std = norm.fit(vis_amp_sample)\n",
    "    med, gamma = cauchy.fit(vis_amp_sample)\n",
    "    g = norm.pdf(x, mu, std)\n",
    "    c = cauchy.pdf(x, med, gamma)\n",
    "    plt.plot(x, g, linewidth=2, label='f{} Gaussian; $\\mu$ = {:.4f}, $\\sigma$ = {:.4f}'.format(frange[i], mu, std), color=cmap(i))\n",
    "    plt.plot(x, c, linewidth=2, label='f{} Cauchy; $x$ = {:.4f}, $\\gamma$ = {:.4f}'.format(frange[i], med, gamma), linestyle='dashed', color=cmap(i))\n",
    "#     title = 'Gaussian fit: $\\mu$ = {:.4f}, $\\sigma$ = {:.4f}\\n'.format(mu, std) + \\\n",
    "#             'Cauchy fit: $x$ = {:.4f}, $\\gamma$ = {:.4f}'.format(med, gamma)\n",
    "plt.legend()\n",
    "plt.title('\\n'.join(wrap('Amplitudes for visibilities with baselines redundant to {} at '\\\n",
    "    'frequency channels {}-{} and time integration {} on JD {} at LAST {}'.format(slct_bl_type, frange[0], \\\n",
    "                                                                   frange[-1], int(tint), int(JD), last0), 80)))\n",
    "plt.xlabel('Visibility amplitude')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Goodness of fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis_amp_sample = vis_amp_f[freq_channel]\n",
    "from scipy.stats import kstest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### KS-test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kstest(vis_amp_sample, 'norm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kstest(vis_amp_sample, 'cauchy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Log-likelihood"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gaussian negative log-likelihood:\n",
    "\n",
    "$$ - \\ln{(\\mathcal{L}^G)} = \\frac{N}{2} \\ln \\left( 2\\pi\\sigma^2 \\right) + \\frac{1}{2\\sigma^2} \\sum_{i=1}^N \\left( x_i - \\mu \\right)^2 $$\n",
    "\n",
    "Cauchy negative log-likelihood:\n",
    "\n",
    "$$ - \\ln{(\\mathcal{L}^C)} = N \\ln{\\left( \\pi \\gamma \\right)} + \\sum_{i=1}^N \\ln{ \\left( 1 + \\left( \\frac{x_i - x}{\\gamma} \\right)^2 \\right)} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logl_g(obs, mean, std):\n",
    "    nll = obs.size*numpy.log(2*numpy.pi*std**2)/2 + numpy.square(obs - mean).sum()/(2*std**2)\n",
    "    return -nll\n",
    "\n",
    "def logl_c(obs, med, hwhm):\n",
    "    nll = obs.size*numpy.log(numpy.pi*hwhm) + (numpy.log(numpy.square((obs - med)/hwhm) + 1)).sum()\n",
    "    return -nll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logl_g_res = numpy.empty(vis_amp_f.shape[0])\n",
    "logl_c_res = numpy.empty_like(logl_g_res)\n",
    "l_ratio = numpy.empty_like(logl_g_res)\n",
    "\n",
    "for i, vis_amp_s in enumerate(vis_amp_f):\n",
    "    if not numpy.isnan(vis_amp_s).all():\n",
    "        mu, sigma = norm.fit(vis_amp_s)\n",
    "        med, gamma = cauchy.fit(vis_amp_s)\n",
    "        logl_g_i = logl_g(vis_amp_s, mu, sigma)\n",
    "        logl_c_i = logl_c(vis_amp_s, med, gamma)\n",
    "        \n",
    "    else:\n",
    "        logl_g_i = numpy.nan\n",
    "        logl_c_i = numpy.nan\n",
    "    \n",
    "    logl_g_res[i] = logl_g_i\n",
    "    logl_c_res[i] = logl_c_i\n",
    "    l_ratio[i] = -2 * (logl_g_i - logl_c_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(11, 7))\n",
    "plt.plot(-logl_g_res, label='Gaussian', alpha=0.6)\n",
    "plt.plot(-logl_c_res, label='Cauchy', alpha=0.6)\n",
    "# plt.plot(l_ratio, label='Likelihood ratio')\n",
    "plt.xlabel('Frequency channel')\n",
    "plt.ylabel('Negative log-likelihood')\n",
    "plt.title('\\n'.join(wrap('Comparison of negative log-likelihoods for Gaussian and Cauchy fittings across frequencies for '\\\n",
    "                         'visibilities with baselines redundant to {} '\\\n",
    "                         'at time integration {} on JD {} at LAST {}'.format(slct_bl_type, int(tint), int(JD), last0), 100)))\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Student's t-distribution\n",
    "\n",
    "Non-standardized probability density function:\n",
    "$$\tf(t; \\nu, x_0, \\gamma) = \\frac{\\Gamma \\left( \\frac{\\nu + 1}{2} \\right)}{\\sqrt{\\pi \\nu} \\Gamma \\left( \\frac{\\nu}{2} \\right) \\gamma } \\left(1 + \\frac{1}{\\nu} \\left( \\frac{t - x_0}{\\gamma} \\right)^2 \\right) ^{-\\frac{\\nu + 1}{2}} $$\n",
    "\n",
    "Log-likelihood:\n",
    "$$ -\\log{\\left( \\mathcal{L}^T \\right)} \\left( \\nu, x_0, \\gamma \\right)  = - N \\ln{\\left( \\Gamma \\left( \\frac{\\nu + 1}{2} \\right) \\right)}  + \\frac{N}{2} \\ln{ \\left( \\pi \\nu \\right) } + N \\ln{ \\left( \\Gamma \\left( \\frac{\\nu}{2} \\right) \\right) } + N \\ln{ \\left( \\gamma \\right) } + \\frac{\\nu+1}{2} \\sum_i^N \\ln{ \\left( 1 + \\frac{1}{\\nu} \\left( \\frac{t_i - x_0}{\\gamma} \\right)^2 \\right) } $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import t as student_t\n",
    "\n",
    "loc = 0\n",
    "gamma = 2\n",
    "nus = [1, 2, 3, 4, 5]\n",
    "x = numpy.linspace(-20, 20, 1000)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(11, 7))\n",
    "\n",
    "for nu in nus:\n",
    "    dist = student_t.pdf(x, nu, loc, gamma)\n",
    "    plt.plot(x, dist, label=r'$\\nu$ = {}, $x_0=0$, $\\gamma = 2$'.format(nu))\n",
    "\n",
    "plt.plot(x, norm.pdf(x, 0, 2), ls='--', label=r'Norm, $\\mu=0$, $\\sigma = 2$')\n",
    "plt.xlim(-10, 10)\n",
    "\n",
    "plt.xlabel('$t$')\n",
    "plt.ylabel(r'$P(t| \\nu, x, \\gamma )$')\n",
    "plt.title('Student\\'s $t$ Distribution')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import gamma as gammaf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logl_t(obs, nu, loc, scale):\n",
    "    ll = obs.size*(numpy.log(gammaf(0.5*(nu + 1))) - 0.5*numpy.log(numpy.pi * nu) - \\\n",
    "                   numpy.log(gammaf(0.5*nu)) - numpy.log(scale)) - \\\n",
    "                   0.5*(nu + 1)*(numpy.log(1 + (1/nu)*numpy.square((obs - loc)/scale))).sum() \n",
    "    return ll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis_amp_f.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logl_g_res = numpy.empty(vis_amp_f.shape[0])\n",
    "logl_t2_res = numpy.empty_like(logl_g_res)\n",
    "logl_t3_res = numpy.empty_like(logl_g_res)\n",
    "logl_t4_res = numpy.empty_like(logl_g_res)\n",
    "logl_t5_res = numpy.empty_like(logl_g_res)\n",
    "logl_t20_res = numpy.empty_like(logl_g_res)\n",
    "\n",
    "for i, vis_amp_s in enumerate(vis_amp_f):\n",
    "    if not numpy.isnan(vis_amp_s).all():\n",
    "        mu, sigma = norm.fit(vis_amp_s)\n",
    "        logl_g_i = logl_g(vis_amp_s, mu, sigma)\n",
    "        \n",
    "        df, med, gamma = student_t.fit(vis_amp_s, f0=2)\n",
    "        logl_t2_i = logl_t(vis_amp_s, 2, med, gamma)\n",
    "\n",
    "        df, med, gamma = student_t.fit(vis_amp_s, f0=3)\n",
    "        logl_t3_i = logl_t(vis_amp_s, 3, med, gamma)\n",
    "        \n",
    "        df, med, gamma = student_t.fit(vis_amp_s, f0=4)\n",
    "        logl_t4_i = logl_t(vis_amp_s, 4, med, gamma)\n",
    "        \n",
    "        df, med, gamma = student_t.fit(vis_amp_s, f0=5)\n",
    "        logl_t5_i = logl_t(vis_amp_s, 5, med, gamma)\n",
    "        \n",
    "        df, med, gamma = student_t.fit(vis_amp_s, f0=20)\n",
    "        logl_t20_i = logl_t(vis_amp_s, 20, med, gamma)\n",
    "        \n",
    "    else:\n",
    "        logl_g_i = numpy.nan\n",
    "        logl_t2_i = logl_t3_i = logl_t4_i = logl_t5_i = logl_t20_i = numpy.nan\n",
    "    \n",
    "    logl_g_res[i] = logl_g_i\n",
    "    logl_t2_res[i] = logl_t2_i\n",
    "    logl_t3_res[i] = logl_t3_i\n",
    "    logl_t4_res[i] = logl_t4_i\n",
    "    logl_t5_res[i] = logl_t5_i\n",
    "    logl_t20_res[i] = logl_t20_i\n",
    "#     l_ratio[i] = -2 * (logl_g_i - logl_t_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(11, 7))\n",
    "plt.plot(-logl_g_res, label='Gaussian', alpha=0.5, linewidth=1)\n",
    "# plt.plot(-logl_t2_res, label=r\"Student's t, $\\nu=2$\", alpha=0.5, linewidth=1)\n",
    "plt.plot(-logl_c_res, label='Cauchy', alpha=0.5, linewidth=1)\n",
    "plt.plot(-logl_t3_res, label=r\"Student's t, $\\nu=3$\", alpha=0.5, linewidth=1)\n",
    "# plt.plot(-logl_t4_res, label=r\"Student's t, $\\nu=4$\", alpha=0.5, linewidth=1)\n",
    "# plt.plot(-logl_t20_res, label=r\"Student's t, $\\nu=5$\", alpha=0.5, linewidth=1)\n",
    "plt.xlabel('Frequency channel')\n",
    "plt.ylabel('Negative log-likelihood')\n",
    "plt.title('\\n'.join(wrap('Comparison of negative log-likelihoods for Gaussian and Cauchy fittings across frequencies for '\\\n",
    "                         'visibilities with baselines redundant to {} '\\\n",
    "                         'at time integration {} on JD {} at LAST {}'.format(slct_bl_type, int(tint), int(JD), last0), 100)))\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adjacent time integrations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a given baseline, one can compare the visibilities between one time integration and the next to get an estimate of the system noise, since the difference between adjacent visibilities will encapsulate both the noise and the difference in the observed sky (due to a slight drift). The statistics of the difference in visibilities therefore provides an upper bound on the noise of the visibilities.\n",
    "\n",
    "We take the standard deviation of the different between visibilities adjacent in time for an entire dataset, as a proxy for the noise. This must first be done per baseline and per frequency. The noise for redundant baselines can then be combined through propagation of error considerations.\n",
    "\n",
    "n.b. the variance of a complex random variable $z$ is equal to the sum of the variances of its real and imaginary parts:\n",
    "\n",
    "$$ \\mathrm{Var}[z] = \\mathrm{Var}[\\Re(z)] + \\mathrm{Var}[\\Im(z)] $$\n",
    "\n",
    "which we use when calculating the standard deviation of complex visibilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis_diffs = numpy.empty((cData_1.shape[0], cData_1.shape[1]-1, \\\n",
    "                         cData_1.shape[2]), dtype=complex)\n",
    "noise_std = numpy.empty((cData_1.shape[0], cData_1.shape[2]))\n",
    "stat_vis_amp = numpy.empty_like(noise_std)\n",
    "for bl in range(cData_1.shape[2]):\n",
    "    for freq in range(cData_1.shape[0]):\n",
    "        vdiff = numpy.asarray([t - s for s, t in zip(cData_1[freq, :, bl], \\\n",
    "                                                     cData_1[freq, 1:, bl])])\n",
    "        vis_diffs[freq, :, bl] = vdiff\n",
    "        noise_std[freq, bl] = numpy.sqrt(numpy.var(vdiff.real) + \\\n",
    "                                             numpy.var(vdiff.imag))\n",
    "        stat_vis_amp[freq, bl] = stat(numpy.abs(cData_1[freq, :, bl]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We add errors in quadrature when considering the noise across a redundant baseline type, assuming an error covariance of zero (independent measurements and uncorrelated errors).\n",
    "\n",
    "$$\\sigma_{\\text{red_group}} = \\frac{1}{N} \\sqrt{\\sum_i{\\sigma_i^2}} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_unq_bls = numpy.unique(bl_types).size\n",
    "red_noise = numpy.empty((cData_1.shape[0], no_unq_bls))\n",
    "red_vis_amp = numpy.empty_like(red_noise)\n",
    "\n",
    "for bl_type in range(no_unq_bls):\n",
    "    group_idxs = numpy.where(bl_types == bl_type)[0]\n",
    "    grouped_noise = noise_std[:, group_idxs]\n",
    "    grouped_vis_amp = stat_vis_amp[:, group_idxs]\n",
    "    red_noise[:, bl_type] = numpy.sqrt(numpy.sum(numpy.square(grouped_noise), axis=1)) \\\n",
    "                            / grouped_noise.shape[1]\n",
    "    red_vis_amp[:, bl_type] = stat(grouped_vis_amp, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "variables": {
     "reds[slct_bl_type][0]": {}
    }
   },
   "source": [
    "### Single baseline: {{reds[slct_bl_type][0]}}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "variables": {
     "freq_channel": {}
    }
   },
   "source": [
    "#### Single frequency: channel {{freq_channel}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bl_grp_id = 0 # ID of baseline within its group\n",
    "bl_id = slct_idxs[bl_grp_id]\n",
    "\n",
    "vis_bl_t = cData_1[:, :, bl_id]\n",
    "print('From the {} baselines of type {} selected, only consider baseline {}\\n'\\\n",
    "      .format(slct_idxs.size, slct_bl_type, reds[slct_bl_type_id][bl_grp_id]))\n",
    "\n",
    "vis_diffs_t = vis_diffs[:, :, bl_id]\n",
    "noise_std_t = noise_std[freq_channel, bl_id]\n",
    "stat_vis_amp_t = stat_vis_amp[freq_channel, bl_id]\n",
    "print('Upper bound on noise, by comparing adjacent visibilities in time for '\\\n",
    "      'frequency channel {} is {}, which is {}% of the {} visibility amplitude'.\\\n",
    "      format(freq_channel, round(noise_std_t, 5), round(100*noise_std_t/stat_vis_amp_t, 1), \\\n",
    "             statistic))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Noise per frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis_bl_tf = cData_1[..., bl_id]\n",
    "vis_diffs_tf = vis_diffs[..., bl_id]\n",
    "noise_std_tf = noise_std[..., bl_id]\n",
    "stat_vis_amp_tf = stat_vis_amp[..., bl_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = clipped_heatmap(numpy.abs(vis_diffs_tf).transpose(), 'Time integration')\n",
    "ax.set_title('\\n'.join(wrap('Residual between adjacent visibilities (in time) for baselines '\\\n",
    "    'redundant to {} on JD {} at LAST {}'.format(slct_bl_type, int(JD), last0), \\\n",
    "                                                 max_title_length)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(11, 7))\n",
    "plt.plot(noise_std_tf)\n",
    "ax.set_yscale('log')\n",
    "plt.xlabel('Frequency channel')\n",
    "plt.ylabel('Log-noise')\n",
    "plt.title('\\n'.join(wrap('Log of the standard deviation of residuals between adjacent '\\\n",
    "    'visibilities (in time) for baselines redundant to {} on JD {} at LAST {}'\\\n",
    "                         .format(slct_bl_type, int(JD), last0), max_title_length)))\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frac_noise_tf = noise_std_tf/stat_vis_amp_tf\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(11, 7))\n",
    "plt.plot(frac_noise_tf)\n",
    "plt.xlabel('Frequency channel')\n",
    "plt.ylabel('Fractional noise')\n",
    "plt.title('\\n'.join(wrap('Standard deviation of residuals between adjacent visibilities '\\\n",
    "    '(in time) for baselines redundant to {}, divided by the {} visibility amplitude on JD '\\\n",
    "    '{} at LAST {}'.format(slct_bl_type, int(JD), last0, statistic), max_title_length)))\n",
    "ytop = numpy.ceil(numpy.nanpercentile(frac_noise_tf, clip_pctile))\n",
    "plt.ylim(bottom=0, top=ytop)\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Redundant baseline group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Considering baselines of type {}'.format(slct_bl_type))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis_diffs_tfb = cData_1[..., slct_idxs]\n",
    "noise_std_tfb = noise_std[..., slct_idxs]\n",
    "stat_vis_amp_tfb = stat_vis_amp[..., slct_idxs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(11, 7))\n",
    "for bl in range(noise_std_tfb.shape[1]):\n",
    "    plt.plot(noise_std_tfb[:, bl], alpha=0.3, linewidth=1)\n",
    "ax.set_yscale('log')\n",
    "plt.xlabel('Frequency channel')\n",
    "plt.ylabel('Log-noise')\n",
    "plt.title('\\n'.join(wrap('Log of the standard deviation of residuals between adjacent '\\\n",
    "    'visibilities (in time) for baselines of type {} on JD {} at LAST {}'\\\n",
    "                         .format(slct_bl_type, int(JD), last0), max_title_length)))\n",
    "plt.ylim(1e-4, 1e0)\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frac_noise_tfb = noise_std_tfb/stat_vis_amp_tfb\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(11, 7))\n",
    "for bl in range(noise_std_tfb.shape[1]):\n",
    "    plt.plot(frac_noise_tfb[:, bl], alpha=0.3, linewidth=1)\n",
    "plt.xlabel('Frequency channel')\n",
    "plt.ylabel('Fractional noise')\n",
    "plt.title('\\n'.join(wrap('Standard deviation of residuals between adjacent visibilities '\\\n",
    "    '(in time) divided by the {} visibility amplitude, for baselines of type {} on JD {} '\\\n",
    "    'at LAST {}'.format(statistic, slct_bl_type, int(JD), last0), max_title_length)))\n",
    "ytop = numpy.ceil(numpy.nanpercentile(frac_noise_tfb, clip_pctile))\n",
    "plt.ylim(bottom=0, top=ytop)\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = clipped_heatmap((noise_std_tfb/stat_vis_amp_tfb).transpose(), 'Baseline')\n",
    "ax.set_title('\\n'.join(wrap('Standard deviation of residuals between adjacent visibilities '\\\n",
    "    '(in time) divided by the {} visibility amplitude, for baselines in redundant group {} '\\\n",
    "    'on JD {} at LAST {}'.format(statistic, slct_bl_type, int(JD), last0), max_title_length)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Noise across redundant group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "red_noise_g = red_noise[:, slct_bl_type_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(11, 7))\n",
    "plt.plot(red_noise_g)\n",
    "ax.set_yscale('log')\n",
    "plt.xlabel('Frequency channel')\n",
    "plt.ylabel('Log-noise')\n",
    "plt.title('\\n'.join(wrap('Log of the combined standard deviation of residuals between '\\\n",
    "    'adjacent visibilities (in time) for baseline group of type {} on JD {} at LAST {}'\\\n",
    "                         .format(slct_bl_type, int(JD), last0), max_title_length)))\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frac_noise_redg = red_noise_g/stat(stat_vis_amp[:, slct_idxs], axis=1)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(11, 7))\n",
    "plt.plot(frac_noise_redg)\n",
    "plt.xlabel('Frequency channel')\n",
    "plt.ylabel('Fractional noise')\n",
    "plt.title('\\n'.join(wrap('Standard deviation of residuals between adjacent visibilities '\\\n",
    "    '(in time) divided by the {} visibility amplitude, for baselines redundant with {} on '\\\n",
    "    'JD {} at LAST {}'.format(statistic, slct_bl_type, int(JD), last0), max_title_length)))\n",
    "ytop = numpy.ceil(numpy.nanpercentile(frac_noise_tfb, clip_pctile))\n",
    "plt.ylim(bottom=0, top=1)\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting individual and combined noise together\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(11, 7))\n",
    "for bl in range(noise_std_tfb.shape[1]):\n",
    "    plt.plot(frac_noise_tfb[:, bl], alpha=0.3, linewidth=1)\n",
    "plt.plot(frac_noise_redg, linewidth=1.5, color='purple', label='Combined noise', alpha=0.8)\n",
    "plt.xlabel('Frequency channel')\n",
    "plt.ylabel('Fractional noise')\n",
    "plt.title('\\n'.join(wrap('Standard deviation of residuals between adjacent visibilities '\\\n",
    "    '(in time) divided by the {} visibility amplitude, for baselines redundant with {} on '\\\n",
    "    'JD {} at LAST {}'.format(statistic, slct_bl_type, int(JD), last0), max_title_length)))\n",
    "plt.ylim(bottom=0, top=3)\n",
    "plt.legend(loc=1)\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Noise power spectrum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chan_bottom = 400\n",
    "chan_top = 700"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "variables": {
     "chan_bottom": {},
     "chan_top": {}
    }
   },
   "source": [
    "Examining the power spectrum of the noise, between frequency channels {{chan_bottom}} and {{chan_top}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resolution = hdraw.freqs[1] - hdraw.freqs[0] # Hz\n",
    "f, Pxx_spec = signal.periodogram(frac_noise_redg[numpy.arange(chan_bottom,chan_top)], \\\n",
    "                                 resolution, window='blackmanharris', detrend=False, \\\n",
    "                                 scaling='spectrum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "plt.semilogy(f, numpy.sqrt(Pxx_spec))\n",
    "plt.xlabel('Delay [s]')\n",
    "plt.ylabel('Power spectrum [V RMS]')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Noise across baselines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_bls_g = numpy.array([numpy.array(group).shape[0] for group in reds])\n",
    "red_bl_lengths = numpy.sqrt(numpy.sum(numpy.square(red_ant_sep(RedG, hdraw.antpos)), axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_bl_info = {'Baseline type':[i[0] for i in reds], \\\n",
    "                'Number of baselines': no_bls_g, \\\n",
    "                'Baseline length': red_bl_lengths,\n",
    "                'Redundant baselines': reds}\n",
    "df_bl_info = pd.DataFrame.from_dict(dict_bl_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bl_info.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frac_noise = red_noise/red_vis_amp\n",
    "fig, ax = clipped_heatmap(frac_noise.transpose(), 'Baseline type')\n",
    "ax.set_title('\\n'.join(wrap('Standard deviation of residuals between adjacent visibilities '\\\n",
    "    '(in time) divided by the {} visibility amplitude, for all redundant baseline types, '\\\n",
    "    'on JD {} at LAST {}'.format(statistic, int(JD), last0), max_title_length)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The lower baseline type IDs correspond to shorter baselines, with baseline length increase (and number of baselines decreasing) with as the baseline type ID increases. We find that the shorter baselines higher frequency channels have the lowest noise out of our dataset.\n",
    "\n",
    "Note that the closure phase analysis found that the optimal frequency ranges for are $110-136$ MHz and $151-173$ MHz, corresponding to channels $102-369$ and $522-748$, respectively (see [HERA Memo 54](http://reionization.org/wp-content/uploads/2018/11/hera-memo-54.pdf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normalizing by number of baselines in each group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nrm_no_bl_frac_noise = frac_noise*numpy.sqrt(no_bls_g[None, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = clipped_heatmap(nrm_no_bl_frac_noise.transpose(), 'Baseline type')\n",
    "ax.set_title('\\n'.join(wrap('Standard deviation of residuals between adjacent visibilities '\\\n",
    "    '(in time) divided by the {} visibility amplitude, for all redundant baseline types, '\\\n",
    "    'on JD {} at LAST {}, multiplied by the square root of the number of baselines for each '\\\n",
    "    'type'.format(statistic, int(JD), last0), max_title_length)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this heatmap, if the number of of baselines in each redundant group is taken into account (multiply the noise by $\\sqrt{N}$), the noise seems to be of around the same magnitude across all groups."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Further normalize by baseline length in each group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nrm_no_bl_length_frac_noise = nrm_no_bl_frac_noise/red_bl_lengths[None, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = clipped_heatmap(nrm_no_bl_length_frac_noise.transpose(), 'Baseline type')\n",
    "ax.set_title('\\n'.join(wrap('Standard deviation of residuals between adjacent visibilities '\\\n",
    "    '(in time) divided by the {} visibility amplitude, for all redundant baseline types, '\\\n",
    "    'on JD {} at LAST {}, multiplied by the square root of the number of baselines and '\\\n",
    "    'divided by the baseline length, for each type'.format(statistic, int(JD), last0), \\\n",
    "                                                           max_title_length)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Same LAST on different JDs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An alternative estimate of the noise is by looking at visibilities from different JDs that match in LAST, although the visibilities on different JDs may vastly differ due to the variability of the instrumental gains and other effects (e.g. ionosphere)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "JD_2a= match_lst(JD, 2458099) # finding the JD_time of the zen_file\n",
    "# that matches the LAST of the first dataset used\n",
    "zen_fn2a = find_zen_file(JD_2a)\n",
    "bad_ants2a = get_bad_ants(zen_fn2a)\n",
    "flags_fn2a = find_flag_file(JD_2a, 'first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_df = pd.read_pickle('jd_lst_map_idr2.pkl')\n",
    "\n",
    "next_row = numpy.where(last_df['JD_time'] == JD_2a)[0][0] + 1\n",
    "JD_2b = last_df.iloc[next_row]['JD_time']\n",
    "zen_fn2b = find_zen_file(JD_2b)\n",
    "bad_ants2b = get_bad_ants(zen_fn2b)\n",
    "flags_fn2b = find_flag_file(JD_2b, 'first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last1 = last_df[last_df['JD_time'] == JD]['LASTs'].values[0]\n",
    "last2 = last_df[last_df['JD_time'] == JD_2a]['LASTs'].values[0]\n",
    "_, offset = find_nearest(last2, last1[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, _, cMData = group_data(zen_fn2a, pol, None, None, bad_ants2a, flags_fn2a)\n",
    "cData_2a = cMData.filled()[:, offset:, :]\n",
    "\n",
    "_, _, cMData = group_data(zen_fn2b, pol, None, None, bad_ants2b, flags_fn2b)\n",
    "cData_2b = cMData.filled()[:, :offset, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cData_2 = numpy.concatenate((cData_2a, cData_2b), axis=1)\n",
    "del cData_2a, cData_2b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Selecting visibilities for a given baseline type and frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slct_vis_j = numpy.squeeze(cData_2[numpy.ix_([freq_channel], \\\n",
    "                                             numpy.arange(cData_2.shape[1]), slct_idxs)])\n",
    "vis_amp_j = numpy.abs(slct_vis_j)\n",
    "lastj = round(last2[offset], 3)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(11, 7))\n",
    "plt.plot(vis_amp_j, alpha=0.5, linewidth=1)\n",
    "plt.plot(numpy.median(vis_amp_j, axis=1), linewidth=2, color='purple', label='median')\n",
    "plt.xlabel('Time integration')\n",
    "plt.ylabel('Visibility amplitude')\n",
    "plt.title('\\n'.join(wrap('Amplitudes for visibilities with baselines redundant to {} at '\\\n",
    "    'frequency channel {} on JD {} at LAST {}'.format(slct_bl_type, freq_channel, int(JD_2a), \\\n",
    "                                                      lastj), max_title_length)))\n",
    "plt.legend()\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(11, 7))\n",
    "plt.plot(numpy.median(vis_amp_t, axis=1), label=str(JD))\n",
    "plt.plot(numpy.median(vis_amp_j, axis=1), label=str(JD_2a))\n",
    "plt.xlabel('Time integration')\n",
    "plt.ylabel('Visibility amplitude')\n",
    "plt.title('Median visibility amplitude on separate JD days but same LAST')\n",
    "plt.title('\\n'.join(wrap('Median visibility amplitudes for baselines redundant to {} at '\\\n",
    "    'frequency channel {} on JDs {} and {} at LAST {}'.format(slct_bl_type, freq_channel, \\\n",
    "    int(JD), int(JD_2a), lastj), max_title_length)))\n",
    "plt.legend()\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Noise diagnostics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis_diffs_j = numpy.empty((cData_2.shape[0], cData_2.shape[1]-1, \\\n",
    "                           cData_2.shape[2]), dtype=complex)\n",
    "noise_std_j = numpy.empty((cData_2.shape[0], cData_2.shape[2]))\n",
    "stat_vis_amp_j = numpy.empty_like(noise_std_j)\n",
    "for bl in range(cData_2.shape[2]):\n",
    "    for freq in range(cData_2.shape[0]):\n",
    "        vdiff = numpy.asarray([t - s for s, t in zip(cData_2[freq, :, bl], \\\n",
    "                                                     cData_2[freq, 1:, bl])])\n",
    "        vis_diffs_j[freq, :, bl] = vdiff\n",
    "        noise_std_j[freq, bl] = numpy.sqrt(numpy.var(vdiff.real) + \\\n",
    "                                           numpy.var(vdiff.imag))\n",
    "        stat_vis_amp_j[freq, bl] = stat(numpy.abs(cData_2[freq, :, bl]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "red_noise_j = numpy.empty((cData_2.shape[0], no_unq_bls))\n",
    "red_vis_amp_j = numpy.empty_like(red_noise_j)\n",
    "\n",
    "for bl_type in range(no_unq_bls):\n",
    "    group_idxs = numpy.where(bl_types == bl_type)[0]\n",
    "    grouped_noise = noise_std_j[:, group_idxs]\n",
    "    grouped_vis_amp = stat_vis_amp_j[:, group_idxs]\n",
    "    red_noise_j[:, bl_type] = numpy.sqrt(numpy.sum(numpy.square(grouped_noise), axis=1)) \\\n",
    "                            / grouped_noise.shape[1]\n",
    "    red_vis_amp_j[:, bl_type] = stat(grouped_vis_amp, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Noise across a redundant group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "red_noise_gj = red_noise_j[:, slct_bl_type_id]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(11, 7))\n",
    "plt.plot(red_noise_gj/stat(stat_vis_amp_j[:, slct_idxs], axis=1), label='LAST', alpha=0.8)\n",
    "plt.plot(red_noise_g/stat(stat_vis_amp[:, slct_idxs], axis=1), label='time', alpha=0.8)\n",
    "plt.xlabel('Frequency channel')\n",
    "plt.ylabel('Fractional noise')\n",
    "plt.title('\\n'.join(wrap('Standard deviation of residuals between adjacent visibilities '\\\n",
    "    '(in time [JD {0}] and LAST [JDs {0} and {1}]) divided by the {2} visibility amplitude, '\\\n",
    "    'for baselines redundant with {3} at LAST {4}'.format(int(JD), int(JD_2a), statistic, \\\n",
    "    slct_bl_type, lastj), max_title_length)))\n",
    "plt.ylim(bottom=0, top=1)\n",
    "plt.legend()\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The fractional noise estimates using both methods match well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frac_noise_j = red_noise_j/red_vis_amp_j\n",
    "fig, ax = clipped_heatmap(frac_noise_j.transpose(), 'Baseline type')\n",
    "ax.set_title('\\n'.join(wrap('Standard deviation of residuals between adjacent visibilities '\\\n",
    "    '(in LAST [JDs {} and {}]) divided by the {} visibility amplitude, for all  redundant '\\\n",
    "    'baseline types, at LAST {}'.format(int(JD), int(JD_2a), statistic, lastj), \\\n",
    "                                        max_title_length)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_diff = (frac_noise - frac_noise_j).transpose()\n",
    "\n",
    "fig, ax = clipped_heatmap(noise_diff, 'Baseline type', cmap='bwr', center=0)\n",
    "ax.set_title('\\n'.join(wrap('Difference in the noise estimated from visibilities '\\\n",
    "    'adjacent in time [JD {0}] and LAST [JDs {0} and {1}] for all baseline types at LAST {2}'\\\n",
    "                            .format(int(JD), int(JD_2a), lastj), max_title_length)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Negative (positive) noise difference values in blue (red) indicate that the noise estimates from using visibilities adjacent in time are lower (higher) than that estimated using visibilities at the same LAST on different JDs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Noise in visibility solutions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can look at the scatter of the visibility solutions from our relative redundant calibration of raw visibilities, to see if this calibration step improves on the intrinsic noise found in Section 1 of this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distribution = 'cauchy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rel_df_path = find_rel_df(JD, pol, distribution, dir='/Users/matyasmolnar/Downloads/HERA_Data/robust_cal/rel_dfs_cauchy')\n",
    "rel_df = pd.read_pickle(rel_df_path)\n",
    "\n",
    "freq_chans = rel_df.index.get_level_values('freq').unique().values\n",
    "time_ints = rel_df.index.get_level_values('time_int').unique().values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "variables": {
     "freq_channel": {}
    }
   },
   "source": [
    "## Visibility amplitudes for test channel {{freq_channel}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rel_vis = numpy.empty((freq_chans.size, time_ints.size, no_unq_bls), dtype=complex)\n",
    "for f, freq in enumerate(freq_chans):\n",
    "    rel_vis_comps, _ = numpy.split(rel_df.loc[freq, :].values[:, 5:-2]\\\n",
    "                                   .astype(float), [no_unq_bls*2,], axis=1)\n",
    "    for tint in time_ints:\n",
    "        rel_vis[f, tint, :] = makeCArray(rel_vis_comps[tint, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rel_vis_amp_f = numpy.abs(rel_vis[freq_channel, ...])\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(11, 7))\n",
    "plt.plot(rel_vis_amp_f, alpha=0.5)\n",
    "plt.xlabel('Time integration')\n",
    "plt.ylabel('Visibility amplitude')\n",
    "plt.title('\\n'.join(wrap('Amplitudes for visibility solutions for all redundant '\\\n",
    "    'baseline groups at frequency channel {} on JD {} at LAST {}'\\\n",
    "                         .format(freq_channel, int(JD), last0), max_title_length)))\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Noise across frequencies and baseline groups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We calculate the noise for each frequency and baseline group, by taking the standard deviation of the visibility solutions over all time integrations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rel_noise_std = numpy.empty((freq_chans.size, no_unq_bls))\n",
    "stat_rel_vis_amp = numpy.empty_like(rel_noise_std)\n",
    "\n",
    "for freq in range(freq_chans.size):\n",
    "    for bl_g in range(no_unq_bls):\n",
    "        rel_vis_fb = rel_vis[freq, :, bl_g]\n",
    "        rel_vis_diffs = numpy.asarray([t - s for s, t in zip(rel_vis_fb, rel_vis_fb[1:])])\n",
    "        rel_noise_std[freq, bl_g] = numpy.sqrt(numpy.var(rel_vis_diffs.real) + \\\n",
    "                                               numpy.var(rel_vis_diffs.imag))\n",
    "        stat_rel_vis_amp[freq, bl_g] = stat(numpy.abs(rel_vis_fb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rel_frac_noise = rel_noise_std/stat_rel_vis_amp\n",
    "fig, ax = clipped_heatmap(rel_frac_noise.transpose(), 'Baseline type')\n",
    "ax.set_title('\\n'.join(wrap('Standard deviation of residuals between adjacent visibility '\\\n",
    "    'solutions (in time), divided by the {} visibility solution amplitude, for all '\\\n",
    "    'redundant baseline types, on JD {} at LAST {}'\\\n",
    "                            .format(statistic, int(JD), last0), max_title_length)))\n",
    "ax.xaxis.set_major_formatter(ticker.ScalarFormatter(useOffset=-50))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalized by the number of baselines in each group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nrm_no_bl_rel_frac_noise = rel_frac_noise*numpy.sqrt(no_bls_g[None, :])\n",
    "\n",
    "fig, ax = clipped_heatmap(nrm_no_bl_rel_frac_noise.transpose(), 'Baseline type')\n",
    "ax.set_title('\\n'.join(wrap('Standard deviation of residuals between adjacent visibility '\\\n",
    "    'solutions (in time), divided by the {} visibility solution amplitude, for all '\\\n",
    "    'redundant baseline types, on JD {} at LAST {}, multiplied by the square root of the '\\\n",
    "    'number of baselines for each type'.format(statistic, int(JD), last0), max_title_length)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Noise comparison with raw visibilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rel_noise_diff = (rel_frac_noise/frac_noise[freq_chans]).transpose()\n",
    "\n",
    "fig, ax = clipped_heatmap(rel_noise_diff, 'Baseline type', cmap='bwr', center=0)\n",
    "ax.set_title('\\n'.join(wrap('Difference between the estimates of the noise for visibility '\\\n",
    "    'solutions and that from raw visibilities adjacent in time and LAST for all baseline '\\\n",
    "    'types on JD {} at LAST {}'.format(int(JD), last0), max_title_length)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Red (blue) regions correspond to baseline groups and frequencies where the noise from raw visibilities is lower (higher) than that for visibility solutions calculated from relative redundant calibration."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
